<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[LZH007]]></title>
  <link href="https://lockxmonk.github.io/atom.xml" rel="self"/>
  <link href="https://lockxmonk.github.io/"/>
  <updated>2017-08-22T19:35:25+08:00</updated>
  <id>https://lockxmonk.github.io/</id>
  <author>
    <name><![CDATA[]]></name>
    
  </author>
  <generator uri="http://www.mweb.im/">MWeb</generator>
  
  <entry>
    <title type="html"><![CDATA[第十三条 用"方法调配技术"调试"黑盒方法"]]></title>
    <link href="https://lockxmonk.github.io/15034774413129.html"/>
    <updated>2017-08-23T16:37:21+08:00</updated>
    <id>https://lockxmonk.github.io/15034774413129.html</id>
    <content type="html"><![CDATA[
<p>因为OC可以在运行期解析 一个对象究竟调用何种方法,所以我们也可以在运行期改变相对应的方法. </p>

<p><font color=red>因为与给定的选择子名称相对应的方法也可以在运行期改变.所以若能善用此特性，则可发挥出巨大优势，因为我们既不需要源代码，也不需要通过继承子类来覆写方法就能改变这个类本身的功能。这样一来，新功能将在本类的所有实例中生效，而不是仅限于覆写了相关方法的那些子类实例。此方案经常称为<mark>“方法调配”（method swizzling)</mark> e</font></p>

<p>类的方法列表会把选择子的名称映射到相关的方法实现之上，使得“动态消息派发系统” 能够据此找到应该调用的方法。这些方法均以函数指针的形式来表示，这种指针叫做<code>IMP</code>, 其原型如下：</p>

<pre><code class="language-objc">
id (*IMP)(id, SEL ,...)

</code></pre>

<p>我们用NSString类来举例,下图表示<code>lowercaseString、uppercaseString、capitalizedString</code>方法映射到了不同的<code>IMP</code>上.</p>

<p><img src="media/15034774413129/15034784608780.jpg" alt=""/></p>

<p>OC运行期系统,提供有方法来操作这个映射表.我们可以向这个表中,<strong>新增选择子,改变选择子所对应的方法实现,交换两个选择子所映射的指针</strong>.类似下图:<br/>
<img src="media/15034774413129/15034786156175.jpg" alt=""/></p>

<p>新表中,多了一个<code>newSelector</code>选择子,并且其他方法的实现也互换了.上述修改均无须编写子类，只是修改了“方法表”的布局.</p>

<p>下面我们来讨论如何互换两个方法的实现:</p>

<p>想要互换两个方法的实现可以,有下列函数:</p>

<pre><code class="language-objc">//互换m1和m2的实现
void method_exchangeImplementations(Method m1, Method m2)

</code></pre>

<p>m1和m2的方法实现可以通过下面方法实现:</p>

<pre><code class="language-objc">
Method class_getInstanceMethod(Class aClass, SEL aSelector)

</code></pre>

<p>此函数根据给定的选择从类中取出与之相关的方法。</p>

<p>下面我们完整的举一个例子,来演示交换前面提到的<code>lowercaseString</code> 与 <code>uppercaseString</code>方法实现:</p>

<pre><code class="language-objc">
Method originalMethod =
    class_getInstanceMethod([NSStringclass],
                            @selector(lowercaseString));
Method swappedMethod =
    class_getInstanceMethod([NSStringclass],
                            @selector(uppercaseString)); 
                            method_exchangeImplementations(originalMethod,swappedMethod);

</code></pre>

<p>从现在开始,如果在NSString实例上调用<code>lowercaseString</code>,那么执行的将是<code>uppercaseString</code>,反之亦然:</p>

<pre><code class="language-objc">
NSString *string = @&quot;This iS tHe StRiNg&quot;;
NSString *lowercaseString = [string lowercaseString];
NSLog(&quot;lowercaseString = %@&quot;, lowercaseString);
// Output: lowercaseString = THIS IS THE STRING


NSString *uppercaseString - [string uppercaseString】；
NSLog (@&quot;uppercaseString = %@&quot;, uppercaseString);
// Output: uppercaseString = this is the string

</code></pre>

<p>刚才向大家演示了如何交换两个方法实现，然而在实际应用中，像这样直接交换两 个方法实现的，意义并不大。因为<code>lowercaseString</code>与<code>uppercaseString</code>这两个方法已经各自实现得很好，没必要再交换了。但是，可以通过这一手段来为既有的方法实现增添新功能。<font color=red>比方说，想要在调用<code>lowercaseString</code>时记录某些信息，这时就可以通过交换方法实现来达成此目标。我们新编写一个方法，在此方法中实现所需的附加功能，并调用原有实现</font>。</p>

<p>新方法可以添加至NSString的一个&quot;分类(category)&quot;中:</p>

<pre><code class="language-objc">
@interface NSString (EOCMyAdditions)

-(NSString*)eoc_myLowercaseString;

@end

</code></pre>

<p>上面的新方法将与原有的方法互换,如下图所示:</p>

<p><img src="media/15034774413129/15034869016993.jpg" alt=""/></p>

<p>新方法的实现代码可以这样写:</p>

<pre><code class="language-objc">
0implementation NSString (EOCMyAdditions)

-(NSString*)eoc_myLowercaseString {
    NSString *lowercase = [self eoc_myLowercaseString];
    NSLog (@&quot;%@ =&gt; %@&quot;, self, lowercase); 
    return lowercase;
)
@end

</code></pre>

<p>这段代码看上去好像会陷人递归调用的<strong>死循环</strong>，<mark><strong>不过大家要记住，此方法是准备和 lowercaseString方法互换的。所以，在运行期，eoc_myLowercaseString选择子实际上对应于原有的lowercaseString方法实现</strong>。</mark>最后，通过下列代码来交换这两个方法实现：</p>

<pre><code class="language-objc">Method originalMethod =
    class_getInstanceMethod([NSString class],
                            @selector(lowercaseString)〉；
Method swappedMethod =
    class_getInstanceMethod([NSString class]f
                            @selector(eoc_myLowercaseString)); 
                            method_exchangeImplementations(originalMethod , swappedMethod);

</code></pre>

<p>之后我们只要如下执行就会发现:</p>

<pre><code class="language-objc">
NSString *string = @&quot;ThIs iS tHe StRiNg&quot;;
NSString *lowercaseString = [string lowercaseString];
//输出了下面这行
// Output: This iS tHe StRiNg =&gt; this is the string

</code></pre>

<blockquote>
<p><strong>通过此方案，开发者可以为那些“完全不知道其具体实现的&quot;（completely opaque, “完全 不透明的”）黑盒方法增加日志记录功能，这非常有助于程序调试。然而，此做法只在调试程序时有用。很少有人在调试程序之外的场合用上述“方法调配技术”来永久改动某个类的功能。不能仅仅因为Objective-C语言里有这个特性就一定要用它。若是滥用，反而会令代码变得不易读懂且难于维护。</strong></p>
</blockquote>

<h2 id="toc_0">要点</h2>

<ul>
<li><p>在运行期，可以向类中新增或替换选择子所对应的方法实现。</p></li>
<li><p>使用另一份实现来替换原有的方法实现，这道工序叫做“方法调配”，开发者常用此技术向原有实现中添加新功能。</p></li>
<li><p>一般来说，只有调试程序的时候才需要在运行期修改方法实现，这种做法不宜滥用。</p></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[第十二条 消息转发机制(Message forwarding)]]></title>
    <link href="https://lockxmonk.github.io/15033908572762.html"/>
    <updated>2017-08-22T16:34:17+08:00</updated>
    <id>https://lockxmonk.github.io/15033908572762.html</id>
    <content type="html"><![CDATA[
<p>第11条讲解了对象的消息传递机制，并强调了其重要性。第12条则要讲解另外一个重要的问题，就是对象在收到无法解读的消息之后会发生什么情况。若想令类能理解某条消息，我们必须以程序码实现出对应的方法才行。<font color=red><strong>但是，在编译期向类发送了其无法解读的消息并不会报错，因为在运行期可以继续向类中添加方法，所以编译器在编译时还无法确知类中到底会不会有某个方法实现。</strong></font>当对象接收到无法解读的消息后，就会启动<mark>“消息转发&quot;（message forwarding)机制</mark>，程序员可经由此过程告沂对象应该如何处理未知消息。</p>

<p>消息转发分为两大阶段:</p>

<ol>
<li><p>先征询接收者，所属的类，看其是否能动态添加方法，以处理当前这个“未知的选择子&quot;（unknown selector),这叫做“动态方法解析”（dynamic method resolution)。</p></li>
<li><p>涉及“完整的消息转发机制”（full forwarding mechanism)。如果运行期系统已经把第一阶段执行完了，那么接收者自己就无法再以动态新增方法的手段来响应包含该选择子的消息了。此时，运行期系统会请求接收者以其他手段来处理与消息相关的方法调用。这又细分为<strong>两小步</strong>。首先，请接收者看看有没有其他对象能处理这条消息。若有，则运行期系统会把消息转给那个对象，于是消息转发过程结束，一切如常。若没有“备援的接收者”（replacement receiver)，则启动完整的消息转发机制，运行期系统会把与消息有关的全部细节都封装到<code>NSInvocation</code>对象中，再给接收者最后一次机会，令其设法解决当前还未处理的这条消息。</p></li>
</ol>

<h2 id="toc_0">动态方法解析</h2>

<p>对象在收到无法解读的消息后，首先将调用其所属类的下列类方法：</p>

<pre><code class="language-objc">
+ (BOOL)resolvelnstanceMethod:(SEL)selector

</code></pre>

<p>该方法的参数就是那个未知的选择子，其返回值为<code>Boolean</code>类型，表示这个类是否能新增一个实例方法用以处理此选择子。在继续往下执行转发机制之前，本类有机会新增一个处理此选择子的方法。假如尚未实现的方法不是实例方法而是类方法，那么运行期系统就会调用另外一个方法，该方法与 <code>“resolvelnstanceMethod:”</code> 类似，叫做 <code>“resolveClassMethod:”</code>。使用这种办法的前提是：相关方法的实现代码已经写好，只等着运行的时候动态插在类里面就可以了。此方案常用来实现<code>@dynamic</code>属性（参见第6条)，比如说，要访问<code>CoreData</code>框架中<code>NSManagedObjects</code>对象的属性时就可以这么做，因为实现这些属性所需的存取方法在编译期就能确定。</p>

<p>下列代码演示了如何用<code>“resolvelnstanceMethod:”</code>来实现<code>@dynamic</code>属性：</p>

<pre><code class="language-objc">
id autoDictionaryGetter(id self, SEL _cmd);
void autoDictionarySetter(id selff SEL _cmd, id value);
+ (BOOL)resolvelnstanceMethod:(SEL)selector {
    NSString *selectorString = NSStringFromSelector(selector);
    if ( /* selector is from a ©dynamic property ★/ ){
        if([selectorstring has Prefix: @&quot;set&quot;]){
            class addMethod(self,
                            selector,
                            (IMP)autoDictionarySetter,
                            &quot;v@ :@&quot;);
    } else {
        class_addMethod(self,
                        selector,
                        (IMP)autoDictionaryGetter,
                        &quot;@ @:&quot;);
        }              
        return YES;
    }
return [super resolvelnstanceMethod:selector];

}

</code></pre>

<h2 id="toc_1">备援接受者</h2>

<p>当前接收者还有第二次机会能处理未知的选择子，在这一步中，运行期系统会问它：能不能把这条消息转给其他接收者来处理。与该步骤对应的处理方法如下：</p>

<pre><code class="language-objc">
-(id)forwardingTargetForSelector:(SEL)selector

</code></pre>

<p>方法参数代表未知的选择子，若当前接收者能找到备援对象，则将其返回，若找不到，就返回<code>nil</code>。通过此方案，我们可以用“组合”（composition)来模拟出“多重继承”（multiple inheritance)的某些特性。在一个对象内部，可能还有一系列其他对象，该对象可经由此方法将能够处理某选择子的相关内部对象返回，这样的话，在外界看来，好像是该对象亲自处理了这些消息似的。</p>

<p><font color=red>请注意，我们无法操作经由这一步所转发的消息。若是想在发送给备援接收者之前先修改消息内容，那就得通过完整的消息转发机制来做了。</font></p>

<h2 id="toc_2">完整的消息转发</h2>

<p>如果转发算法已经来到这一步的话，那么唯一能做的就是启用完整的消息转发机制了。首先创建<code>NSInvocation</code>对象，把与尚未处理的那条消息有关的全部细节都封于其中。此对象包含选择子、目标（target)及参数。在触发NSIrwocation对象时，“消息派发系统”(message-dispatch system)将亲自出马，把消息指派给目标对象。<br/>
此步骤会调用下列方法来转发消息：</p>

<pre><code class="language-objc">
-(void)forwardlnvocation:(NSInvocation*)invocation

</code></pre>

<p>这个方法可以实现得很简单：只需改变调用目标，使消息在新目标上得以调用即可。然<br/>
而这样实现出来的方法与“备援接收者”方案所实现的方法等效，所以很少有人采用这么简<br/>
单的实现方式。比较有用的实现方式为：在触发消息前，先以某种方式改变消息内容，比如追加另外一个参数，或是改换选择子，等等。</p>

<p>实现此方法时，若发现某调用操作不应由本类处理，则需调用超类的同名方法。这样的话，继承体系中的每个类都有机会处理此调用请求，直至<code>NSObject</code>。如果最后调用了<code>NSObject</code>类的方法，那么该方法还会继而调用<code>“doesNotRecognizeSelector:”</code>以抛出异常，此异常表明选择子最终未能得到处理。</p>

<h2 id="toc_3">消息转发全流程</h2>

<p>下图展示了消息转发机制处理消息的各个步骤:<br/>
<img src="media/15033908572762/15033988345236.jpg" alt=""/></p>

<p><font color=red>接收者在每一步中均有机会处理消息。步骤越往后，处理消息的代价就越大。</font>最好能在第一步就处理完，这样的话，运行期系统就可以将此方法缓存起来了。如果这个类的实例稍后还收到同名选择子，那么根本无须启动消息转发流程。</p>

<h2 id="toc_4">完整的示例</h2>

<p>假设要编写一个类似于“字典”的对象，它里面可以容纳其他对象，只不过开发者要直接通过属性来存取其中的数据。这个类的设计思路是：由幵发者来添加属性定义，并将其声明为<code>@dynamic</code>，而类则会自动处理相关属性值的存放与获取操作。</p>

<p>定义该类的接口为:</p>

<pre><code class="language-objc">
#import &lt;Foundation/Foundation.h&gt;
@interface EOCAutoDictionary : NSObject
@property (nonatomic, strong) NSNumber *number;
@property (nonatomic, strong) NSDate *date;
@property (nonatomic, strong)id qpaqueObject;

@end

</code></pre>

<p>本例中，这些属性具体是什么其实无关紧要。笔者用了这么多种数据类型，只是想演示此 功能很有用。在类的内部，每个属性的值还是会存放在字典里，所以我们先在类中编写如下代码，并将属性声明为@dynamiC，这样的话，编译器就不会为其自动生成实例变量及存取方法了：</p>

<pre><code class="language-objc">
#import &quot;EOCAutoDictionary.h&quot;
#import &lt;objc/runtime.h&gt;

@interface EOCAutoDictionary ()

@property (nonatomic, strong) NSMutableDictionary *backingstore;

@end

@implementation EOCAutoDictionary

@dynamic string, number, date, opaqueObject;

-(id)init {
    if ( (self = [super init]}} {
          _backingStore = [NSMutableDictionary new];
}
    return self;
}

</code></pre>

<p>本例的关键在于<code>resolvelnstanceMethod:</code>方法的实现代码：</p>

<pre><code class="language-objc">
+ (BOOL)resolvelnstanceMethod:(SEL)selector {
    NSString *selectorstring = NSStringFromSelector(selector); 
    if ([selectorstring hasPrefix: @&quot;set&quot;]){
        class_addMethod(self,
                        selector,
                        (IMP)autoDictionarySetter
                         &quot;v@:@&quot;);
    } else {
        class_addMethod(self,
                        selector,
                        (IMP)autoDictionaryGetter,
                        &quot;@@:&quot;;)    
    }
    return YES;
}
@end

</code></pre>

<p>当开发者首次在<code>EOCAutoDictionary</code>实例上访问某个属性时，运行期系统还找不到 对应的选择子，因为所需的选择子既没有直接实现，也没有合成出来。现在假设要写入 <code>opaqueObject</code>属性，那么系统就会以<code>“setOpaqueObject:”</code>为选择子来调用上面这个方法。 同理，在读取该属性时，系统也会调用上述方法，只不过传入的选择子是<code>opaqueObject</code>。</p>

<p><code>resolvelnslanceMethod</code>方法会判断选择子的前缀是否为set，以此分辨其是set选择子还是 get选择子。在这两种情况下，都要向类中新增一个处理该选择子所用的方法，这两个方 法分别以<code>autoDictionarySetter</code>及<code>autoDictionaryGetter</code>函数指针的形式出现。此时就用到<code>class_addMethod</code>方法，它可以向类中动态地添加方法，用以处理给定的选择子。第三个参 数为函数指针，指向待添加的方法。而最后一个参数则表示待添加方法的“类型编码”（type encoding)。在本例中，编码开头的字符表示方法的返回值类型，后续字符则表示其所接受的各个参数.</p>

<p><code>getter</code>函数可以用下列代码实现:</p>

<pre><code class="language-objc">
id autoDictionaryGetter(id self, SEL _cmd) {
    //Get the backing store from the object
    EOCAutoDictionary *typedSelf = (EOCAutoDictionary^)self；
    NSMutableDictionary *backingStore = typedSelf.backingStore;
    //The key is simply the selector name 
    NSString *key = NSStringFromSelector(_cmd);
    // Return the value
    return [backingStore objectForKey:key];
}

</code></pre>

<p>而setter函数则可以这么写：</p>

<pre><code class="language-objc">
void autoDictionarySetter(id self, SEL _cmd, id value) {
    //Get the backing store from the object
    EOCAutoDictionary *typedSelf = (EOCAutoDictionary*)self；
    NSMutableDictionary *backingStore = typedSelf.backingStore;

    /** The selector will be for example, &quot;setOpaqueObject:&quot;
    *   We need to remove the &quot;set&quot;，and lowercase the first
    *   letter of the remainder.
    */
    
    NSString *selectorstring = NSStringFromSelector(_cmd);
    NSMutablestring *key = [selectorstring mutableCopy】；
    // Remove the &quot; : &quot; at the end 
    [key deleteCharactersInRange:NSMakeRange(key.length - 1, 1)];
    // Remove the fsetf prefix
    [key deleteCharactersInRange:NSMakeRange(0, 3)];
    // Lowercase the first character
    NSString *lowercaseFirstChar = [[key substringToIndex:1] lowercasestring];
    [key replaceCharactersInRange:NSMakeRange(0 ,1) withString:lowercaseFirstChar];
    if (value) {
    [backingStore setObject:value forKey:key];
    } else {
    [backingStore removeObjectForKey:key];
    }
}

</code></pre>

<p>EOCAutoDictionary的用法很简单：</p>

<pre><code class="language-objc">
    EOCAutoDictionary *dict = [EOCAutoDictionarynew];
    diet.date = [NSDatedateWithTimeIntervalSincel970:475372800];
    NSLog (@&quot;diet .date = %@&quot; , dict.date);
    // Output: diet.date = 1985-01-24 00:00:00 +0000

</code></pre>

<p>其他属性的访问方式与<code>date</code>类似，要想添加新属性，只需来定义，并将其声明为<code>@dynamic</code>即可。</p>

<h2 id="toc_5">要点</h2>

<ul>
<li>若对象无法响应某个选择子，则进人消息转发流程。</li>
<li>通过运行期的动态方法解析功能，我们可以在需要用到某个方法时再将其加入类中。 </li>
<li>对象可以把其无法解读的某些选择子转交给其他对象来处理。</li>
<li>经过上述两步之后，如果还是没办法处理选择子，那就启动完整的消息转发机制。</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[第十一条:理解Objc_msgSend的作用]]></title>
    <link href="https://lockxmonk.github.io/15033059328138.html"/>
    <updated>2017-08-21T16:58:52+08:00</updated>
    <id>https://lockxmonk.github.io/15033059328138.html</id>
    <content type="html"><![CDATA[
<p>在对象中调用方法,在oc中称作&quot;传递消息&quot;.消息有“名称&quot;（name)或“选择子&quot;（selector)，可以接受参数，而且可能还有返回值。</p>

<p>因为OC是C语言的超集,所以我们用C语言来举例.C语言使用“静态绑定”（static binding),也就是说，在编译期就能决定运行时所应调用的函数。</p>

<pre><code class="language-c">#import &lt;stdio.h&gt;

void printHello() {
    printf (&quot;Hello, world! \n&quot;);
    }
void printGoodbye() {
    printf (&quot;Goodbye, world! \n&quot;);

void doTheThing(int type) {
    if (type == 0)  {
        printHello();
    }else{
        printGoodbye();
    }
    return 0；
}

</code></pre>

<p>编译器在编译代码的时候就已经知道程序中有<code>printHello</code>与<code>printGoodbye</code>这两个函数了，于是会直接生成调用这些函数的指令。而函数地址实际上是硬编码在指令之中的。</p>

<p>但是将程序改写为下面这样后:</p>

<pre><code class="language-c">#import &lt;stdio.h&gt;

void printHello() {
    printf (&quot;Hello, world! \n&quot;);
    }
void printGoodbye() {
    printf (&quot;Goodbye, world! \n&quot;);

void doTheThing(int type) {
    void(*fnc)()
    if (type == 0)  {
        fnc = printHello;
    }else{
        fnc = printGoodbye;
    }
    fnc();
    return 0；
}

</code></pre>

<p>这个时候就要使用“动态绑定”（dynamic binding) 了，因为所要调用的函数直到运行期才能确定。编译器在这种情况下生成的指令与刚才那个例子不同，<mark>在第一个例子中，<code>if</code>与<code>else</code>语句里都有函数调用指令。而在第二个例子中，只有一个函数调用指令，不过待调用的函数地址无法硬编码在指令之中，而是要在运行期读取出来</mark>。</p>

<p>在oc中如果向某对象传递消息(方法调用),就会使用动态绑定机制来决定需要调用的方法。在底层，所有方法都是普通的C语言函数，然而对象收到消息之后，究竟该调用哪个方法则完全于运行期决定，甚至可以在程序运行时改变，这些特性使得Objective-C成为一门真正的动态语言。</p>

<p>给对象发送消息可以这样来写：</p>

<pre><code class="language-objc">
id returnValue = [someObject messageName:parameter];

</code></pre>

<p>在本例中，<code>someObject</code>叫做“接收者”（receiver),<code>messageName</code> 叫做<code>“选择子”</code>（selector)。选择子与参数合起来称为“消息”（message)。编译器看到此消息后，将其转换为一条标准的C语言函数调用，所调用的函数乃是消息传递机制中的核心函数,叫做<code>objc_msgSend</code>,其<br/>
“原型&quot;（prototype)如下：</p>

<pre><code class="language-c">
void objc_msgSend(id self, SEL cmd, •••)

</code></pre>

<p>这是个‘参数个数可变的函数’(variadic function)9，能接受两个或两个以上的参数。第一个参数代表接收者，第二个参数代表选择子（SEL是选择子的类型)，后续参数就是消息中的那些参数，其顺序不变。<strong>选择子指的就是方法的名字</strong>。“选择子”与“方法”这两个词经常交替使用。编译器会把刚才那个例子中的消息转换为如下函数：</p>

<pre><code class="language-c">
id returnValue = objc_msgSend(someObject,
                            ^selector(messageName:),
                            parameter);

</code></pre>

<p><code>objc_msgSend</code>函数会依据接收者与选择子的类型来调用适当的方法。为了完成此操作，该方法需要在接收者所属的类中搜寻其“方法列表”（list of methods),如果能找到与选择子名称相符的方法，就跳至其实现代码。若是找不到，那就沿着继承体系继续向上査找，等找到合适的方法之后再跳转。如果最终还是找不到相符的方法，那就执行“消息转发” (message forwarding)操作。消息转发将在第12条中详解。</p>

<p>其它特殊情况需要由一些函数来处理:</p>

<ul>
<li><strong>objc_msgSendstret。</strong>如果待发送的消息要返回结构体，那么可交由此函数处理。只有当CPU的寄存器能够容纳得下消息返回类型时，这个函数才能处理此消息。若是返回值无法容纳于CPU寄存器中（比如说返回的结构体太大了)，那么就由另一个函数执行派发。此时，那个函数会通过分配在栈上的某个变量来处理消息所返回的结构体。</li>
<li>ObjC_mSgSerid_fpret。如果消息返回的是浮点数，那么可交由此函数处理,在某些架构的CPU中调用函数时，需要对浮点数寄存器（floating-point register)做特殊处理,也就是说，通常所用的ObjC_msgSend在这种情况下并不合适。这个函数是为了处理x86等架构CPU中某些令人稍觉惊讶的奇怪状况。</li>
<li>objc_msgSendSuper3 如果要给超类发消息，例如[supermessage:parameter],那么就交由此函数处理。也有另外两个与objc_msgSendstret和objc_MsgSend_fpret等效的函数，用于处理发给super的相应消息。</li>
</ul>

<p>刚才曾提到,Objc_msgSend等函数一旦找到应该调用的方法之后，就会‘跳转过去’。之所以能这样做，是因为Objective-C对象的每个方法都可以视为简单的C函数，其原型如下：</p>

<pre><code class="language-c">
&lt;return type&gt; Class_selector(id self, SEL _cmd, •••)

</code></pre>

<p>真正的函数名和上面写的可能不太一样，笔者用“类”（class)和“选择子”（selector)来命名是想解释其工作原理。每个类里都有一张表格，其中的指针都会指向这种函数，而选择子的名称则是査表时所用的“键”。ObjC_msgSend等函数正是通过这张表格来寻找应该执行的方法并跳至其实现的。请注意，原型的样子和ObjC_msgSend函数很像。这不是巧合，而是为了利用“尾调用优化”技术，令“跳至方法实现”这一操作变得更简单些。</p>

<h2 id="toc_0">要点</h2>

<ul>
<li>消息由接收者、选择子及参数构成。给某对象&quot;发送消息&quot;(invoke a message)也就相当于在该对象上“调用方法”（call a method)。</li>
<li>发给某对象的全部消息都要由“动态消息派发系统”（dynamic message dispatch system)来处理，该系统会査出对应的方法，并执行其代码。</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[小论文想法]]></title>
    <link href="https://lockxmonk.github.io/15032784762045.html"/>
    <updated>2017-08-21T09:21:16+08:00</updated>
    <id>https://lockxmonk.github.io/15032784762045.html</id>
    <content type="html"><![CDATA[
<p>1,结合雾天道路行进过程中,图像在远端,中端和近处的雾气浓度不同,进行评估,来自动化调节去雾强度.可以结合边缘检测算法(OTSU),来检测出天空的区域(当前方有车时,检测),然后将图像分割为远中近三个部分.</p>

<p>2.</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Caffe最优化求解过程]]></title>
    <link href="https://lockxmonk.github.io/14993030681229.html"/>
    <updated>2017-07-06T09:04:28+08:00</updated>
    <id>https://lockxmonk.github.io/14993030681229.html</id>
    <content type="html"><![CDATA[
<ul>
<li>
<a href="#toc_0">求解器是什么</a>
</li>
<li>
<a href="#toc_1">求解器是如何实现的</a>
<ul>
<li>
<a href="#toc_2">算法描述</a>
</li>
</ul>
</li>
</ul>


<p>将前面几天讲述的不同Layer组合起来就可以构建起完整的<code>CNN/DNN</code>。今天将从Caffe的Solver类入手，对Caffe训练时的流程做深入分析，也就是看Caffe实际是如何“动”起来的。</p>

<h2 id="toc_0">求解器是什么</h2>

<p>从前两天内容我们学习到，Net己经完成部分学习任务（数据前向传播、误差反向传播),<mark>而CNN剩下有监督的优化过程、利用每层的梯度生成权值增量则由求解器(Solver)负责.</mark></p>

<p>求解器负责对模型优化,它的KPI(Key Performance Indicator,关键绩效指你，某公司常用的一种员工绩效评定方式）就是让损失函数达到全局最小。</p>

<p>求解器的特性如下:</p>

<ul>
<li>负责记录优化过程，创建用于学习的训练网络和用于评估学习效果的测试网络。</li>
<li>调用Forward\(\rightarrow\)调用Backward\(\rightarrow\)更新权值，反复迭代优化模型。</li>
<li>周期性的评估测试网络</li>
<li>在优化过程中为模型,求解器状态打快照.</li>
</ul>

<p>为了让权值从初始化状态向着更好的模型前进，求解器在每次迭代中做了如下事情：</p>

<ul>
<li>调用Net的前向传播函数来计算输出和损失函数。</li>
<li>调用Net的反向传播函数来计算梯度。</li>
<li>根据求解器方法,将梯度转换为权值增量</li>
<li>根据学习速率、历史权值、所用方法更新求解器状态。</li>
</ul>

<h2 id="toc_1">求解器是如何实现的</h2>

<p>在卷积神经网络中,有两种类型的层需要学习:卷积层和全连接层（统称权值层，因为它们都有<code>weight</code>参数）。<mark>在设计求解器时，学习速率参数的设置也是针对这两个层的</mark>。</p>

<p>在caffe中我们要适当把握度,控制收敛的参数---学习速率.</p>

<p>我们来具体看一下Caffe是如何对权值学习做到“不偏不倚”的。</p>

<h3 id="toc_2">算法描述</h3>

<p>Caffe中的求解器有以下几种:</p>

<ul>
<li>随机梯度下降法（Stochastic Gradient Descent, SGD),最常用的一种</li>
<li>AdaDelta</li>
<li>自适应梯度法（Adaptive Gradient, ADAGRAD)</li>
<li>Adam</li>
<li>Nesterov加速梯度法（Nesterov’s Accelerated Gradient, NAG)</li>
<li>RMSprop</li>
</ul>

<p><mark>求解器方法重点是最小化损失函数的全局优化问题</mark>,对于数据集D,优化目标是在全数据集D上损失函数平均值：<br/>
\[<br/>
L(W)=\frac{1}{|{D}|}\sum^{|D|}_{i}{f_w(X^{(i)}) + \lambda{r}(W)}<br/>
\]</p>

<p>其中，\(f_w(X^{(i)})\)是在数据实例\(X^{(i)\)上的损失函数，\(r(W)\)为规整项，\(\lambda\)为规整项的权重。数据集\(D\)可能非常大，工程上一般在每次迭代中使用这个目标函数的随机逼近，即小批量数据\(N&lt;&lt;|D|\)个数据实例:</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[第10条:在既有类中使用关联对象存放自定义数据]]></title>
    <link href="https://lockxmonk.github.io/14992368546707.html"/>
    <updated>2017-07-05T14:40:54+08:00</updated>
    <id>https://lockxmonk.github.io/14992368546707.html</id>
    <content type="html"><![CDATA[
<p>有时需要在对象中存放相关信息。这时我们通常会从对象所属的类中继承一个子类，然后改用这个子类对象。然而并非所有情况下都能这么做，<mark>有时候类的实例可能是由某种机制所创建的，而开发者无法令这种机制创建出自己所写的子类实例</mark>。</p>

<p><code>Objective-C</code>中有一项强大的特性可以解决此问题，这就是<code>“关联对象&quot;（Associated Object)</code>。</p>

<p>可以给某对象关联许多其他对象，这些对象通过“键”来区分.存储对象值的时候，可以指明“存储策略”（storage policy),用以维护相应的“内存管理语义”。存储策略由名为<code>Objc_ASSOCiationPolicy</code>的枚举所定义，下表列出了该枚举的取值，同时还列出了与之等效属性：假如关联对象成为了属性，那么它就会具备对应的语义（第6条详解了“属性”这个概念).</p>

<table>
<thead>
<tr>
<th>关联类型</th>
<th>等效的@property属性</th>
</tr>
</thead>

<tbody>
<tr>
<td>OBJC_ASSOCIATION_ASSIGN</td>
<td>assign</td>
</tr>
<tr>
<td>OBJC_ASSOCIATION_RETAIN_NONATOMIC</td>
<td>nonatomic, retain</td>
</tr>
<tr>
<td>OBJC_ASSOCIATION_COPY_NONATOMIC</td>
<td>nonatomic, copy</td>
</tr>
<tr>
<td>OBJC_ASSOCIATION_RETAIN</td>
<td>retain</td>
</tr>
<tr>
<td>OBJC_ASSOCIATION_COPY</td>
<td>copy</td>
</tr>
</tbody>
</table>

<p>下列方法可以管理关联对象：</p>

<ul>
<li><p>void objc_setAssociatedObject ( id object, void*key, id value, objc AssociationPolicypolicy)<br/>
此方法以给定的键和策略为某对象设置关联对象值。</p></li>
<li><p>id objc_getAssociatedObject(id object, void*key)<br/>
此方法根据给定的键从某对象中获取相应的关联对象值。</p></li>
<li><p>void objc removeAssociatedObjects(id object)<br/>
此方法移除指定对象的全部关联对象。</p></li>
</ul>

<p>我们可以把某对象想象成<code>NSDictionary</code>,把关联到该对象的值理解为字典中的条目,于是，存取关联对象的值就相当于在NSDictionary对象上调用<code>[object setObject:value forKey:key]</code>与<code>[object objectForKey:key]</code>方法。然而两者之间有个重要差别：设置关联对象时用的键（key)是个&quot;不透明的指针&quot;(opaque pointer)”。如果在两个键上调用<code>“isEqual:”</code>方法的返回值是<code>YES</code>,那么<code>NSDictionary</code>就认为二者相等；然而在设置关联对象值时，若想令两个键匹配到同一个值，则二者必须是完全相同的指针才行。鉴于此，<font color=red>在设置关联对象值时，通常使用<mark>静态全局变量做键</mark></font>。</p>

<h2 id="toc_0">关联对象用法举例</h2>

<p>开发iOS时经常用到<code>UIAlertView</code>类，该类提供了一种标准视图，可向用户展示警告信息.当用户按下按钮关闭该视图时,需要用委托协议（delegate protocol)来处理此动作，但是，要想设置好这个委托机制，就得把创建警告视图和处理按钮动作的代码分开。由于代码分作两块，所以读起来有点乱。比方说，我们在使用<code>UIAlertView</code>时，一般都会这么写：</p>

<pre><code class="language-objc">-(void)askUserAQuestion{
    UIAlertView *alert = [[UIAlertView alloc]
                            initWithTitle:@&quot;Question&quot;
                                  message:@&quot;What do you want to do?&quot;
                                 delegate:self
                        cancelButtonTitle:@&quot;Cancel&quot;
                        otherButtonTitles:@&quot;Continue&quot;, nil]；
        [alert show];
}

// UIAlertViewDelegate protocol method
-(void)alertView:(UIAlertView *)alertView
        clickedButtonAtlndex:(NSInteger)buttonIndex
{
    if (buttonlndex == 0) {
        [self doCancel];
    } else {
        [self doContinue];
    }
}

</code></pre>

<p><font color=red>如果想在同一个类里处理多个警告信息视图，那么代码就会变得更为复杂，我们必须在 <code>delegate</code>方法中检査传人的<code>alertView</code>参数，并据此选用相应的逻辑。要是能在创建警告视图的时候直接把处理每个按钮的逻辑都写好，那就简单多了。这可以通过关联对象来做。创建完警告视图之后，设定一个与之关联的&quot;块&quot;(block)，等到执行<code>delegate</code>方法时再将其读出来。</font>此方案的实现代码如下：</p>

<pre><code class="language-objc">
#import &lt;objc/runtime.h&gt;

static void *EOCMyAlertViewKey = &quot;EOCMyAlertViewKey&quot;;

-(void)askUserAQuestion {
    UIAlertView *alert = [[UIAlertViewalloc]
                            initWithTitle:@&quot;Question&quot;
                                  message: @&quot;What do you want to do?&quot;
                                 delegate:self
                        cancelButtonTitle: @&quot;Cancel&quot;,
                        otherButtonTitles: @&quot;Continue&quot;, nil];
        void (^block)(NSInteger) = ^(NSInteger buttonIndex){
            if (buttonlndex == 0) {
                [self doCancel];
            }else {
                [self doContinue];
            }
        };
        objc_setAssociatedObject(alert,
                                 EOCMyAlertViewKey,
                                 block,
                                 OBJC_ASSOCIATION_COPY);
        [alert show];
}

// UIAlertViewDelegate protocol method
-(void)alertView:(UIAlertView*)alertView
       clickedButtonAtIndex:(NSInteger)buttonIndex
{
    void (^block)(NSInteger)=
        objc_getAssociatedObject(alertView, EOCMyAlertViewKey);
    block(buttonIndex);
}


</code></pre>

<p>以这种方式改写之后，创建警告视图与处理操作结果的代码都放在一起了，这样比原来更易读慷，因为我们无须在两部分代码之间来回游走，即可明白警告视图的用处。但是,采用该方案时需注意：块可能要捕获(capture)某些变量，这也许会造成“保留环”（retain cycle)。第40条详述了此问题。</p>

<p><mark>正如大家所见，这种做法很有用，但是只应该在其他办法行不通时才去考虑用它。若是<br/>
滥用，则很快就会令代码失控，使其难于调试。</mark>“保留环”产生的原因很难査明，因为关联对象之间的关系并没有正式的定义（formal definition)，其内存管理语义是在关联的时候才定义的，而不是在接口中预先定好的。使用这种写法时要小心，不能仅仅因为某处可以用该写法就一定要用它。想创建这种<code>UIAlertView</code>还有个办法，那就是从中继承子类，把块保存为子类中的属性。笔者认为：若是需要多次用到alert视图，那么这种做法比使用关联对象要好。</p>

<h2 id="toc_1">要点</h2>

<ul>
<li>可以通过&quot;关联对象&quot;机制来把两个对象连起来</li>
<li>定义关联对象时可指定内存管理语义，用以模仿定义属性时所采用的“拥有关系”与“非拥有关系”。</li>
<li>只有在其他做法不可行时才应选用关联对象，因为这种做法通常会引入难于査找的bug。</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[SoftmaxWithLossLayer的实现]]></title>
    <link href="https://lockxmonk.github.io/14992160809956.html"/>
    <updated>2017-07-05T08:54:40+08:00</updated>
    <id>https://lockxmonk.github.io/14992160809956.html</id>
    <content type="html"><![CDATA[
<p>我们找到<code>SoftmaxWithLossLayer.hpp</code>文件查看声明,如下:</p>

<pre><code class="language-c++">
//将实数预测向量通过Softmax计算获得每个类别的概率分布
//这个类比单独SoftmaxLayer + MultinomialLogisticLossLayer在梯度数值计算上更加稳定
//Test阶段，这个层可以直接用SoftmaxLayer代替
/**
 *输入Blob 1为预测结果，形状为N x K x 1 x 1，K为总类别数目，N为批量数。取值范围为（-Inf, Inf)，
 *表示每个类别获得的分类score,值越大说明输入图像与该类别越接近
 *输入Blob 2为真实标签，形状为N x 1 x 1 x 1
 *输出Blob为计算得到的交叉熵分类损失E，形状为1 x 1 x 1 x 1
**/
template &lt;typename Dtype&gt;
class SoftmaxWithLossLayer : public LossLayer&lt;Dtype&gt; {
 public:
   /**
    * @param param provides LossParameter loss_param, with options:
    *  - ignore_label (optional)
    *    Specify a label value that should be ignored when computing the loss.
    *  - normalize (optional, default true)
    *    If true, the loss is normalized by the number of (nonignored) labels
    *    present; otherwise the loss is simply summed over spatial locations.
    */
    explicit SoftmaxWithLossLayer(const LayerParameter&amp; param)
      : LossLayer&lt;Dtype&gt;(param) {}
  virtual void LayerSetUp(const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,
      const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top);
  virtual void Reshape(const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,
      const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top);
  virtual inline const char* type() const { return &quot;SoftmaxWithLoss&quot;; }
  virtual inline int ExactNumTopBlobs() const { return -1; }
  virtual inline int MinTopBlobs() const { return 1; }
  virtual inline int MaxTopBlobs() const { return 2; }

 protected:
  virtual void Forward_cpu(const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,
      const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top);
  virtual void Forward_gpu(const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,
      const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top);
      
/**
   * @brief Computes the softmax loss error gradient w.r.t. the predictions.
   *
   * Gradients cannot be computed with respect to the label inputs (bottom[1]),
   * so this method ignores bottom[1] and requires !propagate_down[1], crashing
   * if propagate_down[1] is set.
   *
   * @param top output Blob vector (length 1), providing the error gradient with
   *      respect to the outputs
   *   -# @f$ (1 \times 1 \times 1 \times 1) @f$
   *      This Blob&#39;s diff will simply contain the loss_weight* @f$ \lambda @f$,
   *      as @f$ \lambda @f$ is the coefficient of this layer&#39;s output
   *      @f$\ell_i@f$ in the overall Net loss
   *      @f$ E = \lambda_i \ell_i + \mbox{other loss terms}@f$; hence
   *      @f$ \frac{\partial E}{\partial \ell_i} = \lambda_i @f$.
   *      (*Assuming that this top Blob is not used as a bottom (input) by any
   *      other layer of the Net.)
   * @param propagate_down see Layer::Backward.
   *      propagate_down[1] must be false as we can&#39;t compute gradients with
   *      respect to the labels.
   * @param bottom input Blob vector (length 2)
   *   -# @f$ (N \times C \times H \times W) @f$
   *      the predictions @f$ x @f$; Backward computes diff
   *      @f$ \frac{\partial E}{\partial x} @f$
   *   -# @f$ (N \times 1 \times 1 \times 1) @f$
   *      the labels -- ignored as we can&#39;t compute their error gradients
   */
  virtual void Backward_cpu(const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top,
      const vector&lt;bool&gt;&amp; propagate_down, const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom);
  virtual void Backward_gpu(const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top,
      const vector&lt;bool&gt;&amp; propagate_down, const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom);
      
/// Read the normalization mode parameter and compute the normalizer based
  /// on the blob size.  If normalization_mode is VALID, the count of valid
  /// outputs will be read from valid_count, unless it is -1 in which case
  /// all outputs are assumed to be valid.
  virtual Dtype get_normalizer(
      LossParameter_NormalizationMode normalization_mode, int valid_count);

  /// The internal SoftmaxLayer used to map predictions to a distribution.(内置一个SoftmaxLayer对象)
  shared_ptr&lt;Layer&lt;Dtype&gt; &gt; softmax_layer_;
  /// prob stores the output probability predictions from the SoftmaxLayer.
  Blob&lt;Dtype&gt; prob_;
  /// bottom vector holder used in call to the underlying SoftmaxLayer::Forward
  vector&lt;Blob&lt;Dtype&gt;*&gt; softmax_bottom_vec_;
  /// top vector holder used in call to the underlying SoftmaxLayer::Forward
  vector&lt;Blob&lt;Dtype&gt;*&gt; softmax_top_vec_;
  /// Whether to ignore instances with a certain label.
  bool has_ignore_label_;
  /// The label indicating that an instance should be ignored.
  int ignore_label_;
  /// How to normalize the output loss.
  LossParameter_NormalizationMode normalization_;

  int softmax_axis_, outer_num_, inner_num_;
};

</code></pre>

<p>之后我们来看实现的<code>.cpp</code>文件:</p>

<p>第一个是SetUp函数.<br/>
```c++</p>

<p>template <typename Dtype><br/>
void SoftmaxWithLossLayer<Dtype>::LayerSetUp(<br/>
    const vector<Blob<Dtype><em>&gt;&amp; bottom, const vector<Blob<Dtype></em>&gt;&amp; top) {<br/>
  LossLayer<Dtype>::LayerSetUp(bottom, top);<br/>
  //创建时动态修改本层的LayerParameter参数，适应SoftmaxLayer<br/>
  LayerParameter softmax_param(this-&gt;layer_param_);<br/>
  softmax_param.set_type(&quot;Softmax&quot;);<br/>
  softmax_layer_ = LayerRegistry<Dtype>::CreateLayer(softmax_param);<br/>
  softmax_bottom_vec_.clear();<br/>
  softmax_bottom_vec_.push_back(bottom[0]);<br/>
  softmax_top_vec_.clear();<br/>
  softmax_top_vec_.push_back(&amp;prob_);<br/>
  softmax_layer_-&gt;SetUp(softmax_bottom_vec_, softmax_top_vec_);</p>

<p>has_ignore_label_ =<br/>
    this-&gt;layer_param_.loss_param().has_ignore_label();<br/>
  if (has_ignore_label_) {<br/>
    ignore_label_ = this-&gt;layer_param_.loss_param().ignore_label();<br/>
  }<br/>
  if (!this-&gt;layer_param_.loss_param().has_normalization() &amp;&amp;<br/>
      this-&gt;layer_param_.loss_param().has_normalize()) {<br/>
    normalization_ = this-&gt;layer_param_.loss_param().normalize() ?<br/>
                     LossParameter_NormalizationMode_VALID :<br/>
                     LossParameter_NormalizationMode_BATCH_SIZE;<br/>
  } else {<br/>
    normalization_ = this-&gt;layer_param_.loss_param().normalization();<br/>
  }<br/>
}</p>

<pre><code>可见，在SetUp阶段，创建了内部SoftmaxLayer对象并配置了其输入/输出Blob，然后调用该对象的SetUp函数。


下面看看`SoftmaxWithLossLayer`的前向传播函数：

```c++

template &lt;typename Dtype&gt;
void SoftmaxWithLossLayer&lt;Dtype&gt;::Forward_cpu(
    const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom, const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top) {
  // The forward pass computes the softmax prob values.(内部SoftmaxLayer的前向传播计算)
  softmax_layer_-&gt;Forward(softmax_bottom_vec_, softmax_top_vec_);
  //获得概率密度
  const Dtype* prob_data = prob_.cpu_data();
  //获得标签值
  const Dtype* label = bottom[1]-&gt;cpu_data();
  int dim = prob_.count() / outer_num_;
  int count = 0;
  Dtype loss = 0;
  for (int i = 0; i &lt; outer_num_; ++i) {
    for (int j = 0; j &lt; inner_num_; j++) {
      const int label_value = static_cast&lt;int&gt;(label[i * inner_num_ + j]);
      if (has_ignore_label_ &amp;&amp; label_value == ignore_label_) {
        continue;
      }
      DCHECK_GE(label_value, 0);
      DCHECK_LT(label_value, prob_.shape(softmax_axis_));
      //计算损失函数-log(prob[label])
      loss -= log(std::max(prob_data[i * dim + label_value * inner_num_ + j],
                           Dtype(FLT_MIN)));
      ++count;
    }
  }
  //设置输出Blob值
  top[0]-&gt;mutable_cpu_data()[0] = loss / get_normalizer(normalization_, count);
  if (top.size() == 2) {
    top[1]-&gt;ShareData(prob_);
  }
}


</code></pre>

<p>可见通过内部<code>SoftmaxLayer</code>对象非常简洁。我们再看一下 Backward计算:</p>

<pre><code class="language-c++">
template &lt;typename Dtype&gt;
void SoftmaxWithLossLayer&lt;Dtype&gt;::Backward_cpu(const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top,
    const vector&lt;bool&gt;&amp; propagate_down, const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom) {
  if (propagate_down[1]) {
   //label输入Blob不做反向传播
    LOG(FATAL) &lt;&lt; this-&gt;type()
               &lt;&lt; &quot; Layer cannot backpropagate to label inputs.&quot;;
  }
  if (propagate_down[0]) {
    Dtype* bottom_diff = bottom[0]-&gt;mutable_cpu_diff();
    const Dtype* prob_data = prob_.cpu_data();
    //将概率密度拷贝输入Blob的diff域
    caffe_copy(prob_.count(), prob_data, bottom_diff);
    const Dtype* label = bottom[1]-&gt;cpu_data();
    int dim = prob_.count() / outer_num_;
    int count = 0;
    for (int i = 0; i &lt; outer_num_; ++i) {
      for (int j = 0; j &lt; inner_num_; ++j) {
        const int label_value = static_cast&lt;int&gt;(label[i * inner_num_ + j]);
        if (has_ignore_label_ &amp;&amp; label_value == ignore_label_) {
          for (int c = 0; c &lt; bottom[0]-&gt;shape(softmax_axis_); ++c) {
            bottom_diff[i * dim + c * inner_num_ + j] = 0;
          }
        } else {
        //在输入Blob的diff域，计算当前槪率密度与理想概率密度(label 对应类别概率为1,其他类别 概肀为0)之差，实现误差反向传播
          bottom_diff[i * dim + label_value * inner_num_ + j] -= 1;
          ++count;
        }
      }
    }
    // Scale gradient(适当的缩放)
    Dtype loss_weight = top[0]-&gt;cpu_diff()[0] /
                        get_normalizer(normalization_, count);
    caffe_scal(prob_.count(), loss_weight, bottom_diff);
  }
}
</code></pre>

<p>通过对Caffe损失层的研究，我们了解到，前向传播阶段数据逐层传播，到损失层计算预测概率密度和损失函数；而反向传播阶段则从损失层开始，由预测概率密度与理想概率密度(这就是有监督学习的佐证)<strong>差值</strong>得到误差（diff),然后将由下一节内容逐层反向传播。我们已经知道一个Blob是由data和diff两部分构成的，如果说数据读取层是data之源，那么损失层就是diff之源。</p>

<h2 id="toc_0">反向传播的实现</h2>

<p>Caffe Net数据结构中的&#39;Backward函数具体的声明和实现文件为<code>net.hpp</code>和<code>net.cpp</code>:</p>

<pre><code class="language-c++">//从第start层反向传播到达第end层
template &lt;typename Dtype&gt;
void Net&lt;Dtype&gt;::BackwardFromTo(int start, int end) {
  CHECK_GE(end, 0);
  CHECK_LT(start, layers_.size());
  for (int i = start; i &gt;= end; --i) {
    for (int c = 0; c &lt; before_backward_.size(); ++c) {
      before_backward_[c]-&gt;run(i);
    }
    if (layer_need_backward_[i]) {
    //遍历每个居，调用相应的Backward函数
      layers_[i]-&gt;Backward(
          top_vecs_[i], bottom_need_backward_[i], bottom_vecs_[i]);
      if (debug_info_) { BackwardDebugInfo(i); }
    }
    for (int c = 0; c &lt; after_backward_.size(); ++c) {
      after_backward_[c]-&gt;run(i);
    }
  }
}

//从第start层幵始到第一层的反向传播过程
template &lt;typename Dtype&gt;
void Net&lt;Dtype&gt;::BackwardFrom(int start) {
  BackwardFromTo(start, 0);
}

//从最后一层开始到第end层的反向传播过程
template &lt;typename Dtype&gt;
void Net&lt;Dtype&gt;::BackwardTo(int end) {
  BackwardFromTo(layers_.size() - 1, end);
}

//整个网络的反向传播过程
template &lt;typename Dtype&gt;
void Net&lt;Dtype&gt;::Backward() {
  BackwardFromTo(layers_.size() - 1, 0);
  if (debug_info_) {
  //如果打幵了调试信息开关(在prototxt中设定），则计算所有权值的data/diff的L1、L2范数，监控其变化情况，避免发散
    Dtype asum_data = 0, asum_diff = 0, sumsq_data = 0, sumsq_diff = 0;
    for (int i = 0; i &lt; learnable_params_.size(); ++i) {
      asum_data += learnable_params_[i]-&gt;asum_data();
      asum_diff += learnable_params_[i]-&gt;asum_diff();
      sumsq_data += learnable_params_[i]-&gt;sumsq_data();
      sumsq_diff += learnable_params_[i]-&gt;sumsq_diff();
    }
    const Dtype l2norm_data = std::sqrt(sumsq_data);
    const Dtype l2norm_diff = std::sqrt(sumsq_diff);
    LOG(ERROR) &lt;&lt; &quot;    [Backward] All net params (data, diff): &quot;
               &lt;&lt; &quot;L1 norm = (&quot; &lt;&lt; asum_data &lt;&lt; &quot;, &quot; &lt;&lt; asum_diff &lt;&lt; &quot;); &quot;
               &lt;&lt; &quot;L2 norm = (&quot; &lt;&lt; l2norm_data &lt;&lt; &quot;, &quot; &lt;&lt; l2norm_diff &lt;&lt; &quot;)&quot;;
  }
}

//更新权值函数，在反向传播结束后调用
template &lt;typename Dtype&gt;
void Net&lt;Dtype&gt;::Update() {
  for (int i = 0; i &lt; learnable_params_.size(); ++i) {
  //调用内部Blob的Update()函数，具体计算为data = data - diff
    learnable_params_[i]-&gt;Update();
  }
}

//权值diff清零
template &lt;typename Dtype&gt;
void Net&lt;Dtype&gt;::ClearParamDiffs() {
  for (int i = 0; i &lt; learnable_params_.size(); ++i) {
    Blob&lt;Dtype&gt;* blob = learnable_params_[i];
    switch (Caffe::mode()) {
    case Caffe::CPU:
      caffe_set(blob-&gt;count(), static_cast&lt;Dtype&gt;(0),
                blob-&gt;mutable_cpu_diff());
      break;
    case Caffe::GPU:
#ifndef CPU_ONLY
      caffe_gpu_set(blob-&gt;count(), static_cast&lt;Dtype&gt;(0),
                    blob-&gt;mutable_gpu_diff());
#else
      NO_GPU;
#endif
      break;
    }
  }
}

</code></pre>

<p>到此,caffe基本的backward反向传播过程就清楚了,这样对于设计更复杂的有监督学习算法具有指导意义。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[第九条 以"类族模式"隐藏实现细节]]></title>
    <link href="https://lockxmonk.github.io/14991530470817.html"/>
    <updated>2017-07-04T15:24:07+08:00</updated>
    <id>https://lockxmonk.github.io/14991530470817.html</id>
    <content type="html"><![CDATA[
<p>&quot;类族&quot;(class cluster,也叫类簇)是一种很有用的模式(pattern),可以隐藏&quot;抽象基类&quot;(abstract base class)背后的实现细节.</p>

<p>Objective-C的系统框架中普遍使用此模式。比如，iOS的用户界面框架（user interface framework) UIKit中就有一个名为<code>UIButton</code>的类。想创建按钮，需<br/>
要调用下面这个“类方法”（class method):</p>

<pre><code class="language-objc">+ (UIButton*)buttonWithType:(UIButtonType)type;

</code></pre>

<p>该方法所返回的对象，其类型取决于传入的按钮类型（button type)。然而，不管返回什么类型的对象，它们都继承自同一个基类：<code>UIButton</code>。这么做的意义在于：<strong>UIButton类的使用者无须关心创建出来的按钮具体属于哪个子类，也不用考虑按钮的绘制方式等实现细节。</strong>使用者只需明白如何创建按钮，如何设置像“标题”（title)这样的属性，如何增加触摸动作的目标对象等问题就好。</p>

<p><font color=red>我们使用&quot;类簇&quot;,是为了可以灵活应对多个类，将它们的实现细节隐藏在抽象基类后面，以保持接口简洁。用户无须自己创建子类实例，只需调用基类方法来创建即可。</font></p>

<h2 id="toc_0">创建类簇</h2>

<p>我们现在来看一个样例学习创建类簇.假设有一个处理雇员的类，每个雇员都有“名字”和<br/>
“薪水”这两个属性，管理者可以命令其执行日常工作。但是，各种雇员的工作内容却不同。经理在带领雇员做项目时，无须关心每个人如何完成其工作，仅需指示其开工即可。</p>

<p>首先要定义抽象类:</p>

<pre><code class="language-objc">typedef NS_ENUM(NSUInteger, EOCEmployeeType) {
    EOCEmployeeTypeDeveloper,
    EOCEmployeeTypeDesigner,
    EOCEmployeeTypeFinance,
}；

@interface EOCEmployee : NSObject

@property (copy) NSString *name;
@property NSUInteger salary;

// Helper for creating Employee objects
+ (EOCEmployee*)employeeWithType:(EOCEmployeeType)type;
//Make Employees do their respective day1s work
- (void)doADaysWork;

@end

@implementation EOCEmployee
+ (EOCEmployee*)employeeWithType:(EOCEmployeeType)type {
    switch (type) {
        case EOCEmployeeTypeDeveloper:
            return [EOCEmployeeDeveloper new];
            break;
        case EOCEmployeeTypeDesigner:
            return (EOCEmployeeDesigner new];
            break;
        case EOCEmployeeTypeFinance:
            return (EOCEmployeeFinance new];
            break;
        }
}
-(void)doADaysWork {
    // Subclasses implement this.
}

@end 

</code></pre>

<p>每个&quot;实体子类&quot;（concrete subclass) 都从基类继承而来。例如:</p>

<pre><code class="language-objc">
@interface EOCEmployeeDeveloper : EOCEmployee
@end

@implementation EOCEmployeeDeveloper

-(void)doADaysWork {    
    [self writeCode];
}

@end

</code></pre>

<p>在本例中，基类实现了一个“类方法”，该方法根据待创建的雇员类别分配好对应的雇员类实例。这种“工厂模式”（Factory pattern)是创建类族的办法之一。</p>

<p>OC这门语言没有办法致命某个基类是&quot;抽象的&quot;(abstract).于是,开发者通常会在文档中写明类的用法。这种情况下，基类接口一般都没有名为init的成员方法，这暗<br/>
示该类的实例也许不应该由用户直接创建。还有一种办法可以确保用户不会使用基类实例,<br/>
那就是在基类的doADaysWork方法中拋出异常。然而这种做法相当极端，很少有人用。</p>

<p>如果对象所属的类位于某个类族中，那么在査询其类型信息（introspection)时就要当心了（参见第14条)。你可能觉得自己创建了某个类的实例，然而实际上创建的却是其子类的实例。在 <code>Employee</code> 这个例子中，<code>[employee isMemberOfClass:[EOCEmployee class]]</code>似乎会返回YES，但实际上返回的却是NO,因为<code>employee</code>并非Employee类的实例，而是其某个子类的实例。</p>

<h2 id="toc_1">Cocoa里的类簇</h2>

<p>系统框架中有许多类族。大部分<code>collection</code>类都是某个类簇中的抽象基类,例如<code>NSArray</code>与其可变版本<code>NSMutableArray</code>。这样看来，实际上有两个抽象基类，一个用于不可变数组，另一个用于可变数组。尽管具备公共接口的类有两个，但仍然可以合起来算作一个类族(传统类簇模式中,通常只有一个类具备&quot;公共接口&quot;,就是抽象基类)。<strong>不可变的类定义了对所有数组都通用的方法，而可变的类则定义了那些只适用于可变数组的方法。</strong>两个类共属同一类族，这意味着二者在实现各自类型的数组时可以共用实现代码，此外，还能够把可变数组复制为不可变数组，反之亦然。</p>

<p>像NSArray这样的类的背后其实是个类族（对于大部分collection类而言都是这样)，明白这一点很重要，否则就可能会写出下面这种代码：</p>

<pre><code class="language-objc">
id maybeAnArray = /* ••• */;
if ([maybeAnArray class) == [NSArray class]) {
&quot;Will never be hit
}

</code></pre>

<p>你要是知道<strong>NSArray是个类族</strong>，那就会明白上述代码错在哪里：其中的<code>if</code>语句永远不可能为真。[maybeAnArray class]所返回的类绝不可能是NSArray类本身，因为由NSArray的初始化方法所返回的那个实例其类型是隐藏在类族公共接口（public facade)后面的某个内部类型（internal type)。</p>

<p>不过，仍然有办法可以判断出某个实例所属的类是否位于类族之中。我们不用刚才那种写法，而是改用类型信息查询方法（introspectionmethod)。本书第14条解释了这些方法的用法。若想判断某对象是否位于类族中，<strong>不要直接检测两个“类对象”是否等同，而应该采用下列代码</strong>：</p>

<pre><code class="language-objc">id maybeAnArray = /* ••• */;
if ([maybeAnArray isKindOfClass:[NSArray class])) {
    &quot;Will be hit&quot;
}
</code></pre>

<p>我们经常需要向类族中新增实体子类，不过这么做的时候得留心。在Employee这个例子中，若是没有“工厂方法”（factory method)的源代码，那就无法向其中新增雇员类别了。然而对于Cocoa中NSArray这样的类族来说，还是有办法新增子类的，但是需要遵守几条规则。这几条规则如下。</p>

<ul>
<li><p>子类应该继承自类族中的抽象基类。<br/>
若要编写NSArray类族的子类，则需令其继承自不可变数组的基类或可变数组的基类。</p></li>
<li><p>子类应该定义自己的数据存储方式。<br/>
开发者编写NSArray子类时，经常在这个问题上受阻。子类必须用一个实例变量来存放数组中的对象。这似乎与大家预想的不同，我们以为NSArray自己肯定会保存那些对象，所以在子类中就无须再存一份了。但是大家要记住，<mark>NSArray本身只不过是包在其他隐藏对象外面的壳，它仅仅定义了所有数组都需具备的一些接口。对于这个自定义的数组子类来说，可以用NSArray来保存其实例</mark>。</p></li>
<li><p>子类应当覆写超类文档中指明需要覆写的方法。<br/>
在每个抽象基类中，都有一些子类必须覆写的方法。比如说，想要编写NSArray的子<br/>
类，就需要实现<code>count</code>及<code>“objectAtlndex:”</code>方法。像<code>lastObject</code>这种方法则无须实现，因为基类可以根据前两个方法实现出这个方法。</p></li>
</ul>

<p>在类族中实现子类时所需遵循的规范一般都会定义于基类的文档之中，编码前应该先看看.</p>

<h2 id="toc_2">要点</h2>

<ul>
<li>类族模式可以把实现细节隐藏在一套简单的公共接口后面。</li>
<li>系统框架中经常使用类族。</li>
<li>从类族的公共抽象基类中继承子类时要当心，若有开发文档，则应首先阅读。</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Caffe反向传播计算]]></title>
    <link href="https://lockxmonk.github.io/14991304296690.html"/>
    <updated>2017-07-04T09:07:09+08:00</updated>
    <id>https://lockxmonk.github.io/14991304296690.html</id>
    <content type="html"><![CDATA[
<ul>
<li>
<a href="#toc_0">反向传播的特点</a>
</li>
<li>
<a href="#toc_1">损失函数</a>
<ul>
<li>
<a href="#toc_2">算法描述</a>
</li>
<li>
<a href="#toc_3">参数描述</a>
</li>
<li>
<a href="#toc_4">源码分析</a>
</li>
</ul>
</li>
</ul>


<p>反向传播对电脑的计算能力要求很高,所以反向传播过程只有在训练环境下才需要计算,由于消耗时间较长,对计算资源要求较高,一般为离线服务.</p>

<h2 id="toc_0">反向传播的特点</h2>

<p>CNN进行前向传播阶段，依次调用每个<code>Layer</code>的<code>Forward</code>函数，得到逐层的输出，<code>最后一层与目标函数比较得到损失函数，计算误差更新值，通过反向传播路径逐层到达第一层</code>，<strong>所有权值层在反向传播结束后一起更新</strong>。</p>

<h2 id="toc_1">损失函数</h2>

<p><mark>损失层(Loss Layer)是CNN的终点</mark>，接受两个Blob作为输入，其中一个为CNN的预测值;另一个是真实标签。损失层则将这两个输入进行一系列运算，得到当前网络的损失函数(Loss Function), —般记为\(L(\theta)\)，其中\(\theta\)表示当前网络权值构成的向量空间。机器学习的目的是在权值空间中找到让损失函数\(L(\theta)\)最小的权值\(\theta_{opt}\),可以采用一系列最优化方法（如后面将会介绍的SGD方法)逼近权值\(\theta_{opt}\)</p>

<p><font color=red>损失函数是在前向传播计算中得到的，同时也是反向传播的起点.</font></p>

<h3 id="toc_2">算法描述</h3>

<p>Caffe中实现了多种损失层，分别用于不同场合。其中<code>SoftmaxWithLossLayer</code>实现了<code>Softmax+交叉熵</code>损失函数计算过程，适用于单label的分类问题：另外还有欧式损失函数（用于回归问题）、<code>Hinge</code>损失函数（最大间隔分类，SVM)、<code>Sigmoid+交叉熵</code>损失函数（用于多属性/多分类问题）等。今天我们只关注最基本的<code>SoftmaxWithLossLayer</code>,其他损失层的算法可以直接看Caffe相应源码。</p>

<p>假设有K个类别,Softmax计算过程为:</p>

<p>\[<br/>
Softmax(a_i) = \frac{exp(a_i)}{\sum_j{exp(a_i)}} ,i=0,1,2,...K-1<br/>
\]</p>

<p><strong>Softmax的结果相当于输入图像被分到每个标签的概率分布。根据高等数学知识，该函数是单调增函数，即输入值越大，输出也越大，输入图像属于该标签的概率就越大。</strong></p>

<p>对Softmax的结果计算交叉熵分类损失函数为：</p>

<p>\[<br/>
L(\theta) = -{\frac{1}{N}}\sum_ilog[Softmax(a_k)], i=0,1,2,...N-1<br/>
\]</p>

<p>其中,k为真实标签值，N为一个批量的大小.</p>

<blockquote>
<p>理想的分类器应当是除了真实标签的概率为1,其余标签概率均为0,这样计算得到其损失函数为<code>-ln(1) =0</code>损失函数越大，说明该分类器在真实标签上分类概率越小，性能也就越差,一个非常差的分类器，可能在真实标签上的分类概率接近于0,那么损失函数就接近于正无穷,我们称为训练发散，需要调小学习速率,在ImageNet-1000分类问题中，初始状态为均匀分布,每个类别的分类概率均为0.001，故此时计算损失函数值为-ln(O.OO1) = ln(1000) = 6.907755... 经常有同学问，“我的loss为什么总是在6.9左右（该现象被称为6.9高原反应），训练了好久都不下降呢？”说明还都没有训练收敛的迹象,尝试调大学习速率,或者修改权值初始化方式.</p>
</blockquote>

<h3 id="toc_3">参数描述</h3>

<p>先看一下<code>caffe.proto</code>,找到有关<code>Softmax</code>的消息定义:</p>

<pre><code class="language-protobuf">
// Message that stores parameters used by SoftmaxLayer, SoftmaxWithLossLayer
message SoftmaxParameter {
  enum Engine {
    DEFAULT = 0;
    CAFFE = 1;
    CUDNN = 2;  //使用cudnn引擎计算
  }
  optional Engine engine = 1 [default = DEFAULT]; // 默认为 0 

  // The axis along which to perform the softmax -- may be negative to index
  // from the end (e.g., -1 for the last axis).
  // Any other axes will be evaluated as independent softmaxes.
  // axis为可选参数，指定沿哪个维度计算Softmax,可以是负数，表示从后向前索引
  optional int32 axis = 2 [default = 1];
}

</code></pre>

<h3 id="toc_4">源码分析</h3>

<p>损失层的基类声明于<code>include/caffe/layers/loss_layers.hpp</code>中：</p>

<pre><code class="language-c++">/**
 * @brief An interface for Layer%s that take two Blob%s as input -- usually
 *        (1) predictions and (2) ground-truth labels -- and output a
 *        singleton Blob representing the loss.
 *
 * LossLayers are typically only capable of backpropagating to their first input
 * -- the predictions.
 */
 
 
 //损失层的鼻祖类，派生于Layer
template &lt;typename Dtype&gt;
class LossLayer : public Layer&lt;Dtype&gt; {
 public:
 //显式抅造函数
  explicit LossLayer(const LayerParameter&amp; param)
     : Layer&lt;Dtype&gt;(param) {}
//层配置函数
  virtual void LayerSetUp(
      const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom, const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top);
//变形函数
  virtual void Reshape(
      const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom, const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top);
//接受沔个Blob作为输入
  virtual inline int ExactNumBottomBlobs() const { return 2; }

  /**
   * @brief For convenience and backwards compatibility, instruct the Net to
   *        automatically allocate a single top Blob for LossLayers, into which
   *        they output their singleton loss, (even if the user didn&#39;t specify
   *        one in the prototxt, etc.).
   */
   //为了方便和后向兼容，指导Net为损失层自动分配单个输出Blob.损失层则会将计算结果L(θ)保存在这里
  virtual inline bool AutoTopBlobs() const { return true; }
  //只有一个输出Blob
  virtual inline int ExactNumTopBlobs() const { return 1; }
  /**
   * We usually cannot backpropagate to the labels; ignore force_backward for
   * these inputs.
   */
  virtual inline bool AllowForceBackward(const int bottom_index) const {
    return bottom_index != 1;
  }
};

</code></pre>

<p>用来计算 <code>Softmax</code> 损失函数的层 <code>SoftmaxLayer</code> 声明在 <code>include/caffe/layers/softmaxlayer.hpp</code>中：</p>

<pre><code class="language-c++">/**
 * @brief Computes the softmax function.
 *
 * TODO(dox): thorough documentation for Forward, Backward, and proto params.
 */
 
 //SoftmaxLayer直接派生于Layer
template &lt;typename Dtype&gt;
class SoftmaxLayer : public Layer&lt;Dtype&gt; {
 public:
 //显示构造函数
  explicit SoftmaxLayer(const LayerParameter&amp; param)
      : Layer&lt;Dtype&gt;(param) {}
//变形函数
  virtual void Reshape(const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,
      const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top);
//返回类名字符串
  virtual inline const char* type() const { return &quot;Softmax&quot;; }
  //该层接受一个输入BLOB,传生一个输出Blob
  virtual inline int ExactNumBottomBlobs() const { return 1; }
  virtual inline int ExactNumTopBlobs() const { return 1; }

 protected:
 //前向传播函数
  virtual void Forward_cpu(const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,
      const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top);
  virtual void Forward_gpu(const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,
      const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top);
  //反向传播函数
  virtual void Backward_cpu(const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top,
      const vector&lt;bool&gt;&amp; propagate_down, const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom);
  virtual void Backward_gpu(const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top,
     const vector&lt;bool&gt;&amp; propagate_down, const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom);
//计算参数
  int outer_num_;
  int inner_num_;
  int softmax_axis_;
  /// sum_multiplier is used to carry out sum using BLAS(利用BLAS计算求和)
  Blob&lt;Dtype&gt; sum_multiplier_;
  /// scale is an intermediate Blob to hold temporary results.(用来临时存放中间结果的Blob)
  Blob&lt;Dtype&gt; scale_;
};

</code></pre>

<p>SoftmaxLayer实现在<code>src/caffe/layers/softmax_layer.cpp</code>中，我们深入内部来看一下具体实现：</p>

<pre><code class="language-c++">//变形函数
template &lt;typename Dtype&gt;
void SoftmaxLayer&lt;Dtype&gt;::Reshape(const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,
      const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top) {
//获得正确的维度索引
  softmax_axis_ =
      bottom[0]-&gt;CanonicalAxisIndex(this-&gt;layer_param_.softmax_param().axis());
//是输出blob与输入blob形状相同
  top[0]-&gt;ReshapeLike(*bottom[0]);
  //sum_multiplier_这里都是1，用于辅助计算，可以看作一个行向量，或者行数为1的矩阵 类似于sum_multiplier_.Reshape(1, bottom[0]-&gt;channels(),bottom[0]-&gt;height(), bottom[0]-&gt;width());  
  vector&lt;int&gt; mult_dims(1, bottom[0]-&gt;shape(softmax_axis_));
  sum_multiplier_.Reshape(mult_dims);
  Dtype* multiplier_data = sum_multiplier_.mutable_cpu_data();
  //乘子初始化为1
  caffe_set(sum_multiplier_.count(), Dtype(1), multiplier_data);
  outer_num_ = bottom[0]-&gt;count(0, softmax_axis_);
  inner_num_ = bottom[0]-&gt;count(softmax_axis_ + 1);
  vector&lt;int&gt; scale_dims = bottom[0]-&gt;shape();
  scale_dims[softmax_axis_] = 1;
  //初始化scale_的形状
  scale_.Reshape(scale_dims);
}

//前向计算，得到Softmax(a_k}值
template &lt;typename Dtype&gt;
void SoftmaxLayer&lt;Dtype&gt;::Forward_cpu(const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,
    const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top) {
    
//获得输入/输出Blob数据指针
  const Dtype* bottom_data = bottom[0]-&gt;cpu_data();
  Dtype* top_data = top[0]-&gt;mutable_cpu_data();
  //中间临时值数据指针
  Dtype* scale_data = scale_.mutable_cpu_data();
  int channels = bottom[0]-&gt;shape(softmax_axis_);
  int dim = bottom[0]-&gt;count() / outer_num_; //总的类别数目
  caffe_copy(bottom[0]-&gt;count(), bottom_data, top_data); //将输入拷贝到输出缓冲区
  // We need to subtract the max to avoid numerical issues, compute the exp,
  // and then normalize.(遍历bottom_data查找最大值，存入scale_data)
  for (int i = 0; i &lt; outer_num_; ++i) {
    // initialize scale_data to the first plane(初始化scale_data为bottom_data首元素)
    caffe_copy(inner_num_, bottom_data + i * dim, scale_data);
    for (int j = 0; j &lt; channels; j++) {
      for (int k = 0; k &lt; inner_num_; k++) {
        scale_data[k] = std::max(scale_data[k],
            bottom_data[i * dim + j * inner_num_ + k]);
      }
    }
    // subtraction(输出缓冲区减去最大值a_k = a_k- max(a_i))
    caffe_cpu_gemm&lt;Dtype&gt;(CblasNoTrans, CblasNoTrans, channels, inner_num_,
        1, -1., sum_multiplier_.cpu_data(), scale_data, 1., top_data);
    // exponentiation(求指数项exp(a_k))
    caffe_exp&lt;Dtype&gt;(dim, top_data, top_data);
    // sum after exp(累加求和1 + exp(a_k)，存放在scale_data中)
    caffe_cpu_gemv&lt;Dtype&gt;(CblasTrans, channels, inner_num_, 1.,
        top_data, sum_multiplier_.cpu_data(), 0., scale_data);
    // division 求Softmax值，即exp(a_k)/(1 + exp(a_k))
    for (int j = 0; j &lt; channels; j++) {
    // top_data = top_data / scale_data
      caffe_div(inner_num_, top_data, scale_data, top_data);
      // 加偏移跳转指针
      top_data += inner_num_;
    }
  }
}
//反向传播,与求导有关
template &lt;typename Dtype&gt;
void SoftmaxLayer&lt;Dtype&gt;::Backward_cpu(const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top,
    const vector&lt;bool&gt;&amp; propagate_down,
    const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom) {
//获得data,diff指针
  const Dtype* top_diff = top[0]-&gt;cpu_diff();
  const Dtype* top_data = top[0]-&gt;cpu_data();
  Dtype* bottom_diff = bottom[0]-&gt;mutable_cpu_diff();
  Dtype* scale_data = scale_.mutable_cpu_data();
  int channels = top[0]-&gt;shape(softmax_axis_);
  int dim = top[0]-&gt;count() / outer_num_;
  caffe_copy(top[0]-&gt;count(), top_diff, bottom_diff);
  for (int i = 0; i &lt; outer_num_; ++i) {
    // compute dot(top_diff, top_data) and subtract them from the bottom diff
    for (int k = 0; k &lt; inner_num_; ++k) {
      scale_data[k] = caffe_cpu_strided_dot&lt;Dtype&gt;(channels,
          bottom_diff + i * dim + k, inner_num_,
          top_data + i * dim + k, inner_num_);
    }
    // subtraction
    caffe_cpu_gemm&lt;Dtype&gt;(CblasNoTrans, CblasNoTrans, channels, inner_num_, 1,
        -1., sum_multiplier_.cpu_data(), scale_data, 1., bottom_diff + i * dim);
  }
  // elementwise multiplication(逐点相乘)
  caffe_mul(top[0]-&gt;count(), bottom_diff, top_data, bottom_diff);
}


</code></pre>

<p>到这里我们就已经了解了<code>Softmax</code>函数的计算过程,后面我们在来看<code>SoftmaxWithLossLayer</code>的实现.</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[第八条:理解"对象同等性"这一概念]]></title>
    <link href="https://lockxmonk.github.io/14990683410396.html"/>
    <updated>2017-07-03T15:52:21+08:00</updated>
    <id>https://lockxmonk.github.io/14990683410396.html</id>
    <content type="html"><![CDATA[
<p>根据“等同性”（equality)来比较对象是一个非常有用的功能。不过，按照<code>==</code>操作符比较出来的结果未必是我们想要的，因为该操作比较的是两个<mark>指针本身</mark>，而不是其所指的对象。应该使用NSObject协议中声明的<strong><mark>“isEqual”</mark></strong>：方法来判断两个对象的等同性。一般来说,两个类型不同的对象总是不相等的（unequal)。某些对象提供了特殊的“等同性判定方法”(equality-checking method),<strong>如果已经知道两个受测对象都属于同一个类，那么就可以使用这种方法</strong>。以下述代码为例：</p>

<pre><code class="language-objc">
NSString *foo = @&quot;Badger 123&quot;;
NSString *bar = [NSStringstringWithFormat: @fTBadger %i&quot;, 123】；
BOOL equalA = (foo == bar); //&lt; equal A - NO
BOOL equalB = [foo isEqual: bar ] ; //&lt; equalB = YES
BOOL equalC = [foo isEqualToString:bar]; //&lt; equalC = YES

</code></pre>

<p>上面可以看到<code>==</code>与等同性判断方法之间的差别。<code>NSString</code>类实现了一个自己独有的等同性判断方法，名叫<code>“isEqualToString:”</code>。传递给该方法的对象必须是<code>NSString</code>,否则结果未定义（undefined)。调用该方法比调用<code>“isEqual”</code>方法快，后者还要执行额外的步骤，因为它不知道受测对象的类型(前者指使用NSString所以快些)。</p>

<p><code>NSObject</code>协议中有两个用于判断等同性的关键方法：</p>

<pre><code class="language-objc">
- (BOOL) isEqual: (id) object;
- (NSUInteger) hash;

</code></pre>

<p><code>NSObject</code>类对这两个方法的默认实现是：当且仅当其<strong>“指针值&quot;（pointer value)(内存地址)完全相等时，这两个对象才相等。</strong>若想在自定义的对象中正确覆写这些方法，就必须先理解其约定<br/>
(contract)。如果<code>“isEqual:”</code>方法判定两个对象相等，那么其<code>hash</code>方法也必须返回同一个值。但是，如果两个对象的hash方法返回同一个值，那么“isEqual:”方法未必会认为两者相等。</p>

<p>比如有下面这个类：</p>

<pre><code class="language-objc">
@interface EOCPerson : NSObject
@property (nonatomic, copy) NSString *firstName;
@property (nonatomic, copy) NSString *lastName;
@property (nonatomic, assign) NSUInteger age;
@end

</code></pre>

<p>我们认为，如果两个<code>EOCPerson</code>的所有字段均相等，那么这两个对象就相等。于是<code>“isEqual:”</code>方法可以写成：</p>

<pre><code class="language-objc">
-(BOOL)isEqual:(id)object {
    if (self == object) return YES;
    if ( [self class] != [object class]) return NO;
    EOCPerson ^otherPerson = (EOCPerson*)object;
    if (! [_firstName isEqualToString:otherPerson.firstName))
    return NO;
    if (![_lastName isEqualToString:otherPerson.lastName])
    return NO;
    if (_age != otherPerson.age)
    return NO;
    return YES;
}

</code></pre>

<p>首先，直接判断两个指针是否相等。若相等，则其均指向同一对象，所以受测的对象也必定相等。接下来，比较两对象所属的类。若不属于同一个类，则两对象不相等。<code>EOCPerson</code>对象当然不可能与<code>EOCDog</code>对象相等。不过，有时我们可能认为：一个EOCPerson实例可以与其子类（比如EOCSmithPerson)实例相等。在继承体系（inheritance hierarchy)中判断等同属性时,经常遭遇此类问题.所以实现&quot;isEqual:&quot;方法时要考虑到这种情况。最后，检测每个属性是否相等。只要其中有不相等的属性，就判定两对象不等，否则两对象相等。</p>

<p>接下来,我们实现hash方法.回想一下，根据等同性约定：若两对象相等，则其哈希码(hash)也相等，但是两个哈希码相同的对象却未必相等。这是能否正确覆写“isEqual”方法的关键所在。下面这种写法完全可行：</p>

<pre><code class="language-objc">
-(NSUInteger)hash {
    return 1337;
}

</code></pre>

<p>在<code>collection</code>中使用这种对象将产生性能问题，因为collection在检索哈希表（hash table)时，会用对象的哈希码做索引。假如某个<code>collection</code>是用<code>set</code>实现的，那么<code>set</code>可能会根据哈希码把对象分装到不同的数组中。在向<code>set</code>中添加新对象时，要根据其哈希码找到与之相关的那个数组，依次检査其中各个元素，看数组中已有的对象是否和将要添加的新对象相等。如果相等，那就说明要添加的对象已经在set里面了。如果令每个对象都返回相同的哈希码，那么在<code>set</code>中已有<code>1000000</code>个对象的情况下，若是继续向其中添加对象，则需将这<code>1 000000</code>个对象全部扫描一遍。</p>

<p>我们看另一种计算哈希码的方法:</p>

<pre><code class="language-objc">
-(NSUInteger)hash {
    NSUInteger firstNameHash = [_firstName hash];
    NSUInteger lastNameHash = [_lastName hash];
    NSUInteger ageHash = _age;
    return firstNameHash ^ lastNameHash ^ ageHash;
}

</code></pre>

<p>这种做法既能保持较高效率，又能使生成的哈希码至少位于一定范围之内，而不会过于频繁地重复。当然，此算法生成的哈希码还是会碰撞（collision),不过至少可以保证哈希码有多种可能的取值.<strong>编写hash方法时，应该用当前的对象做做实验，以便在减少碰撞频度与降低运算复杂程度之间取舍。</strong></p>

<h2 id="toc_0">特定类所具有的等同性判定方法</h2>

<p>除了刚才提到的<code>NSString</code>之外，<code>NSArray</code>与<code>NSDictionary</code>类也具有特殊的等同性判定方法，前者名为<code>“isEqualToArray:”</code>，后者名为<code>“isEqualToDictionary:”</code>。如果和其相比较的对象不是数组或字典，那么这两个方法会各自抛出异常。由于<code>Objective-C</code>在编译期不做强类型检査（strong type checking),这样容易不小心传入类型错误的对象，因此开发者应该保证所传对象的类型是正确的。</p>

<p>如果我们觉得提供的判断方法不好用,可以自己来写一个,令代码看上<br/>
去更美观、更易读,使自己编写的判定方法更容易读懂，而且不用再检査两个受测对象的类型了。</p>

<p><strong>在编写判定方法时，也应一并覆写“isEqual:”方法。后者的常见实现方式为：如果受测的参数与接收该消息的对象都属于同一个类，那么就调用自已编写的判定方法，否则就交由超类来判断。</strong></p>

<p>例如:</p>

<pre><code class="language-objc">
- (BOOL)isEqualToPerson:(EOCPerson*)otherPerson {
if (self == object) return YES;
    if (! [_firstName isEqualToString:otherPerson.firstName])
        return NO;
    if (![_lastName isEqualToString:otherPerson.lastName])
        return NO;
    if (_age != otherPerson.age)
        return NO;
    return YES;
}

-(BOOL)isEqual:(id)object {
    if ([self class] == [object class]) {
        return [self isEqualToPerson:(EOCPerson*)object];
    } else {
        return [super isEqual:object】；

</code></pre>

<h2 id="toc_1">等同性判定的执行深度</h2>

<p>创建等同性判定方法时，需要决定是根据整个对象来判断等同性，还是仅根据其中几个字段来判断。<code>NSArray</code>的检测方式为先看两个数组所含对象个数是否相同，若相同，则在每个对应位置的两个对象身上调用其<code>“isEqual”</code>方法。如果对应位置上的对象均相等，那么这两个数组就相等，这叫做<strong>“深度等同性判定”（deep equality)。</strong>不过有时候无须将所有数据<br/>
逐个比较，只根据其中部分数据即可判明二者是否等同。</p>

<p>比方说，我们假设<code>EOCPerson</code>类的实例是根据数据库里的数据创建而来，那么其中就可能会含有另外一个属性，此属性是<strong>“唯一标识符&quot;（unique identifier)</strong>,在数据库中用作“主键”</p>

<pre><code class="language-objc">
@property NSUInteger identifier;

</code></pre>

<p>在这种情况下，我们也许只会根据标识符来判断等同性，尤其是在此属性声明为<code>readonly</code>时更应该如此。因为只要两者标识符相同，就肯定表示同一个对象，因而必然相等。<br/>
这样的话，无须逐个比较<code>EOCPerson</code>对象的每条数据，只要标识符相同，就说明这两个对象就是由同一个数据源所创建的，据此我们能够断定，其余数据也必然相同。</p>

<h2 id="toc_2">容器中可变类的等同性</h2>

<p>还有一种情况一定要注意，就是在容器中放入可变类对象的时候。把某个对象放入<code>collection</code>之后，就不应再改变其哈希码了。前面解释过，<code>collection</code>会把各个对象按照其哈希码分装到不同的“箱子数组”中。如果某对象在放入“箱子”之后哈希码又变了，那么其现在所处的这个箱子对它来说就是“错误”的。要想解决这个问题，<strong><mark>需要确保哈希码不是根据对象的“可变部分”（mutable portion)</mark></strong>计算出来的,或是保证放入<code>collection</code>之后就不再改变对象内容了。之后将在第18条中解释为何要将对象做成“不可变的&quot;（immutable)。</p>

<h2 id="toc_3">要点:</h2>

<ul>
<li>若想检测对象的等同性，请提供<code>“isEqual:”</code>与<code>hash</code>方法。</li>
<li>相同的对象必须具有相同的哈希码，但是两个哈希码相同的对象却未必相同。</li>
<li>不要盲目地逐个检测每条属性，而是应该依照具体需求来制定检测方案。</li>
<li>编写hash方法时，应该使用计算速度快而且哈希码碰撞几率低的箅法。</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Net Forward实现]]></title>
    <link href="https://lockxmonk.github.io/14990441879389.html"/>
    <updated>2017-07-03T09:09:47+08:00</updated>
    <id>https://lockxmonk.github.io/14990441879389.html</id>
    <content type="html"><![CDATA[
<p>掌握了上次Net的初始化代码以及方法,我们下面来看一下他的<code>Forward</code>代码:</p>

<pre><code class="language-c++">
template &lt;typename Dtype&gt;
Dtype Net&lt;Dtype&gt;::ForwardFromTo(int start, int end) {
//计算从第start到end层的前向传播过程
  CHECK_GE(start, 0);
  CHECK_LT(end, layers_.size());
  Dtype loss = 0;
  for (int i = start; i &lt;= end; ++i) {
    for (int c = 0; c &lt; before_forward_.size(); ++c) {
      before_forward_[c]-&gt;run(i);
    }
// LOG(ERROR) &lt;&lt; &quot;Forwarding &quot; &lt;&lt;layer_names_[i];
// 调用每个Layer的Forward()函数，得到每层loss
    Dtype layer_loss = layers_[i]-&gt;Forward(bottom_vecs_[i], top_vecs_[i]);
    loss += layer_loss;
    if (debug_info_) { ForwardDebugInfo(i); }
    for (int c = 0; c &lt; after_forward_.size(); ++c) {
      after_forward_[c]-&gt;run(i);
    }
  }
  //返回loss值
  return loss;
}

template &lt;typename Dtype&gt;
Dtype Net&lt;Dtype&gt;::ForwardFrom(int start) {
//计算从start开始到最后一层的前向传播过程
  return ForwardFromTo(start, layers_.size() - 1);
}

template &lt;typename Dtype&gt;
Dtype Net&lt;Dtype&gt;::ForwardTo(int end) {
//计算从第1层到第end层的前向传播过程
  return ForwardFromTo(0, end);
}

template &lt;typename Dtype&gt;
const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; Net&lt;Dtype&gt;::Forward(Dtype* loss) {
//计算整个网络前向传播过程,返回损失值(可选)和网络输出Blob
  if (loss != NULL) {
    *loss = ForwardFromTo(0, layers_.size() - 1);
  } else {
    ForwardFromTo(0, layers_.size() - 1);
  }
  return net_output_blobs_;
}

template &lt;typename Dtype&gt;
const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; Net&lt;Dtype&gt;::Forward(
    const vector&lt;Blob&lt;Dtype&gt;*&gt; &amp; bottom, Dtype* loss) {
    //接受输入Blob作为Net输入，计算前向传播,得到损失值（可选）和网络输出Blob
  LOG_EVERY_N(WARNING, 1000) &lt;&lt; &quot;DEPRECATED: Forward(bottom, loss) &quot;
      &lt;&lt; &quot;will be removed in a future version. Use Forward(loss).&quot;;
  // Copy bottom to net bottoms(直接将输入Blob拷贝到net_input_blobs_中)
  for (int i = 0; i &lt; bottom.size(); ++i) {
    net_input_blobs_[i]-&gt;CopyFrom(*bottom[i]);
  }
  return Forward(loss);
}

</code></pre>

<p>到这里 我们就初步了解了所有的前向传波函数,应该能够在脑海中形成DAG数据流动图,后面学习反向传播过程.</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Net初始化时的三个登记注册函数]]></title>
    <link href="https://lockxmonk.github.io/14988713979681.html"/>
    <updated>2017-07-01T09:09:57+08:00</updated>
    <id>https://lockxmonk.github.io/14988713979681.html</id>
    <content type="html"><![CDATA[
<p>我们已经知道<code>Init()</code>函数完成了非常关键的网络初始化和层初始化操作.虽然代码很长.但是只要抓住几个核心对象,了解其功能并密切关注其动态,即可掌握<code>Init()</code>函数的执行流程和具体意义.</p>

<p>在<code>Init()</code>中调用了<mark>三个登记注册函数</mark>:</p>

<p><strong>AppendTop</strong>:</p>

<pre><code class="language-c++">
// Helper for Net::Init: add a new top blob to the net.
//登记每层输出Blob
template &lt;typename Dtype&gt;
void Net&lt;Dtype&gt;::AppendTop(const NetParameter&amp; param, const int layer_id,
                           const int top_id, set&lt;string&gt;* available_blobs,
                           map&lt;string, int&gt;* blob_name_to_idx) {
  shared_ptr&lt;LayerParameter&gt; layer_param(
      new LayerParameter(param.layer(layer_id)));
  const string&amp; blob_name = (layer_param-&gt;top_size() &gt; top_id) ?
      layer_param-&gt;top(top_id) : &quot;(automatic)&quot;;
  // Check if we are doing in-place computation(检查是否为原位计算)
  if (blob_name_to_idx &amp;&amp; layer_param-&gt;bottom_size() &gt; top_id &amp;&amp;
      blob_name == layer_param-&gt;bottom(top_id)) {
    // In-place computation(是原位计算)
    LOG_IF(INFO, Caffe::root_solver())
        &lt;&lt; layer_param-&gt;name() &lt;&lt; &quot; -&gt; &quot; &lt;&lt; blob_name &lt;&lt; &quot; (in-place)&quot;;
    top_vecs_[layer_id].push_back(blobs_[(*blob_name_to_idx)[blob_name]].get());
    top_id_vecs_[layer_id].push_back((*blob_name_to_idx)[blob_name]);
  } else if (blob_name_to_idx &amp;&amp;
             blob_name_to_idx-&gt;find(blob_name) != blob_name_to_idx-&gt;end()) {
    // If we are not doing in-place computation but have duplicated blobs,
    // raise an error.
    LOG(FATAL) &lt;&lt; &quot;Top blob &#39;&quot; &lt;&lt; blob_name
               &lt;&lt; &quot;&#39; produced by multiple sources.&quot;;
  } else {
    // Normal output.(正常输出)
    if (Caffe::root_solver()) {
      LOG(INFO) &lt;&lt; layer_param-&gt;name() &lt;&lt; &quot; -&gt; &quot; &lt;&lt; blob_name;
    }
    shared_ptr&lt;Blob&lt;Dtype&gt; &gt; blob_pointer(new Blob&lt;Dtype&gt;());
    //新建一个Blob,插入到Net::blobs_最后
    const int blob_id = blobs_.size();
    blobs_.push_back(blob_pointer);
    blob_names_.push_back(blob_name);
    blob_need_backward_.push_back(false);
    if (blob_name_to_idx) { (*blob_name_to_idx)[blob_name] = blob_id; }
    top_id_vecs_[layer_id].push_back(blob_id);
    top_vecs_[layer_id].push_back(blob_pointer.get());
  }
  if (available_blobs) { available_blobs-&gt;insert(blob_name); }
}

</code></pre>

<p><strong>AppendBottom</strong>:</p>

<pre><code class="language-c++">
// Helper for Net::Init: add a new bottom blob to the net.
//登记每层输入Blob
template &lt;typename Dtype&gt;
int Net&lt;Dtype&gt;::AppendBottom(const NetParameter&amp; param, const int layer_id,
    const int bottom_id, set&lt;string&gt;* available_blobs,
    map&lt;string, int&gt;* blob_name_to_idx) {
  const LayerParameter&amp; layer_param = param.layer(layer_id);
  const string&amp; blob_name = layer_param.bottom(bottom_id);
  if (available_blobs-&gt;find(blob_name) == available_blobs-&gt;end()) {
    LOG(FATAL) &lt;&lt; &quot;Unknown bottom blob &#39;&quot; &lt;&lt; blob_name &lt;&lt; &quot;&#39; (layer &#39;&quot;
               &lt;&lt; layer_param.name() &lt;&lt; &quot;&#39;, bottom index &quot; &lt;&lt; bottom_id &lt;&lt; &quot;)&quot;;
  }
  const int blob_id = (*blob_name_to_idx)[blob_name];
  LOG_IF(INFO, Caffe::root_solver())
      &lt;&lt; layer_names_[layer_id] &lt;&lt; &quot; &lt;- &quot; &lt;&lt; blob_name;
  bottom_vecs_[layer_id].push_back(blobs_[blob_id].get());
  bottom_id_vecs_[layer_id].push_back(blob_id);
  available_blobs-&gt;erase(blob_name);
  bool need_backward = blob_need_backward_[blob_id];
  // Check if the backpropagation on bottom_id should be skipped(检查是否可以跳过反向传播)
  if (layer_param.propagate_down_size() &gt; 0) {
    need_backward = layer_param.propagate_down(bottom_id);
  }
  bottom_need_backward_[layer_id].push_back(need_backward);
  return blob_id;
}

</code></pre>

<p><strong>AppendParam</strong>:</p>

<pre><code class="language-c++">
//登记每层权值Blob
template &lt;typename Dtype&gt;
void Net&lt;Dtype&gt;::AppendParam(const NetParameter&amp; param, const int layer_id,
                             const int param_id) {
  const LayerParameter&amp; layer_param = layers_[layer_id]-&gt;layer_param();
  const int param_size = layer_param.param_size();
  string param_name =
      (param_size &gt; param_id) ? layer_param.param(param_id).name() : &quot;&quot;;
  if (param_name.size()) {
    param_display_names_.push_back(param_name);
  } else {
    ostringstream param_display_name;
    param_display_name &lt;&lt; param_id;
    param_display_names_.push_back(param_display_name.str());
  }
  const int net_param_id = params_.size();
  params_.push_back(layers_[layer_id]-&gt;blobs()[param_id]);
  param_id_vecs_[layer_id].push_back(net_param_id);
  param_layer_indices_.push_back(make_pair(layer_id, param_id));
  ParamSpec default_param_spec;
  const ParamSpec* param_spec = (layer_param.param_size() &gt; param_id) ?
      &amp;layer_param.param(param_id) : &amp;default_param_spec;
  if (!param_size || !param_name.size() || (param_name.size() &amp;&amp;
      param_names_index_.find(param_name) == param_names_index_.end())) {
    // This layer &quot;owns&quot; this parameter blob -- it is either anonymous
    // (i.e., not given a param_name) or explicitly given a name that we
    // haven&#39;t already seen.
    //该层拥有权值Blob
    param_owners_.push_back(-1);
    if (param_name.size()) {
      param_names_index_[param_name] = net_param_id;
    }
    const int learnable_param_id = learnable_params_.size();
    learnable_params_.push_back(params_[net_param_id].get());
    learnable_param_ids_.push_back(learnable_param_id);
    has_params_lr_.push_back(param_spec-&gt;has_lr_mult());
    has_params_decay_.push_back(param_spec-&gt;has_decay_mult());
    params_lr_.push_back(param_spec-&gt;lr_mult());
    params_weight_decay_.push_back(param_spec-&gt;decay_mult());
  } else {
    // Named param blob with name we&#39;ve seen before: share params(该层共享权值Blob)
    const int owner_net_param_id = param_names_index_[param_name];
    param_owners_.push_back(owner_net_param_id);
    const pair&lt;int, int&gt;&amp; owner_index =
        param_layer_indices_[owner_net_param_id];
    const int owner_layer_id = owner_index.first;
    const int owner_param_id = owner_index.second;
    LOG_IF(INFO, Caffe::root_solver()) &lt;&lt; &quot;Sharing parameters &#39;&quot; &lt;&lt; param_name
        &lt;&lt; &quot;&#39; owned by &quot;
        &lt;&lt; &quot;layer &#39;&quot; &lt;&lt; layer_names_[owner_layer_id] &lt;&lt; &quot;&#39;, param &quot;
        &lt;&lt; &quot;index &quot; &lt;&lt; owner_param_id;
    Blob&lt;Dtype&gt;* this_blob = layers_[layer_id]-&gt;blobs()[param_id].get();
    Blob&lt;Dtype&gt;* owner_blob =
        layers_[owner_layer_id]-&gt;blobs()[owner_param_id].get();
    const int param_size = layer_param.param_size();
    if (param_size &gt; param_id &amp;&amp; (layer_param.param(param_id).share_mode() ==
                                  ParamSpec_DimCheckMode_PERMISSIVE)) {
      // Permissive dimension checking -- only check counts are the same.
      CHECK_EQ(this_blob-&gt;count(), owner_blob-&gt;count())
          &lt;&lt; &quot;Cannot share param &#39;&quot; &lt;&lt; param_name &lt;&lt; &quot;&#39; owned by layer &#39;&quot;
          &lt;&lt; layer_names_[owner_layer_id] &lt;&lt; &quot;&#39; with layer &#39;&quot;
          &lt;&lt; layer_names_[layer_id] &lt;&lt; &quot;&#39;; count mismatch.  Owner layer param &quot;
          &lt;&lt; &quot;shape is &quot; &lt;&lt; owner_blob-&gt;shape_string() &lt;&lt; &quot;; sharing layer &quot;
          &lt;&lt; &quot;shape is &quot; &lt;&lt; this_blob-&gt;shape_string();
    } else {
      // Strict dimension checking -- all dims must be the same.(严格检查)
      CHECK(this_blob-&gt;shape() == owner_blob-&gt;shape())
          &lt;&lt; &quot;Cannot share param &#39;&quot; &lt;&lt; param_name &lt;&lt; &quot;&#39; owned by layer &#39;&quot;
          &lt;&lt; layer_names_[owner_layer_id] &lt;&lt; &quot;&#39; with layer &#39;&quot;
          &lt;&lt; layer_names_[layer_id] &lt;&lt; &quot;&#39;; shape mismatch.  Owner layer param &quot;
          &lt;&lt; &quot;shape is &quot; &lt;&lt; owner_blob-&gt;shape_string() &lt;&lt; &quot;; sharing layer &quot;
          &lt;&lt; &quot;expects shape &quot; &lt;&lt; this_blob-&gt;shape_string();
    }
    const int learnable_param_id = learnable_param_ids_[owner_net_param_id];
    learnable_param_ids_.push_back(learnable_param_id);
    if (param_spec-&gt;has_lr_mult()) {
      if (has_params_lr_[learnable_param_id]) {
        CHECK_EQ(param_spec-&gt;lr_mult(), params_lr_[learnable_param_id])
            &lt;&lt; &quot;Shared param &#39;&quot; &lt;&lt; param_name &lt;&lt; &quot;&#39; has mismatched lr_mult.&quot;;
      } else {
        has_params_lr_[learnable_param_id] = true;
        params_lr_[learnable_param_id] = param_spec-&gt;lr_mult();
      }
    }
    if (param_spec-&gt;has_decay_mult()) {
      if (has_params_decay_[learnable_param_id]) {
        CHECK_EQ(param_spec-&gt;decay_mult(),
                 params_weight_decay_[learnable_param_id])
            &lt;&lt; &quot;Shared param &#39;&quot; &lt;&lt; param_name &lt;&lt; &quot;&#39; has mismatched decay_mult.&quot;;
      } else {
        has_params_decay_[learnable_param_id] = true;
        params_weight_decay_[learnable_param_id] = param_spec-&gt;decay_mult();
      }
    }
  }
}

</code></pre>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[第七条 在对象内部尽量直接访问实例变量]]></title>
    <link href="https://lockxmonk.github.io/14988067800935.html"/>
    <updated>2017-06-30T15:13:00+08:00</updated>
    <id>https://lockxmonk.github.io/14988067800935.html</id>
    <content type="html"><![CDATA[
<p>在对象之外访问实例变量时，总是应该通过<strong>属性</strong>来做,然而在对象内部访问实例变量时,除了几种特殊情况之外，<font color=red><strong>强烈建议大家在读取实例变量的时候采用<mark>直接访问</mark>的形式，而在设置实例变量的时候通过属性来做</strong></font>。</p>

<p>下面举个例子:</p>

<pre><code class="language-objc">
@interface EOCPerson : NSObject
@property (nonatomic, copy) NSString *firstName;
@property (nonatomic, copy) NSString *lastName;

// Convenience for firstName + ” ” 十 lastName:
-(NSString*)fullName;
-(void)setFullName:(NSString*) fullName;
@end

</code></pre>

<p><code>fullName与setFullName</code>这两个“便捷方法”可以这样来实现:</p>

<pre><code class="language-objc">
-(NSString*)fullName {
    return [NSString stringWithFormat: @&quot;%@ %@&quot;,
            self.firstName, self.lastName];
/** The following assumes all full names have exactly 2
*   parts. The method could be rewritten to support more
* exotic names.
*/
-(void)setFullName:(NSString*)fullName {
NSArray *components =
[fullName componentsSeparatedByString:@&quot; &quot;];

self.firstName = [components objectAtIndex: 0];
self.lastName = [components objectAtIndex:1];
}

</code></pre>

<p>然后我们改写上面的例子:</p>

<pre><code class="language-objc">
-(NSString*)fullName {
    return [NSString stringWithFormat: @&quot;%@ %@&quot;,
            _firstName, _lastName];

-(void)setFullName:(NSString*)fullName {
NSArray *components =
[fullName componentsSeparatedByString:@&quot; &quot;];

_firstName = [components objectAtIndex: 0];
_lastName = [components objectAtIndex:1];
}

</code></pre>

<p>这两种写法各有优点和缺点:</p>

<ul>
<li><p>由于不经过Objective-C的<strong>“方法派发” (method dispatch，之后第11条）</strong>步骤，所以直接访问实例变量的速度当然比较快。在这种情况下，编译器所生成的代码会直接访问保存对象实例变量的那块内存。</p></li>
<li><p>直接访问实例变童时，不会调用其“设置方法”,这就绕过了为相关属性所定义的“内<br/>
存管理语义”。比方说，如果在ARC下直接访问一个声明为copy的属性，那么并不<br/>
会拷贝该属性，只会保留新值并释放旧值。</p></li>
<li><p>如果直接访问实例变量，那么不会触发‘键值观测’（Key-Value Observing，KVO)通知。这样做是否会产生问题，还取决于具体的对象行为。</p></li>
<li><p>通过属性来访问有助于排査与之相关的错误，因为可以给“获取方法”和/或“设置<br/>
方法”中新增“断点&quot;（breakpoint),监控该属性的调用者及其访问时机。</p></li>
</ul>

<p>因为各有好处,这里我们就找一个折中方案:<mark>写入实例变量时，通过其“设置方法”来做</mark>，而在<mark>读取实例变量时，则直接访问之</mark>。此办法既能提高读取操作的速度，又能控制对属性的写入操作。之所以要通过“设置方法”来写人实例变量，其首要原因在于，这样做能够确保相关属性的“内存管理语义”得以贯彻。但是，选用这种做法时，需注意几个问题:</p>

<p><strong>第一个要注意的地方就是</strong>，在初始化方法中应该如何设置属性值。这种情况下总是应<br/>
该<mark>直接访问实例变量</mark>，因为子类可能会<strong>“覆写”（override)设置方法</strong>。假设<code>EOCPerson</code>有一个子类叫做<code>EOCSmithPerson</code>，这个子类专门表示那些姓“Smith”的人。该子类可能会覆写<code>lastName</code>属性所对应的设置方法：</p>

<pre><code class="language-objc">
-(void)setLastName:(NSString*)lastName {
    if (![lastName isEqualToString:@&quot;Smith&quot;]){
      [NSException raise:NSInvalidArgumentException
                  format:@&quot;Last name must be Smith&quot;];
}
    self.lastName = lastname; //这里没有直接访问,而是用的点语法.(最好直接访问)
}

</code></pre>

<p>在基类<code>EOCPerson</code>的默认初始化方法中，可能会将姓氏设为空字符串。此时若是通过<br/>
“设置方法”来做，那么<strong>调用的将会是子类的设置方法，从而拋出异常</strong>。但是，某些情况下却又必须在初始化方法中调用设置方法:如果待初始化的实例变量声明在超类中，而我们又无法在子类中直接访问此实例变量的话，那么就需要调用“设置方法”了。</p>

<p><strong>第二个注意问题</strong>是<strong>&quot;惰性初始化&quot;（lazy initialization)</strong>。在这种情况下，必须通过“获取方法”来访问属性，否则，实例变量就永远不会初始化。比方说，<code>EOCPerson</code>类也许会用一个属性来表示人脑中的信息，这个属性所指代的对象相当复杂。由于此属性不常用,而且创建该属性的成本较高，所以，<mark>我们可能会在“获取方法”中对其执行惰性初始化</mark>:</p>

<pre><code class="language-objc">
-(EOCBrain” brain {
    if (!_brain) {
        brain = [Brain new];    //若没有调用获取方法,这句话永远也不会执行,去初始化
    }
    return _brain;

</code></pre>

<p>若没有调用“获取方法”就直接访问实例变量，则会看到尚未设置好的<code>brain</code>,所以说,<br/>
如果使用了“惰性初始化”技术，那么必须通过存取方法来访问<code>brain</code>属性。</p>

<h2 id="toc_0">要点</h2>

<ul>
<li><p>在对象内部读取数据时,应该直接通过实例变量来读，而写入数据时，则应通过属性<br/>
来写。</p></li>
<li><p>在初始化方法及<code>dealloc</code>方法中，总是应该直接通过实例变量来读写数据。</p></li>
<li><p>有时会使用惰性初始化技术配置某份数据,这种情况下，需要通过属性的&quot;获取方法&quot;来读取数据。</p></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Caffe前向传播计算]]></title>
    <link href="https://lockxmonk.github.io/14987856817486.html"/>
    <updated>2017-06-30T09:21:21+08:00</updated>
    <id>https://lockxmonk.github.io/14987856817486.html</id>
    <content type="html"><![CDATA[
<ul>
<li>
<a href="#toc_0">前向传播的特点</a>
</li>
<li>
<a href="#toc_1">前向传播的实现</a>
</li>
<li>
<a href="#toc_2">DAG(有向无环图)构造过程</a>
</li>
</ul>


<p>使用传统的BP算法进行CNN训练时包括两个阶段：前向传播计算（Forward)和反向传播计算（Backward)。今天我们将注意力放在前向传播阶段。</p>

<p>前向传播阶段在实际应用中最常见，<mark><strong>比如大量的在线系统（语音识别、文字识别、图像分类和检索等)都是仅前向传播阶段的应用</strong></mark>;一些嵌入式系统（视觉机器人、无人机、智能语音 机器人）受限于计算资源，仅实现前向传播阶段，而<mark><strong>反向传播计算则由计算性能更强大的服务器完成</strong></mark>.</p>

<h2 id="toc_0">前向传播的特点</h2>

<p>在前向传播阶段，数据源起于数据读取层，经过若干处理层，到达最后一层(可能是损失 层或特征层）。</p>

<p>网络中的权值在前向传播阶段<mark><strong>不发生变化</strong></mark>，可以看作常量。</p>

<p>网络路径是一个<mark>有向无环图（DirectedAcyclineGraph，DAG)</mark>。从最初的节点出发，经历若干处理层，不存在循环结构，因此数据流会直向前推进到达终点。</p>

<p>我们可以使用数据流分析方法对前向传播过程进行研究：</p>

<p>从输入数据集中取一个样本\((X,Y)\),其中X为数据，Y为标签。将X送入网络,逐层计算,得到相应的网络处理输出\(O\)。网络执行的计算可以用公式表达为：<br/>
\[<br/>
O = F_n(...(F_2(F_1(XW_1)W_2)...)W_n)<br/>
\]</p>

<p>其中,\(F_i ,i=1,2,...n\)表示非线性变换，而\(W_i=1,2,…n\),表示各个权值层权值。</p>

<p>得到网络输出\(O\)后，可以用\((Y,O)\)评估网络质量。理想的网络满足\(Y==O\)。</p>

<h2 id="toc_1">前向传播的实现</h2>

<p>在Caffe中CNN前向传播过程由Net + Layer组合完成，中间结果和最终结果则使用Blob承载。下面我们深入代码来观察这一过程。</p>

<h2 id="toc_2">DAG(有向无环图)构造过程</h2>

<p>首先我们从Net构造函数开始.</p>

<pre><code class="language-c++">
//从NetParameter对象构造
template &lt;typename Dtype&gt;
Net&lt;Dtype&gt;::Net(const NetParameter&amp; param) {
  Init(param);
}

//从net.prototxt文件构造
template &lt;typename Dtype&gt;
Net&lt;Dtype&gt;::Net(const string&amp; param_file, Phase phase,
    const int level, const vector&lt;string&gt;* stages) {
  NetParameter param;
  ReadNetParamsFromTextFileOrDie(param_file, &amp;param);
  // Set phase, stages and level
  param.mutable_state()-&gt;set_phase(phase);
  if (stages != NULL) {
    for (int i = 0; i &lt; stages-&gt;size(); i++) {
      param.mutable_state()-&gt;add_stage((*stages)[i]);
    }
  }
  param.mutable_state()-&gt;set_level(level);
  Init(param);
}

</code></pre>

<p>从上面的构造函数看到，二者都调用了Init()函数。传递给该函数的参数param是 NetParameter对象，我们已经之前的例程中使用过，了解过其数据结构描述(caffe.proto)。 我们可以从<code>net.prototxt</code>文件读取到内存中，初始化一个NetParameter对象，然后传递给<code>Init()</code>函数.</p>

<p>接着追踪<code>Init()</code>函数:</p>

<pre><code class="language-c++">//这个函数很长
template &lt;typename Dtype&gt;
void Net&lt;Dtype&gt;::Init(const NetParameter&amp; in_param) {
  // Set phase from the state.
  phase_ = in_param.state().phase();
  // Filter layers based on their include/exclude rules and
  // the current NetState.
  NetParameter filtered_param;
  //过滤一些参数,仅仅保留当前阶段参数.
  FilterNet(in_param, &amp;filtered_param);
  LOG_IF(INFO, Caffe::root_solver())
      &lt;&lt; &quot;Initializing net from parameters: &quot; &lt;&lt; std::endl
      &lt;&lt; filtered_param.DebugString();
  // Create a copy of filtered_param with splits added where necessary.(创建一个拷贝,之后就用这个拷贝)
  NetParameter param;
  InsertSplits(filtered_param, &amp;param);
  // Basically, build all the layers and set up their connections.(构建所有Layer并将它们连接)
  name_ = param.name(); //网络名
  map&lt;string, int&gt; blob_name_to_idx;    //Blob名与索引的映射
  set&lt;string&gt; available_blobs;  //已有Blob名集合
  memory_used_ = 0;     //统计内存占用
  // For each layer, set up its input and output
  //对每个 Layer 设置输入 Blob (BottomBlob)和输出 Blob (TopBlob)
  bottom_vecs_.resize(param.layer_size()); //有多少层，就有多少个输入 Blob 
  top_vecs_.resize(param.layer_size()); //有多少层，就有多少个输出Blob 
  bottom_id_vecs_.resize(param.layer_size()); //记录每个层的输入Blob索引
  param_id_vecs_.resize(param.layer_size());    // 记录每个层的权值Blob索引
  top_id_vecs_.resize(param.layer_size());  // 记录每个层的输出Blob索引
  bottom_need_backward_.resize(param.layer_size()); //记录每个Blob是否需要反向传播过程
  
  //遍历每个层
  for (int layer_id = 0; layer_id &lt; param.layer_size(); ++layer_id) {
    // Inherit phase from net if unset.(每个层的阶段标记.如果在层描述中未指定阶段，就使用Net的阶段)
    if (!param.layer(layer_id).has_phase()) {
      param.mutable_layer(layer_id)-&gt;set_phase(phase_);
    }
    // Setup layer.
    //获取层参数
    const LayerParameter&amp; layer_param = param.layer(layer_id);
    if (layer_param.propagate_down_size() &gt; 0) {
      CHECK_EQ(layer_param.propagate_down_size(),
          layer_param.bottom_size())
          &lt;&lt; &quot;propagate_down param must be specified &quot;
          &lt;&lt; &quot;either 0 or bottom_size times &quot;;
    }
    // Layer工厂，专业制造各种Layer，然后添加到Net类的layers_对象中 
    // 注意到这Layer的LayerParameter都继承自NetParameter
NetParameterlayers_.push_back(LayerRegistry&lt;Dtype&gt;::CreateLayer(layer_param));
    layer_names_.push_back(layer_param.name());
    LOG_IF(INFO, Caffe::root_solver())
        &lt;&lt; &quot;Creating Layer &quot; &lt;&lt; layer_param.name();
    bool need_backward = false;     //判断该层是否需要反向传播

    // Figure out this layer&#39;s input and output(确定该Layer的输入Blob和输出Blob)
    for (int bottom_id = 0; bottom_id &lt; layer_param.bottom_size();
         ++bottom_id) {
         //遍历所有输入Blob,记录到Blob名集合、Blob名到索引映射中
      const int blob_id = AppendBottom(param, layer_id, bottom_id, &amp;available_blobs, &amp;blob_name_to_idx);
      // If a blob needs backward, this layer should provide it.
      need_backward |= blob_need_backward_[blob_id];
    }
    //输出Blob做同样的事
    int num_top = layer_param.top_size();
    for (int top_id = 0; top_id &lt; num_top; ++top_id) {
      AppendTop(param, layer_id, top_id, &amp;available_blobs, &amp;blob_name_to_idx);
      // Collect Input layer tops as Net inputs.(收集输入层(InputLayer)信息，如果有，其输出blob将作为整个Net的输入)
      if (layer_param.type() == &quot;Input&quot;) {
        const int blob_id = blobs_.size() - 1;
        net_input_blob_indices_.push_back(blob_id);
        net_input_blobs_.push_back(blobs_[blob_id].get());
      }
    }
    // If the layer specifies that AutoTopBlobs() -&gt; true and the LayerParameter
    // specified fewer than the required number (as specified by
    // ExactNumTopBlobs() or MinTopBlobs()), allocate them here.
    Layer&lt;Dtype&gt;* layer = layers_[layer_id].get();
    if (layer-&gt;AutoTopBlobs()) {
      const int needed_num_top =
          std::max(layer-&gt;MinTopBlobs(), layer-&gt;ExactNumTopBlobs());
      for (; num_top &lt; needed_num_top; ++num_top) {
        // Add &quot;anonymous&quot; top blobs -- do not modify available_blobs or
        // blob_name_to_idx as we don&#39;t want these blobs to be usable as input
        // to other layers.
        AppendTop(param, layer_id, num_top, NULL, NULL);
      }
    }
    
    
    // After this layer is connected, set it up.(Layer连接设置完毕，调用各个Layer的SetUp()函数)
    layers_[layer_id]-&gt;SetUp(bottom_vecs_[layer_id], top_vecs_[layer_id]);
    LOG_IF(INFO, Caffe::root_solver())
        &lt;&lt; &quot;Setting up &quot; &lt;&lt; layer_names_[layer_id];
        //设置输出Blob对损失函数的投票因子
    for (int top_id = 0; top_id &lt; top_vecs_[layer_id].size(); ++top_id) {
      if (blob_loss_weights_.size() &lt;= top_id_vecs_[layer_id][top_id]) {
        blob_loss_weights_.resize(top_id_vecs_[layer_id][top_id] + 1, Dtype(0));
      }
      blob_loss_weights_[top_id_vecs_[layer_id][top_id]] = layer-&gt;loss(top_id);
      //打印每层输出Blob尺寸信息
      LOG_IF(INFO, Caffe::root_solver())
          &lt;&lt; &quot;Top shape: &quot; &lt;&lt; top_vecs_[layer_id][top_id]-&gt;shape_string();
      if (layer-&gt;loss(top_id)) {
        LOG_IF(INFO, Caffe::root_solver())
            &lt;&lt; &quot;    with loss weight &quot; &lt;&lt; layer-&gt;loss(top_id);      //除了损失层的loss_weight为1,其它层都是0
      }
      //统计每个输出Blob内存占用量
      memory_used_ += top_vecs_[layer_id][top_id]-&gt;count();
    }
    //打印所有输出Blob内存占用量
    LOG_IF(INFO, Caffe::root_solver())
        &lt;&lt; &quot;Memory required for data: &quot; &lt;&lt; memory_used_ * sizeof(Dtype);
        
    //下面开始初始化各层权值Blob
    const int param_size = layer_param.param_size();
    const int num_param_blobs = layers_[layer_id]-&gt;blobs().size();
    //保证参数配置需要的权值Blob数目不大于实际对象的权值Blob数
    CHECK_LE(param_size, num_param_blobs)
        &lt;&lt; &quot;Too many params specified for layer &quot; &lt;&lt; layer_param.name();
    ParamSpec default_param_spec;
    //每个权值层(卷基层,全连接层)都要经历下面的过程
    for (int param_id = 0; param_id &lt; num_param_blobs; ++param_id) {
      const ParamSpec* param_spec = (param_id &lt; param_size) ?
          &amp;layer_param.param(param_id) : &amp;default_param_spec;
      const bool param_need_backward = param_spec-&gt;lr_mult() != 0;
      //设置权值层param(lr_mult:0)可以禁止其反向传播过程，即冻结权值
      need_backward |= param_need_backward;
      layers_[layer_id]-&gt;set_param_propagate_down(param_id,
                                                  param_need_backward);
    }
    for (int param_id = 0; param_id &lt; num_param_blobs; ++param_id) {
    //记录权值Blob到Net后台数据库
      AppendParam(param, layer_id, param_id);
    }
    // Finally, set the backward flag
    layer_need_backward_.push_back(need_backward);
    if (need_backward) {
      for (int top_id = 0; top_id &lt; top_id_vecs_[layer_id].size(); ++top_id) {
        blob_need_backward_[top_id_vecs_[layer_id][top_id]] = true;
      }
    }
  }
  // Go through the net backwards to determine which blobs contribute to the
  // loss.  We can skip backward computation for blobs that don&#39;t contribute
  // to the loss.
  // Also checks if all bottom blobs don&#39;t need backward computation (possible
  // because the skip_propagate_down param) and so we can skip bacward
  // computation for the entire layer
  set&lt;string&gt; blobs_under_loss;
  set&lt;string&gt; blobs_skip_backp;
  for (int layer_id = layers_.size() - 1; layer_id &gt;= 0; --layer_id) {
    bool layer_contributes_loss = false;
    bool layer_skip_propagate_down = true;
    for (int top_id = 0; top_id &lt; top_vecs_[layer_id].size(); ++top_id) {
      const string&amp; blob_name = blob_names_[top_id_vecs_[layer_id][top_id]];
      if (layers_[layer_id]-&gt;loss(top_id) ||
          (blobs_under_loss.find(blob_name) != blobs_under_loss.end())) {
        layer_contributes_loss = true;
      }
      if (blobs_skip_backp.find(blob_name) == blobs_skip_backp.end()) {
        layer_skip_propagate_down = false;
      }
      if (layer_contributes_loss &amp;&amp; !layer_skip_propagate_down)
        break;
    }
    // If this layer can skip backward computation, also all his bottom blobs
    // don&#39;t need backpropagation
    if (layer_need_backward_[layer_id] &amp;&amp; layer_skip_propagate_down) {
      layer_need_backward_[layer_id] = false;
      for (int bottom_id = 0; bottom_id &lt; bottom_vecs_[layer_id].size();
               ++bottom_id) {
        bottom_need_backward_[layer_id][bottom_id] = false;
      }
    }
    if (!layer_contributes_loss) { layer_need_backward_[layer_id] = false; }
    if (Caffe::root_solver()) {
      if (layer_need_backward_[layer_id]) {
        LOG(INFO) &lt;&lt; layer_names_[layer_id] &lt;&lt; &quot; needs backward computation.&quot;;
      } else {
        LOG(INFO) &lt;&lt; layer_names_[layer_id]
            &lt;&lt; &quot; does not need backward computation.&quot;;
      }
    }
    for (int bottom_id = 0; bottom_id &lt; bottom_vecs_[layer_id].size();
         ++bottom_id) {
      if (layer_contributes_loss) {
        const string&amp; blob_name =
            blob_names_[bottom_id_vecs_[layer_id][bottom_id]];
        blobs_under_loss.insert(blob_name);
      } else {
        bottom_need_backward_[layer_id][bottom_id] = false;
      }
      if (!bottom_need_backward_[layer_id][bottom_id]) {
        const string&amp; blob_name =
                   blob_names_[bottom_id_vecs_[layer_id][bottom_id]];
        blobs_skip_backp.insert(blob_name);
      }
    }
  }
  // Handle force_backward if needed.
  if (param.force_backward()) {
    for (int layer_id = 0; layer_id &lt; layers_.size(); ++layer_id) {
      layer_need_backward_[layer_id] = true;
      for (int bottom_id = 0;
           bottom_id &lt; bottom_need_backward_[layer_id].size(); ++bottom_id) {
        bottom_need_backward_[layer_id][bottom_id] =
            bottom_need_backward_[layer_id][bottom_id] ||
            layers_[layer_id]-&gt;AllowForceBackward(bottom_id);
        blob_need_backward_[bottom_id_vecs_[layer_id][bottom_id]] =
            blob_need_backward_[bottom_id_vecs_[layer_id][bottom_id]] ||
            bottom_need_backward_[layer_id][bottom_id];
      }
      for (int param_id = 0; param_id &lt; layers_[layer_id]-&gt;blobs().size();
           ++param_id) {
        layers_[layer_id]-&gt;set_param_propagate_down(param_id, true);
      }
    }
  }
  // In the end, all remaining blobs are considered output blobs.(所有剩下的Blob都被看作输出Blob)
  for (set&lt;string&gt;::iterator it = available_blobs.begin();
      it != available_blobs.end(); ++it) {
    LOG_IF(INFO, Caffe::root_solver())
        &lt;&lt; &quot;This network produces output &quot; &lt;&lt; *it;
    net_output_blobs_.push_back(blobs_[blob_name_to_idx[*it]].get());
    net_output_blob_indices_.push_back(blob_name_to_idx[*it]);
  }
  //将Blob名称与Blob id对应关系登记到Net后台数据库
  for (size_t blob_id = 0; blob_id &lt; blob_names_.size(); ++blob_id) {
    blob_names_index_[blob_names_[blob_id]] = blob_id;
  }
  //将Layer名称与Layer id对应关系登记到Net后台数据库
  for (size_t layer_id = 0; layer_id &lt; layer_names_.size(); ++layer_id) {
    layer_names_index_[layer_names_[layer_id]] = layer_id;
  }
  ShareWeights();
  debug_info_ = param.debug_info();
  LOG_IF(INFO, Caffe::root_solver()) &lt;&lt; &quot;Network initialization done.&quot;;
}


</code></pre>

<p>到这里我们大概了解了一个Net初始化的过程,关于其中三个登记注册函数,后面继续学习.</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[第六条 理解"属性" 这一概念]]></title>
    <link href="https://lockxmonk.github.io/14986374781793.html"/>
    <updated>2017-06-28T16:11:18+08:00</updated>
    <id>https://lockxmonk.github.io/14986374781793.html</id>
    <content type="html"><![CDATA[
<p>用Objective-C等面向对象语言编程时，“对象”（object)就是“基本构造单元&quot;（building block),开发者可以通过对象来存储并传递数据。在对象之间传递数据并执行任务的过程就叫做“消息传递”（Messaging)。若想编写出髙效且易维护的代码，就一定要熟悉这两个特性的工作原理。</p>

<p>当应用程序运行起来以后,为其提供相关支持的代码叫做<strong>“Objective-C运行期环境”(Objective-C runtime)</strong>,它提供了一些使得对象之间能够传递消息的重要函数，并且包含创建类实例所用的全部逻辑。在理解了运行期环境中各个部分协同工作的原理之后，你的开发水<br/>
平将会进一步提升。</p>

<h2 id="toc_0">属性</h2>

<p>“属性”（property)是Objecive-C的一项特性，用于封装对象中的数据。Objective-C对象通常会把其所需要的数据保存为各种实例变量。实例变量一般通过“存取方法”（access method)来访问。其中，“获取方法&quot;（getter)用于读取变量值，&quot;设置方法&quot;（setter)用于写入变量值。这个概念已经定型，并且经由“属性”这一特性而成为Objective-C 2.0的一部分,开发者可以令编译器自动编写与属性相关的存取方法。此特性引入了一种新的“点语法”（dot syntax),使开发者可以更为容易地依照类对象来访问存放于其中的数据。你也许已经使用过“属性”这个概念了，不过你未必知道其全部细节。而且，还有很多与属性有关的麻烦事。<strong>第6条将会告诉大家有哪些问题可以用属性来解决，并指出其中所体现出来的关键特性。</strong>在描述个人信息的类中，也许会存放人名、生日、地址等内容。可以在类接口的public<br/>
区段中声明一些实例变量：</p>

<pre><code class="language-objc">
@interface EOCPerson : NSObject {
@public
    NSString *_firstName;
    NSString *_lastName;
@private
    NSString *_someInternalData;
}
@end

</code></pre>

<p>这种写法在其他语言中,java或者c++中比较常见,但是编写Objective-C代码时却很少这么做。这种写法的问题是：<strong>对象布局在编译期（compile time)就已经固定了。只要碰到访问firstName变量的代码，编译器就把其替换为“偏移量”（offset),这个偏移量是“硬编码”（hardcode),表示该变M距离存放对象的<br/>
内存区域的起始地址有多远。</strong></p>

<p>这种写法的问题是,如果又增加一个实例变量,就麻烦了,例如:</p>

<pre><code class="language-objc">
@interface EOCPerson : NSObject {
@public
    NSString *_dataOfBirth;
    NSString *_firstName;
    NSString *_lastName;
@private
    NSString *_someInternalData;
}
@end

</code></pre>

<p>原来表示<code>_firstName</code>的偏移量现在却指向<code>dateOfBirth</code>了。把偏移量硬编码于其中的那些代码都会读取到错误的值。</p>

<p><strong>如果代码使用了编译期计算出来的偏移量，那么在修改类定义之后必须重新编译，否则就会出错。</strong></p>

<p>例如，某个代码库中的代码使用了一份旧的类定义。如果和其相链接的代码使用了新的类定义，那么运行时就会出现不兼容现象（incompatibility)。各种编程语言都有应对<br/>
此问题的办法。<strong>Objective-C的做法是，把实例变量当做一种存储偏移量所用的“特殊变量”(special variable),交由“类对象”（class object)保管。偏移量会在运行期査找，如果类的定义变了，那么存储的偏移量也就变了</strong>，这样的话，无论何时访问实例变量，总能使用正确的偏移最。甚至可以在运行期向类中新增实例变量，这就是稳固的<strong>“应用程序二进制接口”（Application Binary Interface，ABI)</strong>。有了这种“稳固的”（nonfragile)的ABI，我们就可以在“class-continuation分类”或实现文件中定义实例变量了。所以说，<font color=red><strong>不一定要在接口中把全部实例变量都声明好，可以将某些变量从接口的public区段里移走，以便保护与类实现有关的内部信息</strong></font>。</p>

<p>下面我们就要来讨论另一种解决方法,也就是&quot;属性&quot;,<strong>我们尽量不要直接访问实例变量，而应该通过存取方法来做。虽说属性最终还是得通过实例变量来实现，但它却提供了一种简洁的抽象机制。</strong>你可以自己编写存取方法，然而在正规的Objective-C编码风格中，存取方法有着严格的命名规范。正因为有了这种严格的命名规范，所以Objective-C这门语言才能根据名称自动创建出存取方法。这时<code>@property</code>语法就派上用场了。</p>

<p>在对象接口的定义中，<strong><font color=red>可以使用属性，这是一种标准的写法，能够访问封装在对象里的数据。因此，也可以把属性当做一种简称，其意思是说：编译器会自动写出一套存取方法,用以访问给定类型中具有给定名称的变量。</font></strong>,例如下面这个类：</p>

<pre><code class="language-objc">
@interface EOCPerson : NSObject
@property NSString *firstName;
@property NSString *lastName;

@end

</code></pre>

<p>对于该类的使用者来说，上述代码写出来的类与下面这种写法等效：</p>

<pre><code class="language-objc">
@interface EOCPerson : NSObject
- (NSString*)firstName;
- (void) setFirstName: (NSString*) firstName;
- (NSString*)lastName;
- (void)setLastName:(NSString*)lastName;
@end

</code></pre>

<p>要访问属性我们可以使用<strong>点语法</strong>,与c语言类似.使用“点语法”和直接调用存取方法之间没有丝毫差别:</p>

<pre><code class="language-objc">
EOCPerson *aPerson = [Person new];
aPerson.firstName = @&quot;Bob&quot;; //Same as:
[aPerson setFirstName:@&quot;Bob&quot;];

NSString *lastName = aPerson.lastName; //Same as:
NSString *lastName = [aPerson lastName];

</code></pre>

<p>如果使用了属性的话,编译器会自动编写这些属性的访问方法.此过程叫做“自动合成”（autosynthesis)。需要强调的是，这个过程由编译器在编译期执行，所以编辑器里看不到这些“合成方法&quot;（synthesized method)的源代码。</p>

<p>编译器还会自动向类中添加适当的实例变量,并且在属性名前面加下划线，以此作为实例变量的名字.在前例中，会生成两个实例变量，其名称分别为<code>_firstName与_lastName</code>。也可以在类的实现代码里通过<code>@synthesize</code>语法来指定实例变量的名字：</p>

<pre><code class="language-objc">
@implementation EOCPerson
@synthesize firstName = _myFirstName;
@synthesize lastName = _myLastName;
@end

</code></pre>

<p>前述语法会将生成的实例变量命名为<code>_myFirstName与_myLastName</code>,而不再使用默认的名字。</p>

<p>若不想令编译器自动合成存取方法，则可以自己实现。如果你只实现了其中一个存取方法，那么另外一个还是会由编译器来合成。还有一种办法能阻止编译器自动合成存取方<br/>
法，就是使用<code>@dynamic</code>关键字,<strong>它会告诉编译器:不要自动创建实现属性所用的实例变量，也不要为其创建存取方法。</strong>而且，在编译访问属性的代码时，即使编译器发现没有定义存取方法，<strong>也不会报错</strong>，它相信这些方法能在运行期找到。比方说，如果从CoreData框架中的<code>NSManagedObject</code>类里继承了一个子类，那么就需要在运行期动态创建存取方法。继承<code>NSManagedObject</code>时之所以要这样做，是因为子类的某些属性不是实例变量，其数据来自后端的数据库中。所以:</p>

<pre><code class="language-objc">
@interface EOCPerson : NSManagedObject
@property NSString *firstName;
@property NSString *lastName;
@end

@implementation EOCPerson
@dynamic firstName, lastName;

@end
</code></pre>

<blockquote>
<p>编译器不会为上面这个类自动合成存取方法或实例变量。如果用代码访问其中的属性，编译器也不会发出警示信息.</p>
</blockquote>

<h2 id="toc_1">属性特质</h2>

<p>使用属性时还有一个问题要注意，就是其各种特质（attribute)设定也会影响编译器所生成的存取方法。比如下面这个属性就指定了三项特质：</p>

<pre><code class="language-objc">
@property (nonatomic, readwrite, copy) NSString * 
firstName;

</code></pre>

<p><font color=red>属性可以拥有的特质分为四类：</font></p>

<ol>
<li><p>原子性:<br/>
在默认情况下，由编译器所合成的方法会通过锁定机制确保其原子性（atomicity) 。如果属性具备nonatomic特质，则不使用同步锁。请注意，尽管没有名为“atomic”的特质（如果某属性不具备nonatomic特质，那它就是“原子的”（atomic)),但是仍然可以在属性特质中写明这一点，编译器不会报错。若是自己定义存取方法，那么就应该遵从与属性特质相符的原子性。</p></li>
<li><p>读/写权限:</p>

<ul>
<li>    具备<strong>readwrite</strong>(读写）特质的属性拥有“获取方法”（getter)与“设置方法&quot;（setter)。若该属性由<code>@synthesize</code>实现，则编译器会自动生成这两个方法。</li>
<li>    具备<strong>readonly</strong>(只读）特质的属性仅拥有获取方法<font color=red>，<strong>只有当该属性由<code>@synthesize</code>实现时，编译器才会为其合成获取方法</strong></font>。你可以用此特质把某个属性对外公开为只读属性,然后在<code>“class-cominuaticm分类”</code>中将其重新定义为读写属性。后面再详述这种做法。</li>
</ul></li>
<li><p>内存管理语义:<br/>
属性用于封装数据，而数据则要有<code>“具体的所有权语义”（concrete ownership semantic)</code>。下面这一组特质<strong>仅会影响“设置方法”(setter)</strong>。例如，用“设置方法”设定一个新值时，它是应该<code>“保留&quot;(retain)</code>此值呢，还是只将其赋给底层实例变量就好？<strong>编译器在合成存取方法时，要根据此特质来决定所生成的代码。如果自己编写存取方法，那么就必须同有关属性所具备的特质相符</strong>。</p>

<ul>
<li>    <strong>assign</strong>  “设置方法”只会执行针对“纯量类型”（scalar type，例如CGFloat或NSImeger等）的简单赋值操作。</li>
<li>    <strong>strong</strong>  此特质表明该属性定义了一种“拥有关系”（owning relationship)。为这种属性设置新值时，设置方法会先保留新值，并释放旧值，然后再将新值设置上去。</li>
<li>    <strong>weak</strong>  此特质表明该属性定义了一种“非拥有关系”（nonowning relationship)。<strong>为这种属性设置新值时，设置方法既不保留新值，也不释放旧值</strong>。此特质同assign类似,然而在属性所指的对象遭到摧毁时，属性值也会清空（nil out)。</li>
<li>    <strong>unsafe_unretained</strong>  此特质的语义和assign相同，但是它适用于“对象类型”（object type),该特质表达一种“非拥有关系”（“不保留”，unretained),<strong>当目标对象遭到摧毁时，属性值不会自动清空（“不安全”，unsafe),这一点与weak有区别</strong>。</li>
<li>    <strong>copy</strong>  <font color=red>此特质所表达的所属关系与strong类似。然而设置方法并不保留新值,而是将其“拷贝”（copy)。<strong>当属性类型为<code>NSString*</code>时，经常用此特质来保护其封装性,因为传递给设置方法的新值有可能指向一个<code>NSMutableString类</code>的实例。这个类是<code>NSString的子类</code>，表示一种可以修改其值的字符串，此时若是不拷贝字符串，那么设置完属性之后，字符串的值就可能会在对象不知情的情况下遭人更改。</strong></font>所以，这时就要拷贝一份“不可变”（immutable)的字符串，确保对象中的字符串值不会无意间变动。只要实现属性所用的对象是“可变的”（mutable)，就应该在设置新属性值时拷贝一份.</li>
</ul></li>
<li><p>方法名:<br/>
可通过如下特质来指定存取方法的方法名：</p></li>
</ol>

<ul>
<li><strong>getter=<name></strong>  指定“获取方法”的方法名。如果某属性是<code>Boolean</code>型，而你想为其获取方法加上<code>“is”</code>前缀，那么就可以用这个办法来指定。比如说，在<code>UISwitch</code>类中，表示“开关&quot;（switch)是否打开的属性就是这样定义的：</li>
</ul>

<pre><code class="language-objc">
@property (nonatomic, getter=isOn) BOOL on;

</code></pre>

<ul>
<li><p><strong>setter=<name></strong> 指定&quot;设置方法&quot;的方法名.(不太常见)</p>

<p>通过上述特质，可以微调由编译器所合成的存取方法。不过需要注意：<font color=red>若是自己来实现这些存取方法，那么应该保证其具备相关属性所声明的特质</font>。比方说，如果将某个属性声明为<code>copy</code>，那么就应该在“设置方法”中拷贝相关对象，否则会误导该属性的使用者，而且，<br/>
若是不遵从这一约定，还会令程序产生bug。</p></li>
</ul>

<p>如果想在其他方法里设置属性值，那么同样要遵守属性定义中所宣称的语义。例如，我们扩充一下前面提到的<code>EOCPerson</code>类。由于字符串值可能会改变，所以要把相关属性的“内存管理语义&quot;声明为<code>copy</code>。该类中新增了一个<strong>‘初始化方法’(initializer)</strong>,用于设置“名&quot;(first name)和“姓”（last name)的初始值：</p>

<pre><code class="language-objc">
@interface EOCPerson : NSManagedObject
@property (copy) NSString *firstName;
©property (copy) NSString *lastName;

- (id)initWithFirstName: (NSString*)firstName
                lastName:(NSString*)lastName;
@end

</code></pre>

<p><strong><font color=red>在实现这个自定义的初始化方法时，一定要遵循属性定义中宣称的“copy”语义</font></strong>，因为“属性定义”就相当于“类”和“待设置的属性值”之间所达成的契约。初始化方法的实现代码可以这样写：</p>

<pre><code class="language-objc">
- (id)initWithFirstName: (NSString*) firstName
                lastName:(NSString*)lastName
{
    if ((self = [super init])) {
        _firstName = [firstName copy];
         _lastName = [lastName copy];
    }
return self;
}

</code></pre>

<p>这里也许会有疑问:为何不调用属性所对应的“设置方法”呢？如果用了“设置方法”的话，不是总能保证准确的语义吗？<font color=red>后面第7条学习中将会详细解释为什么决不应该在init(或dealloc)方法中调用存取方法</font>。</p>

<p>要是看过第18条的话，你就会明白，应该尽量使用不可变的对象。如果将这一条套用到<code>EOCPerson</code>类身上，那就等于说，其两个属性都应该设为“只读”。用初始化方法设置好属性值之后，就不能再改变了。在本例中，仍需声明属性的“内存管理语义”。于是可以把属性的定义改成这样：</p>

<pre><code class="language-objc">
@property (copy, readonly) NSString *firstName;
@property (copy, readonly) NSString *lastName;

</code></pre>

<p>由于是只读属性，所以编译器不会为其创建对应的“设置方法”，即便如此，我们还是要写上这些属性的语义，以此表明初始化方法在设置这些属性值时所用的方式。要是不写明语义的话，该类的调用者就不知道初始化方法里会拷贝这些属性，他们有可能会在调用初始化方法之前自行拷贝属性值。这种操作是多余而且低效的。</p>

<p><code>atomic与nonatomic</code>的区别就是是否具有原子性,具备atomic特质的获取方法会通过锁定机制来确保其操作的原子性。避免两个进程同时访问同一属性时,读取到其它线程没有修改好的属性值.</p>

<p>在ios开发中,其中所有属性都声明为ncmatomic。这样做的历史原因是：<font color=red>在iOS中使用同步锁的开销较大，这会带来性能问题。</font>一般情况下并不要求属性必须是“原子的”，因为这并不能保证“线程安全&quot;（thread safety),若要实现“线程安全”的操作，还需采用更为深层的锁定机制才行。</p>

<h2 id="toc_2">要点:</h2>

<ul>
<li> 可以用<code>@property</code>语法来定义对象中所封装的数据。</li>
<li> 通过“特质”来指定存储数据所需的正确语义。</li>
<li> 在设置属性所对应的实例变量时，一定要遵从该属性所声明的语义。</li>
<li> <font color=red>开发iOS程序时应该使用<code>nonatomic</code>属性，因为<code>atomic</code>属性会严重影响性能。</font></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Caffe模型]]></title>
    <link href="https://lockxmonk.github.io/14986110416063.html"/>
    <updated>2017-06-28T08:50:41+08:00</updated>
    <id>https://lockxmonk.github.io/14986110416063.html</id>
    <content type="html"><![CDATA[
<ul>
<li>
<a href="#toc_0">内存中的表示</a>
</li>
<li>
<a href="#toc_1">磁盘上表示</a>
</li>
<li>
<a href="#toc_2">Caffe Modal Zoo</a>
</li>
</ul>


<p>我们之前学习过,一个完整的深度学习系统最核心的两个方面是<strong>数据</strong>和<strong>模型</strong>。今大我们 主要关注模型。一个深度学习模型通常由<strong>三部分</strong>参数组成：</p>

<ul>
<li>可学习参数（Leamable Parameter),又称可训练参数、神经网络权系数、权重，其数值<strong>由模型初始化参数、误差反向传播过程控制</strong>,一般不可人工干预.</li>
<li>结构参数（Archetecture Parameter),包括<strong>卷积层/全连接层/下采样层数目、卷积核数目、 卷积核大小等描述网络结构的参数</strong>,一旦设定好,在网络训练阶段不能更改;值得注意的是,训练阶段网络结构参数和预测阶段结构参数很可能不同。</li>
<li>训练超参数（Hyper-Parameter),用来控制网络训练收敛的参数，训练阶段可以自动或手动调节以获得更好的效果，预测阶段不需要该参数.</li>
</ul>

<p>在Caffe中，一个模型的三部分参数分别由<strong>不同模块定义和实现</strong>:</p>

<ul>
<li><strong>可学习参数</strong>在内存中使用Blob对象保持，必要时以二进制ProtoBuffer文件(*.caffemodel)形态序列化并存储于磁盘上，便于进一步微调（finetune,又称精调）、共享（例如参数服务器Parameter Server, PS)、性能评估（benchmark)。</li>
<li><strong>结构参数</strong>使用ProtoBuffer文本格式（*.prototxt)描述，网络初始化时通过该描述文件构建Net对象、Layer对象形成有向无环图结构，在Layer与Layer之间、Net输入源和输出阱均为持有数据和中间结果的Blob对象。</li>
<li><strong>训练超参数</strong>同样使用ProtoBuffer文本格式（*.prototxt)描述，训练阶段利用该描述文件构建求解器（Solver)对象，该对象按照一定规则在训练网络时自动调节这些超参数值。</li>
</ul>

<p>我们在MNIST例子中对LeNet-5模型稍微修改一下.变成逻辑回归（Logistic Regression, LR)分类器。<br/>
<img src="media/14986110416063/14986122892113.jpg" alt=""/></p>

<p>复制一份<code>examples/mnist/lenet_train_test.prototxt</code>,重命名为 <code>lenet_lr.prototxt</code>，修改内容如下:</p>

<pre><code class="language-protobuf">
name: &quot;LeNet&quot;
layer {
  name: &quot;mnist&quot;
  type: &quot;Data&quot;
  top: &quot;data&quot;
  top: &quot;label&quot;
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: &quot;examples/mnist/mnist_train_lmdb&quot;
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: &quot;mnist&quot;
  type: &quot;Data&quot;
  top: &quot;data&quot;
  top: &quot;label&quot;
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: &quot;examples/mnist/mnist_test_lmdb&quot;
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: &quot;ip&quot;
  type: &quot;InnerProduct&quot;
  bottom: &quot;data&quot;
  top: &quot;ip&quot;
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 20
    weight_filler {
      type: &quot;xavier&quot;
    }
    bias_filler {
      type: &quot;constant&quot;
    }
  }
}
layer {
  name: &quot;accuracy&quot;
  type: &quot;Accuracy&quot;
  bottom: &quot;ip&quot;
  bottom: &quot;label&quot;
  top: &quot;accuracy&quot;
  include {
    phase:TEST
  }
}
layer {
  name: &quot;loss&quot;
  type: &quot;SoftmaxWithLoss&quot;
  bottom: &quot;ip&quot;
  bottom: &quot;label&quot;
  top: &quot;loss&quot;
}

</code></pre>

<p>复制一份<code>examples/mnist/lenet_solver.prototxt</code>，重命名为<code>lenet_lr_solver.prototxt</code>,修改内容<br/>
如下:</p>

<pre><code class="language-protobuf">
# The train/test net protocol buffer definition
net: &quot;examples/mnist/lenet_lr.prototxt&quot;
# test_iter specifies how many forward passes the test should carry out.
# In the case of MNIST, we have test batch size 100 and 100 test iterations,
# covering the full 10,000 testing images.
test_iter: 100
# Carry out testing every 500 training iterations.
test_interval: 500
# The base learning rate, momentum and the weight decay of the network.
base_lr: 0.01
momentum: 0.9
weight_decay: 0.0005
# The learning rate policy
lr_policy: &quot;inv&quot;
gamma: 0.0001
power: 0.75
# Display every 100 iterations
display: 100
# The maximum number of iterations
max_iter: 10000
# snapshot intermediate results
snapshot: 5000
snapshot_prefix: &quot;examples/mnist/lenet&quot;
# solver mode: CPU or GPU
solver_mode: CPU

</code></pre>

<p>然后运行训练命令,在命令行输入:</p>

<pre><code>./build/tools/caffe train --solver=examples/mnist/lenet_lr_solver.prototxt
</code></pre>

<p>但是发现报错了:<br/>
<img src="media/14986110416063/14986154204478.jpg" alt=""/></p>

<p>通过上述错误描述,发现是lmdb数据文件没有的问题....</p>

<p>运行<code>./examples/mnist/create_mnist.sh</code>脚本,将之前下载过的数据转化成lmdb形式.中间的报错和解决如截图所示:</p>

<p><img src="media/14986110416063/14986155733551.jpg" alt=""/></p>

<p>我们成功获得到了lmdb文件.</p>

<p>再次执行训练命令:</p>

<pre><code>master) ✗ ./build/tools/caffe train --solver=examples/mnist/lenet_lr_solver.prototxt
</code></pre>

<p>然后就发现已经开始训练了.</p>

<p>最后得到结果如图所示:<br/>
<img src="media/14986110416063/14986195740444.jpg" alt=""/></p>

<p>经过训练，可以获得在测试集上分类准确率为0.9908的模型。相比LeNet-5而言准确率降低了，这也符合直觉，因为将模型简化后参数变少，层数变少，网络表达能力变差。我们今天不关注准确率，只关注模型的表达方式。</p>

<h2 id="toc_0">内存中的表示</h2>

<p>从运行的log文件可以追踪模型是如何从prototxt描述变为内存中表示方式的,</p>

<p>看到这行:</p>

<pre><code>
 Creating training net from net file:
examples/mnist/lenet_lr.prototxt

// ...不要在意这些细节
Initializing net from parameters:

</code></pre>

<p>追踪<code>solver.cpp</code>的第87行，看到如下代码：</p>

<pre><code class="language-c++">
//前面省略..
//在solver.hpp 中声明了SolverParameterparam_
//它是ProtoBuffer工具生成的结构体,用来解析lenet_lr_solver.prototxt
if (param_.has_net()) {
    LOG_IF(INFO, Caffe::root_solver()) //打印log
        //这里param_.net()会返回examples/mnist/lenet_lr.prototxt 
        &lt;&lt; &quot;Creating training net from net file: &quot; &lt;&lt; param_.net();
    ReadNetParamsFromTextFileOrDie(param_.net(), &amp;net_param);
  }
  
</code></pre>

<h2 id="toc_1">磁盘上表示</h2>

<p>Caffe使用ProtoBuffer二进制文件有最小文件尺寸，并由ProtoBuffer工具自动生成高效的序列化/反序列化接U口(多语言支持，包括C++、Java、Python)，以及可读性好、兼容二进制文件的文本格式.</p>

<p>我们仍然从运行log查找线索:</p>

<pre><code>Snapshotting to binary proto file
examples/mn is t/lenet__iter_l 0000. caffemodel

Snapshotting solver state to binary proto file examples/mnist/Xenet_iter_10000.solverstate

</code></pre>

<p>其中,<code>.caffemodel</code>文件是在特定训练间隙保存的二进制文件，包含当前网络各层的权值状态;而<code>.solverstate</code>是与<code>.caffemodel</code>一起产生的二进制文件，<strong>包含从上次停止点恢复训练模型所需的信息</strong>。我们具体看下列代码：</p>

<p>追踪<code>solver.cpp</code>的第445行,上下文信息如下所示:</p>

<pre><code class="language-c++">
template &lt;typename Dtype&gt;
string Solver&lt;Dtype&gt;::SnapshotToBinaryProto() {
//得到模型文件名
  string model_filename = SnapshotFilename(&quot;.caffemodel&quot;);
  LOG(INFO) &lt;&lt; &quot;Snapshotting to binary proto file &quot; &lt;&lt; model_filename;
  NetParameter net_param;
  //将net_转换为Netparameter
  net_-&gt;ToProto(&amp;net_param, param_.snapshot_diff());
  ///写入 ProtoBuffer 二进制文件，这里是 lenet_iter_10000.caffemodel
    WriteProtoToBinaryFile(net_param, model_filename);
  return model_filename;
}

</code></pre>

<p>追踪<code>sgd_solver.cpp</code>的259行:</p>

<pre><code class="language-c++">
template &lt;typename Dtype&gt;
void SGDSolver&lt;Dtype&gt;::SnapshotSolverStateToBinaryProto(
    const string&amp; model_filename) {
  SolverState state;    //创建一个序列化对象
  state.set_iter(this-&gt;iter_);  //记录当前的迭代次数
  state.set_learned_net(model_filename); //记录网络描述文件
  state.set_current_step(this-&gt;current_step_);  //记录当前步进值
  state.clear_history();    //清空容器,准备接纳新内容
  for (int i = 0; i &lt; history_.size(); ++i) {
    // Add history 记录权值的历史信息
    BlobProto* history_blob = state.add_history();
    history_[i]-&gt;ToProto(history_blob);
  }
  string snapshot_filename = Solver&lt;Dtype&gt;::SnapshotFilename(&quot;.solverstate&quot;);
  LOG(INFO)
    &lt;&lt; &quot;Snapshotting solver state to binary proto file &quot; &lt;&lt; snapshot_filename;
    //将SolverState对象写入二进制文件（*.solverstate)
  WriteProtoToBinaryFile(state, snapshot_filename.c_str());
}

</code></pre>

<p><strong>从磁盘上将模型、求解器状态文件载入内存的过程与上面代码刚好相反，我们可自行跟踪阅读。</strong></p>

<h2 id="toc_2">Caffe Modal Zoo</h2>

<p>对于前面我们运行的简单模型，可以从头训练（from scrash)。然而，对于规模更大、结构更复杂的模型，从头训练需耍解决两个问题：首先是硬件计算能力。模型训练十分消耗计算资源，使用普通计算机需要相当长的时间，不经济：而且世界上每个研究机构都从头训练，重复性工作太多，不环保。其次是调参能力。<strong>同样的模型设计，可能每个人训练结果都不一致，中间调参是项技术活，控制不当会引起训练发散或训练不充分，无法达到理想的分类效果</strong>。</p>

<p>为了解决上述问题,<strong>Caffe Model Zoo</strong>则提供了一个分享模型的平台，世界各地的研究人员都可以把自己的训练成果共享给社区中更多的人使用，节省人力、物力。</p>

<p><strong>今天我们也站在前人的肩膀上，运行一个基于已训练模型的图片分类例程</strong>。我们首先需要下载几个文件。</p>

<p>下载meta数据到当前目录:</p>

<pre><code>➜  caffe git:(master) ✗ cd data/ilsvrc12

➜  ilsvrc12 git:(master) ✗ ./get_ilsvrc_aux.sh

Downloading...
--2017-06-29 10:54:55--  http://dl.caffe.berkeleyvision.org/caffe_ilsvrc12.tar.gz
Resolving dl.caffe.berkeleyvision.org... 169.229.222.251
Connecting to dl.caffe.berkeleyvision.org|169.229.222.251|:80... connected.
HTTP request sent, awaiting response... 302 Found
Location: http://202.114.49.110/cache/9/02/berkeleyvision.org/6b5ff42be9dd0690a814318a14401a7f/caffe_ilsvrc12.tar.gz [following]
--2017-06-29 10:54:56--  http://202.114.49.110/cache/9/02/berkeleyvision.org/6b5ff42be9dd0690a814318a14401a7f/caffe_ilsvrc12.tar.gz
Connecting to 202.114.49.110:80... connected.
HTTP request sent, awaiting response... 200 OK
Length: 17858008 (17M) [application/octet-stream]
Saving to: ‘caffe_ilsvrc12.tar.gz’

caffe_ilsvrc12.tar. 100%[===================&gt;]  17.03M  9.67MB/s    in 1.8s

2017-06-29 10:54:58 (9.67 MB/s) - ‘caffe_ilsvrc12.tar.gz’ saved [17858008/17858008]

Unzipping...
Done.

</code></pre>

<p>下载caffenet模型:</p>

<pre><code>➜  ilsvrc12 git:(master) ✗ cd ../../models/bvlc_reference_caffenet

➜  bvlc_reference_caffenet git:(master) ✗ wget http://dl.caffe.berkeleyvision.org/bvlc_reference_caffenet.caffemodel
--2017-06-29 11:14:10--  http://dl.caffe.berkeleyvision.org/bvlc_reference_caffenet.caffemodel
Resolving dl.caffe.berkeleyvision.org... 169.229.222.251
Connecting to dl.caffe.berkeleyvision.org|169.229.222.251|:80... connected.
HTTP request sent, awaiting response... 200 OK
Length: 243862418 (233M) [application/octet-stream]
Saving to: ‘bvlc_reference_caffenet.caffemodel’

bvlc_reference_caffen 100%[=========================&gt;] 232.56M   129KB/s    in 21m 50s

2017-06-29 11:36:01 (182 KB/s) - ‘bvlc_reference_caffenet.caffemodel’ saved [243862418/243862418]

</code></pre>

<p>回到根目录执行:</p>

<pre><code>
➜  caffe git:(master) ✗ ./build/examples/cpp_classification/classification.bin \
models/bvlc_reference_caffenet/deploy.prototxt \
models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel \
data/ilsvrc12/imagenet_mean.binaryproto \
data/ilsvrc12/synset_words.txt \
examples/images/cat.jpg


</code></pre>

<p>发现报错:<br/>
<img src="media/14986110416063/14987195644285.jpg" alt=""/></p>

<p>执行:</p>

<pre><code>
➜  caffe git:(master) ✗ install_name_tool -add_rpath &#39;/Users/liangzhonghao/anaconda2/lib&#39;  /usr/local/Cellar/caffe/./build/examples/cpp_classification/classification.bin

</code></pre>

<p>再次运行上面命令,得出结果:<br/>
<img src="media/14986110416063/14987199347439.jpg" alt=""/></p>

<p>命令行解释如下:</p>

<pre><code class="language-c++">➜  caffe git:(master) ✗ ./build/examples/cpp_classification/classification.bin \        //二进制程序名
models/bvlc_reference_caffenet/deploy.prototxt \    //模型描述文件
models/bvlc_reference_caffenet/     bvlc_reference_caffenet.caffemodel \        //*.caffemodel模型权值文件
data/ilsvrc12/imagenet_mean.binaryproto \       //图像均值文件
data/ilsvrc12/synset_words.txt \    //图像类别标签信息
examples/images/mouse.png   //输入待分类图像

</code></pre>

<p>打开输入图像<code>examples/images/cat.jpg</code>:</p>

<p><img src="media/14986110416063/cat.jpg" alt="cat"/></p>

<p>命令行输出的预测结果为:</p>

<p><img src="media/14986110416063/14987205986830.jpg" alt=""/></p>

<p>可见给出了5个预测结果，按照概率分布从高到低的顺序排列。这种预测结果称为<code>Top-5</code>预测结果，对当前样本而言，分类准确率为5项之和。除<code>Top-5</code>预测结果之外，还有<code>Top-3、 Top-1等</code>预测结果，对当前样木的分类正确率分别为0.6749、0.3134。</p>

<p>分类准确率不仅与验证数据集有关，与模型的关系也非常密切。我们在<code>Caffe Model Zoo</code>上找到几个模型在ILSVRC 2012验证数据集上的分类效果，如图所示。<br/>
<img src="media/14986110416063/14987207716731.jpg" alt=""/></p>

<p>可见单模型<strong>分类性能最好的是BVLC GoogLeNet</strong>。</p>

<p>通过掌握上面的内容，并学习其他更多深度学习模型的设计和训练方法.</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[使用SQLite]]></title>
    <link href="https://lockxmonk.github.io/14985505390356.html"/>
    <updated>2017-06-27T16:02:19+08:00</updated>
    <id>https://lockxmonk.github.io/14985505390356.html</id>
    <content type="html"><![CDATA[
<p>SQLite是一种嵌入式数据库，它的数据库就是一个文件。由于SQLite本身是C写的，而且体积很小，所以，经常被集成到各种应用程序中，甚至在iOS和Android的App中都可以集成。</p>

<p>Python就内置了SQLite3，所以，在Python中使用SQLite，不需要安装任何东西，直接使用。</p>

<p>在使用SQLite前，我们先要搞清楚几个概念：</p>

<ol>
<li><p>表是数据库中存放关系数据的集合，一个数据库里面通常都包含多个表，比如学生的表，班级的表，学校的表，等等。表和表之间通过外键关联。</p></li>
<li><p>要操作关系数据库，首先需要连接到数据库，一个数据库连接称为Connection；</p></li>
<li><p>连接到数据库后，需要打开游标，称之为Cursor，通过Cursor执行SQL语句，然后，获得执行结果。</p></li>
<li><p>Python定义了一套操作数据库的API接口，任何数据库要连接到Python，只需要提供符合Python标准的数据库驱动即可。</p></li>
</ol>

<p>由于SQLite的驱动内置在Python标准库中，所以我们可以直接来操作SQLite数据库。</p>

<p>我们在Python交互式命令行实践一下：</p>

<pre><code class="language-python">
# 导入SQLite驱动:
&gt;&gt;&gt; import sqlite3

# 连接到SQLite数据库
# 数据库文件是test.db
# 如果文件不存在，会自动在当前目录创建:
&gt;&gt;&gt; conn = sqlite3.connect(&#39;test.db&#39;)
# 创建一个Cursor:
&gt;&gt;&gt; cursor = conn.cursor()
# 执行一条SQL语句，创建user表:
&gt;&gt;&gt; cursor.execute(&#39;create table user (id varchar(20) primary key, name varchar(20))&#39;)
&lt;sqlite3.Cursor object at 0x104082490&gt;
# 继续执行一条SQL语句，插入一条记录:
&gt;&gt;&gt; cursor.execute(&#39;insert into user (id, name) values (\&#39;1\&#39; , \&#39;Michale\&#39;)&#39;)
&lt;sqlite3.Cursor object at 0x104082490&gt;
# 通过rowcount获得插入的行数:
&gt;&gt;&gt; cursor.rowcount
1
# 关闭Cursor:
&gt;&gt;&gt; cursor.close()
# 提交事务:
&gt;&gt;&gt; conn.commit()
# 关闭Connection:
&gt;&gt;&gt; conn.close()

</code></pre>

<p>创建和插入表数据后,我们来查询:</p>

<pre><code class="language-python">
&gt;&gt;&gt; conn = sqlite3.connect(&#39;test.db&#39;)
&gt;&gt;&gt; cursor = conn.cursor()
# 执行查询语句:
&gt;&gt;&gt; cursor.execute(&#39;select * from user where id = ? &#39;, (&#39;1&#39;,))
&lt;sqlite3.Cursor object at 0x104082500&gt;
# 获得查询结果集:
&gt;&gt;&gt; values = cursor.fetchall()
&gt;&gt;&gt; values
[(u&#39;1&#39;, u&#39;Michale&#39;)]
&gt;&gt;&gt; cursor.close()
&gt;&gt;&gt; conn.close()
</code></pre>

<p><font color=red><strong>注意事项</strong></font></p>

<ol>
<li><p>使用Python的DB-API时，只要搞清楚Connection和Cursor对象，打开后一定记得关闭，就可以放心地使用。</p></li>
<li><p>使用Cursor对象执行<code>insert</code>，<code>update</code>，<code>delete</code>语句时，执行结果由<code>rowcount</code>返回影响的行数，就可以拿到执行结果。</p></li>
<li><p>使用Cursor对象执行<code>select</code>语句时，通过<code>featchall()</code>可以拿到结果集。结果集是一个<code>list</code>，每个元素都是一个<code>tuple</code>，对应一行记录。</p></li>
<li><p>如果SQL语句带有参数，那么需要把参数按照位置传递给<code>execute()</code>方法，有几个<code>?</code>占位符就必须对应几个参数，例如：</p></li>
</ol>

<pre><code class="language-py">
cursor.execute(&#39;select * from user where name=? and pwd=?&#39;, (&#39;abc&#39;, &#39;123456&#39;))

</code></pre>

<p>SQLite支持常见的标准SQL语句以及几种常见的数据类型。具体文档请参阅SQLite官方网站。</p>

<h2 id="toc_0">小结</h2>

<p>在Python中操作数据库时，要先导入数据库对应的驱动，然后，通过Connection对象和Cursor对象操作数据。</p>

<p>要确保打开的Connection对象和Cursor对象都正确地被关闭，否则，资源就会泄露。</p>

<p>如何才能确保出错的情况下也关闭掉Connection对象和Cursor对象呢？请回忆<code>try:...except:...finally:...</code>的用法。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[数据转换器]]></title>
    <link href="https://lockxmonk.github.io/14984437069936.html"/>
    <updated>2017-06-26T10:21:46+08:00</updated>
    <id>https://lockxmonk.github.io/14984437069936.html</id>
    <content type="html"><![CDATA[
<ul>
<li>
<a href="#toc_0">数据结构描述</a>
</li>
<li>
<a href="#toc_1">数据变换器的实现</a>
</li>
</ul>


<p>Caffe的数据变换器（DataTransformer)主要提供了对原始输入图像的预处理方法，包括随机切块、随机镜像、幅度缩放、去均值、灰度/色度变换等。相信熟悉图像处理、OpenCV的读者对上述操作并不陌生。</p>

<h2 id="toc_0">数据结构描述</h2>

<pre><code class="language-protobuf">message TransformationParameter {
  // For data pre-processing, we can do simple scaling and subtracting the
  // data mean, if provided. Note that the mean subtraction is always carried
  // out before scaling.
  //像素幅度缩放参数，默认为1，即不缩放
  optional float scale = 1 [default = 1];
  // Specify if we want to randomly mirror data.
  //图像随机镜像开关，默认为false,即不进行镜像操作
  optional bool mirror = 2 [default = false];
  // Specify if we would like to randomly crop an image.
  //图像随机切块的大小，默认为0,即不进行切块操作
  optional uint32 crop_size = 3 [default = 0];
  // mean_file and mean_value cannot be specified at the same time(存储图像均值的文件)
  optional string mean_file = 4;
  // if specified can be repeated once (would subtract it from all the channels)
  // or can be repeated the same number of times as channels
  // (would subtract them from the corresponding channel)
  //均值数值，无须读取文件。若数目与图像通道数相等，则每个图像通道分别减去对应的均值；如果只给出一个值.则毎个图像通道都减去同一个均值
  repeated float mean_value = 5;
  // Force the decoded image to have 3 color channels.
  //强制为三通道彩色图像输入
  optional bool force_color = 6 [default = false];
  // Force the decoded image to have 1 color channels.
  //强制为单通道灰度图像输入
  optional bool force_gray = 7 [default = false];
}

</code></pre>

<h2 id="toc_1">数据变换器的实现</h2>

<p>数据变换器声明头文件位于<code>include/cafTe/data_transformer.hpp</code>中，如果需要单独使用该模块,应包含这个头文件。文件内容如下:</p>

<pre><code class="language-c++">#ifndef CAFFE_DATA_TRANSFORMER_HPP
#define CAFFE_DATA_TRANSFORMER_HPP

#include &lt;vector&gt;

#include &quot;caffe/blob.hpp&quot;
#include &quot;caffe/common.hpp&quot;
#include &quot;caffe/proto/caffe.pb.h&quot;

namespace caffe {

/**
 * @brief Applies common transformations to the input data, such as
 * scaling, mirroring, substracting the image mean...
 */
 //DataTransformer类声明
template &lt;typename Dtype&gt;
class DataTransformer {
 public:
 //显式构造函数
  explicit DataTransformer(const TransformationParameter&amp; param, Phase phase);
  //析构函数
  virtual ~DataTransformer() {}

  /**
   * @brief Initialize the Random number generations if needed by the
   *    transformation.
   */
   //初始化随机数种子函数
  void InitRand();

  /**
   * @brief Applies the transformation defined in the data layer&#39;s
   * transform_param block to the data.
   *
   * @param datum
   *    Datum containing the data to be transformed.
   * @param transformed_blob
   *    This is destination blob. It can be part of top blob&#39;s data if
   *    set_cpu_data() is used. See data_layer.cpp for an example.
   */
   //下面几种函数重载,以适应多种输入数据源
  void Transform(const Datum&amp; datum, Blob&lt;Dtype&gt;* transformed_blob);

  /**
   * @brief Applies the transformation defined in the data layer&#39;s
   * transform_param block to a vector of Datum.
   *
   * @param datum_vector
   *    A vector of Datum containing the data to be transformed.
   * @param transformed_blob
   *    This is destination blob. It can be part of top blob&#39;s data if
   *    set_cpu_data() is used. See memory_layer.cpp for an example.
   */
  void Transform(const vector&lt;Datum&gt; &amp; datum_vector,
                Blob&lt;Dtype&gt;* transformed_blob);

#ifdef USE_OPENCV
  /**
   * @brief Applies the transformation defined in the data layer&#39;s
   * transform_param block to a vector of Mat.
   *
   * @param mat_vector
   *    A vector of Mat containing the data to be transformed.
   * @param transformed_blob
   *    This is destination blob. It can be part of top blob&#39;s data if
   *    set_cpu_data() is used. See memory_layer.cpp for an example.
   */
  void Transform(const vector&lt;cv::Mat&gt; &amp; mat_vector,
                Blob&lt;Dtype&gt;* transformed_blob);

  /**
   * @brief Applies the transformation defined in the data layer&#39;s
   * transform_param block to a cv::Mat
   *
   * @param cv_img
   *    cv::Mat containing the data to be transformed.
   * @param transformed_blob
   *    This is destination blob. It can be part of top blob&#39;s data if
   *    set_cpu_data() is used. See image_data_layer.cpp for an example.
   */
  void Transform(const cv::Mat&amp; cv_img, Blob&lt;Dtype&gt;* transformed_blob);
#endif  // USE_OPENCV

  /**
   * @brief Applies the same transformation defined in the data layer&#39;s
   * transform_param block to all the num images in a input_blob.
   *
   * @param input_blob
   *    A Blob containing the data to be transformed. It applies the same
   *    transformation to all the num images in the blob.
   * @param transformed_blob
   *    This is destination blob, it will contain as many images as the
   *    input blob. It can be part of top blob&#39;s data.
   */
  void Transform(Blob&lt;Dtype&gt;* input_blob, Blob&lt;Dtype&gt;* transformed_blob);


 //获取执行Transform后的输出Blob形状
  /**
   * @brief Infers the shape of transformed_blob will have when
   *    the transformation is applied to the data.
   *
   * @param datum
   *    Datum containing the data to be transformed.
   */
  vector&lt;int&gt; InferBlobShape(const Datum&amp; datum);
  /**
   * @brief Infers the shape of transformed_blob will have when
   *    the transformation is applied to the data.
   *    It uses the first element to infer the shape of the blob.
   *
   * @param datum_vector
   *    A vector of Datum containing the data to be transformed.
   */
  vector&lt;int&gt; InferBlobShape(const vector&lt;Datum&gt; &amp; datum_vector);
  /**
   * @brief Infers the shape of transformed_blob will have when
   *    the transformation is applied to the data.
   *    It uses the first element to infer the shape of the blob.
   *
   * @param mat_vector
   *    A vector of Mat containing the data to be transformed.
   */
#ifdef USE_OPENCV
  vector&lt;int&gt; InferBlobShape(const vector&lt;cv::Mat&gt; &amp; mat_vector);
  /**
   * @brief Infers the shape of transformed_blob will have when
   *    the transformation is applied to the data.
   *
   * @param cv_img
   *    cv::Mat containing the data to be transformed.
   */
  vector&lt;int&gt; InferBlobShape(const cv::Mat&amp; cv_img);
#endif  // USE_OPENCV

 protected:
   /**
   * @brief Generates a random integer from Uniform({0, 1, ..., n-1}).
   *
   * @param n
   *    The upperbound (exclusive) value of the random number.
   * @return
   *    A uniformly random integer value from ({0, 1, ..., n-1}).
   */
   //产生取值{0, 1, n-1}的随机整数，服从均匀分布
  virtual int Rand(int n);

  void Transform(const Datum&amp; datum, Dtype* transformed_data);
  // Tranformation parameters(变换参数，该数据结构由ProtoBuffer工具自动生成)
  TransformationParameter param_;

//随机数生成器，声明在include/caffe/common.hpp中
  shared_ptr&lt;Caffe::RNG&gt; rng_;
//当前运行阶段，可能为TRAIN或TEST。阶段不同，执行变换会有差异
  Phase phase_;
//均值图像,用于从均值文件中读取
  Blob&lt;Dtype&gt; data_mean_;
//均值数值,用于从param_中提取
  vector&lt;Dtype&gt; mean_values_;
};

}  // namespace caffe

#endif  // CAFFE_DATA_TRANSFORMER_HPP_

</code></pre>

<p>数据变化器的实现文件位于<code>src/caffe/data_transformer.cpp</code>，我们来深入阅读一下。</p>

<pre><code class="language-c++">#ifdef USE_OPENCV
#include &lt;opencv2/core/core.hpp&gt;
#endif  // USE_OPENCV

#include &lt;string&gt;
#include &lt;vector&gt;

#include &quot;caffe/data_transformer.hpp&quot;
#include &quot;caffe/util/io.hpp&quot;
#include &quot;caffe/util/math_functions.hpp&quot;
#include &quot;caffe/util/rng.hpp&quot;

namespace caffe {
//构造函数
template&lt;typename Dtype&gt;
DataTransformer&lt;Dtype&gt;::DataTransformer(const TransformationParameter&amp; param,
    Phase phase)
    : param_(param), phase_(phase) {        //初始化param_和phase_
  // check if we want to use mean_file(查看是否使用均值文件)
  if (param_.has_mean_file()) {
  //如果定了均值文件，又指定了均值数值，则报错，只能2选1
    CHECK_EQ(param_.mean_value_size(), 0) &lt;&lt;
      &quot;Cannot specify mean_file and mean_value at the same time&quot;;
    const string&amp; mean_file = param.mean_file();    //获取均值文件名
    if (Caffe::root_solver()) {
      LOG(INFO) &lt;&lt; &quot;Loading mean file from: &quot; &lt;&lt; mean_file;
    }
    //从均值文件中读取数据到blob_proto对象中
    BlobProto blob_proto;
    ReadProtoFromBinaryFileOrDie(mean_file.c_str(), &amp;blob_proto);
    //从blob_proto将均值反序列化到data_mean_内存中 
    data_mean_.FromProto(blob_proto);
  }
  // check if we want to use mean_value(均值数值)
  if (param_.mean_value_size() &gt; 0) {
    CHECK(param_.has_mean_file() == false) &lt;&lt;
      &quot;Cannot specify mean_file and mean_value at the same time&quot;;
    for (int c = 0; c &lt; param_.mean_value_size(); ++c) {
      mean_values_.push_back(param_.mean_value(c));//从param_中读取均值数值,不在读取均值文件
    }
  }
}
//变换函数，从众多重载函数中，我们选择一个重点讲解，其他的计算流程都类似
//下面函数使用了Datum作为输入，这个结构体我们可以从caffe.proto中一窥究竟
/*
    // Datum用来从LMDB/LEVELDB中读取数据，或将数据写入LMDB/LEVELDB,和BlobProto有相似的功能,只是BlobProto用于模型权值序列化/反序列化，而Datum专为数据或特征阁（feature map)提供序列化/反序列化服务.
message Datum {
 //数据维度信息，channels * height ★ width
  optional int32 channels = 1;
  optional int32 height = 2;
  optional int32 width = 3;
  // the actual image data, in bytes(图像数据，以字节类型存储)
  optional bytes data = 4;
  //标签数据，统一用int32类型存储
  optional int32 label = 5;
  // Optionally, the datum could also hold float data.(可选，图像数据也可以用float类型存储 )
  repeated float float_data = 6;
  // If true data contains an encoded image that need to be decoded(是否为编码数据，默认不是)
  optional bool encoded = 7 [default = false];
}
*/

//下面函数输入为Datum,输出为数据指针 
template&lt;typename Dtype&gt;
void DataTransformer&lt;Dtype&gt;::Transform(const Datum&amp; datum,
                                       Dtype* transformed_data) {
  //获得datum数据字串、维度信息
  const string&amp; data = datum.data();
  const int datum_channels = datum.channels();
  const int datum_height = datum.height();
  const int datum_width = datum.width();

//从取处理参数，如切块大小、幅度缩放、随机镜像、图像均值等
  const int crop_size = param_.crop_size();
  const Dtype scale = param_.scale();
  const bool do_mirror = param_.mirror() &amp;&amp; Rand(2);
  const bool has_mean_file = param_.has_mean_file();
  const bool has_uint8 = data.size() &gt; 0;
  const bool has_mean_values = mean_values_.size() &gt; 0;

  CHECK_GT(datum_channels, 0);  //保证输入数据通道数大于0
  CHECK_GE(datum_height, crop_size);    //保证输入数据宽和高大于切块大小
  CHECK_GE(datum_width, crop_size);
//获得图像均值
  Dtype* mean = NULL;
  if (has_mean_file) {  //若指定了图像均值文件
  //保证图像均值的维度与输入图像数据的维度完全相同 
    CHECK_EQ(datum_channels, data_mean_.channels());
    CHECK_EQ(datum_height, data_mean_.height());
    CHECK_EQ(datum_width, data_mean_.width());
    mean = data_mean_.mutable_cpu_data(); //夺取图像均值数据控制权
  }
  if (has_mean_values) {    //若没有指定图像均值文件，而是直接给出数值
  //保证均值数值维度为1,或与输人图像数据的channels数目相同
    CHECK(mean_values_.size() == 1 || mean_values_.size() == datum_channels) &lt;&lt;
     &quot;Specify either 1 mean_value or as many as channels: &quot; &lt;&lt; datum_channels;
    if (datum_channels &gt; 1 &amp;&amp; mean_values_.size() == 1) {
      // Replicate the mean_value for simplicity(若均值数值维度为1,而输入数据channels数目大于1,则重复该值channels次 )
      for (int c = 1; c &lt; datum_channels; ++c) {
        mean_values_.push_back(mean_values_[0]);
      }
    }
  }
  //输入图像宽和高
  int height = datum_height;
  int width = datum_width;
  //开始图像切块
  int h_off = 0;
  int w_off = 0;
  if (crop_size) { //crop_size不为0，则进行切块;若为0表示不切块
    height = crop_size;
    width = crop_size;
    // We only do random crop when we do training.
    if (phase_ == TRAIN) {
      h_off = Rand(datum_height - crop_size + 1); //切块的 height偏移量
      w_off = Rand(datum_width - crop_size + 1);  //切块的 width 偏移量
    } else {
      h_off = (datum_height - crop_size) / 2;
      w_off = (datum_width - crop_size) / 2;
    }
  }

  Dtype datum_element;      //存放输入图像的像素值
  int top_index, data_index;    //分别存放输出index,输入index
  for (int c = 0; c &lt; datum_channels; ++c) {
    for (int h = 0; h &lt; height; ++h) {
      for (int w = 0; w &lt; width; ++w) {
        data_index = (c * datum_height + h_off + h) * datum_width + w_off + w;
        if (do_mirror) {    //若需要镜像操作，则对输出index设置width反向
          top_index = (c * height + h) * width + (width - 1 - w);
        } else {
          top_index = (c * height + h) * width + w;
        }
        if (has_uint8) {    //若datum中使用uint8存储图像数据，需要转换为float
          datum_element =
            static_cast&lt;Dtype&gt;(static_cast&lt;uint8_t&gt;(data[data_index]));
        } else {
          datum_element = datum.float_data(data_index);
        }
        if (has_mean_file) {    //若指定了均值文件
          transformed_data[top_index] =
            (datum_element - mean[data_index]) * scale; // 执行去均值、幅度缩放
        } else {
          if (has_mean_values) {    //若指定了均值数值
            transformed_data[top_index] =
              (datum_element - mean_values_[c]) * scale;    //去均值,幅度缩放
          } else {
            transformed_data[top_index] = datum_element * scale;    //不去均值,制作幅度缩放
          }
        }
      }
    }
  }
}

//与上面函数类似.只是输出变为Blob
template&lt;typename Dtype&gt;
void DataTransformer&lt;Dtype&gt;::Transform(const Datum&amp; datum,
                                       Blob&lt;Dtype&gt;* transformed_blob) {
  // If datum is encoded, decode and transform the cv::image.(如果datum是经过编码的图像，则先解码 )
  if (datum.encoded()) {
#ifdef USE_OPENCV
    CHECK(!(param_.force_color() &amp;&amp; param_.force_gray()))
        &lt;&lt; &quot;cannot set both force_color and force_gray&quot;;
    cv::Mat cv_img;
    if (param_.force_color() || param_.force_gray()) {
    // If force_color then decode in color otherwise decode in gray.
      cv_img = DecodeDatumToCVMat(datum, param_.force_color());
    } else {
      cv_img = DecodeDatumToCVMatNative(datum);
    }
    // Transform the cv::image into blob.(将cv::image变为Blob)
    return Transform(cv_img, transformed_blob);
#else
    LOG(FATAL) &lt;&lt; &quot;Encoded datum requires OpenCV; compile with USE_OPENCV.&quot;;
#endif  // USE_OPENCV
  } else {
    if (param_.force_color() || param_.force_gray()) {
      LOG(ERROR) &lt;&lt; &quot;force_color and force_gray only for encoded datum&quot;;
    }
  }

  const int crop_size = param_.crop_size();
  const int datum_channels = datum.channels();
  const int datum_height = datum.height();
  const int datum_width = datum.width();

  // Check dimensions.
  const int channels = transformed_blob-&gt;channels();
  const int height = transformed_blob-&gt;height();
  const int width = transformed_blob-&gt;width();
  const int num = transformed_blob-&gt;num();

  CHECK_EQ(channels, datum_channels);
  CHECK_LE(height, datum_height);
  CHECK_LE(width, datum_width);
  CHECK_GE(num, 1);

  if (crop_size) {
    CHECK_EQ(crop_size, height);
    CHECK_EQ(crop_size, width);
  } else {
    CHECK_EQ(datum_height, height);
    CHECK_EQ(datum_width, width);
  }

  Dtype* transformed_data = transformed_blob-&gt;mutable_cpu_data();
  Transform(datum, transformed_data);   //参数变换完毕，调用现有函数
}

//对一组datum进行变换
template&lt;typename Dtype&gt;
void DataTransformer&lt;Dtype&gt;::Transform(const vector&lt;Datum&gt; &amp; datum_vector,
                                       Blob&lt;Dtype&gt;* transformed_blob) {
  const int datum_num = datum_vector.size();
  const int num = transformed_blob-&gt;num();
  const int channels = transformed_blob-&gt;channels();
  const int height = transformed_blob-&gt;height();
  const int width = transformed_blob-&gt;width();

  CHECK_GT(datum_num, 0) &lt;&lt; &quot;There is no datum to add&quot;;
  CHECK_LE(datum_num, num) &lt;&lt;
    &quot;The size of datum_vector must be no greater than transformed_blob-&gt;num()&quot;;
  Blob&lt;Dtype&gt; uni_blob(1, channels, height, width); //临时Blob
  //依次对每个datum进行变换.放入对应的Blob中
  for (int item_id = 0; item_id &lt; datum_num; ++item_id) {
    int offset = transformed_blob-&gt;offset(item_id);
    uni_blob.set_cpu_data(transformed_blob-&gt;mutable_cpu_data() + offset);
    Transform(datum_vector[item_id], &amp;uni_blob);
  }
}
//对一组输入cv::Mat对象进行变换.放入Blob中
#ifdef USE_OPENCV
template&lt;typename Dtype&gt;
void DataTransformer&lt;Dtype&gt;::Transform(const vector&lt;cv::Mat&gt; &amp; mat_vector,
                                       Blob&lt;Dtype&gt;* transformed_blob) {
  const int mat_num = mat_vector.size();
  const int num = transformed_blob-&gt;num();
  const int channels = transformed_blob-&gt;channels();
  const int height = transformed_blob-&gt;height();
  const int width = transformed_blob-&gt;width();

  CHECK_GT(mat_num, 0) &lt;&lt; &quot;There is no MAT to add&quot;;
  CHECK_EQ(mat_num, num) &lt;&lt;
    &quot;The size of mat_vector must be equals to transformed_blob-&gt;num()&quot;;
  Blob&lt;Dtype&gt; uni_blob(1, channels, height, width);
  for (int item_id = 0; item_id &lt; mat_num; ++item_id) {
    int offset = transformed_blob-&gt;offset(item_id);
    uni_blob.set_cpu_data(transformed_blob-&gt;mutable_cpu_data() + offset);
    Transform(mat_vector[item_id], &amp;uni_blob);
  }
}

//对一个cv:Mat对象进行变换
template&lt;typename Dtype&gt;
void DataTransformer&lt;Dtype&gt;::Transform(const cv::Mat&amp; cv_img,
                                       Blob&lt;Dtype&gt;* transformed_blob) {
  const int crop_size = param_.crop_size();
  const int img_channels = cv_img.channels();
  const int img_height = cv_img.rows;
  const int img_width = cv_img.cols;

  // Check dimensions.
  const int channels = transformed_blob-&gt;channels();
  const int height = transformed_blob-&gt;height();
  const int width = transformed_blob-&gt;width();
  const int num = transformed_blob-&gt;num();

  CHECK_EQ(channels, img_channels);
  CHECK_LE(height, img_height);
  CHECK_LE(width, img_width);
  CHECK_GE(num, 1);

  CHECK(cv_img.depth() == CV_8U) &lt;&lt; &quot;Image data type must be unsigned byte&quot;;

  const Dtype scale = param_.scale();
  const bool do_mirror = param_.mirror() &amp;&amp; Rand(2);
  const bool has_mean_file = param_.has_mean_file();
  const bool has_mean_values = mean_values_.size() &gt; 0;

  CHECK_GT(img_channels, 0);
  CHECK_GE(img_height, crop_size);
  CHECK_GE(img_width, crop_size);

  Dtype* mean = NULL;
  if (has_mean_file) {
    CHECK_EQ(img_channels, data_mean_.channels());
    CHECK_EQ(img_height, data_mean_.height());
    CHECK_EQ(img_width, data_mean_.width());
    mean = data_mean_.mutable_cpu_data();
  }
  if (has_mean_values) {
    CHECK(mean_values_.size() == 1 || mean_values_.size() == img_channels) &lt;&lt;
     &quot;Specify either 1 mean_value or as many as channels: &quot; &lt;&lt; img_channels;
    if (img_channels &gt; 1 &amp;&amp; mean_values_.size() == 1) {
      // Replicate the mean_value for simplicity(复制均值数值,便于操作)
      for (int c = 1; c &lt; img_channels; ++c) {
        mean_values_.push_back(mean_values_[0]);
      }
    }
  }

  int h_off = 0;
  int w_off = 0;
  cv::Mat cv_cropped_img = cv_img;
  if (crop_size) {
    CHECK_EQ(crop_size, height);
    CHECK_EQ(crop_size, width);
    // We only do random crop when we do training.
    if (phase_ == TRAIN) {
      h_off = Rand(img_height - crop_size + 1);
      w_off = Rand(img_width - crop_size + 1);
    } else {
      h_off = (img_height - crop_size) / 2;
      w_off = (img_width - crop_size) / 2;
    }
    cv::Rect roi(w_off, h_off, crop_size, crop_size);
    cv_cropped_img = cv_img(roi);
  } else {
    CHECK_EQ(img_height, height);
    CHECK_EQ(img_width, width);
  }

  CHECK(cv_cropped_img.data);

  Dtype* transformed_data = transformed_blob-&gt;mutable_cpu_data();
  int top_index;
  for (int h = 0; h &lt; height; ++h) {
    const uchar* ptr = cv_cropped_img.ptr&lt;uchar&gt;(h);
    int img_index = 0;
    for (int w = 0; w &lt; width; ++w) {
      for (int c = 0; c &lt; img_channels; ++c) {
        if (do_mirror) {
          top_index = (c * height + h) * width + (width - 1 - w);
        } else {
          top_index = (c * height + h) * width + w;
        }
        // int top_index = (c * height + h) * width + w;
        Dtype pixel = static_cast&lt;Dtype&gt;(ptr[img_index++]);
        if (has_mean_file) {
          int mean_index = (c * img_height + h_off + h) * img_width + w_off + w;
          transformed_data[top_index] =
            (pixel - mean[mean_index]) * scale;
        } else {
          if (has_mean_values) {
            transformed_data[top_index] =
              (pixel - mean_values_[c]) * scale;
          } else {
            transformed_data[top_index] = pixel * scale;
          }
        }
      }
    }
  }
}
#endif  // USE_OPENCV

//输入是Blob,输出也是Blob
template&lt;typename Dtype&gt;
void DataTransformer&lt;Dtype&gt;::Transform(Blob&lt;Dtype&gt;* input_blob,
                                       Blob&lt;Dtype&gt;* transformed_blob) {
  const int crop_size = param_.crop_size();
  const int input_num = input_blob-&gt;num();
  const int input_channels = input_blob-&gt;channels();
  const int input_height = input_blob-&gt;height();
  const int input_width = input_blob-&gt;width();

  if (transformed_blob-&gt;count() == 0) {
    // Initialize transformed_blob with the right shape.(初始化变换后的Blob的形状)
    if (crop_size) {
      transformed_blob-&gt;Reshape(input_num, input_channels,
                                crop_size, crop_size);
    } else {
      transformed_blob-&gt;Reshape(input_num, input_channels,
                                input_height, input_width);
    }
  }

  const int num = transformed_blob-&gt;num();
  const int channels = transformed_blob-&gt;channels();
  const int height = transformed_blob-&gt;height();
  const int width = transformed_blob-&gt;width();
  const int size = transformed_blob-&gt;count();

  CHECK_LE(input_num, num);
  CHECK_EQ(input_channels, channels);
  CHECK_GE(input_height, height);
  CHECK_GE(input_width, width);


  const Dtype scale = param_.scale();
  const bool do_mirror = param_.mirror() &amp;&amp; Rand(2);
  const bool has_mean_file = param_.has_mean_file();
  const bool has_mean_values = mean_values_.size() &gt; 0;

  int h_off = 0;
  int w_off = 0;
  if (crop_size) {
    CHECK_EQ(crop_size, height);
    CHECK_EQ(crop_size, width);
    // We only do random crop when we do training.
    if (phase_ == TRAIN) {
      h_off = Rand(input_height - crop_size + 1);
      w_off = Rand(input_width - crop_size + 1);
    } else {
      h_off = (input_height - crop_size) / 2;
      w_off = (input_width - crop_size) / 2;
    }
  } else {
    CHECK_EQ(input_height, height);
    CHECK_EQ(input_width, width);
  }

  Dtype* input_data = input_blob-&gt;mutable_cpu_data();
  if (has_mean_file) {
    CHECK_EQ(input_channels, data_mean_.channels());
    CHECK_EQ(input_height, data_mean_.height());
    CHECK_EQ(input_width, data_mean_.width());
    for (int n = 0; n &lt; input_num; ++n) {
      int offset = input_blob-&gt;offset(n);
      caffe_sub(data_mean_.count(), input_data + offset,
            data_mean_.cpu_data(), input_data + offset);
    }
  }

  if (has_mean_values) {
    CHECK(mean_values_.size() == 1 || mean_values_.size() == input_channels) &lt;&lt;
     &quot;Specify either 1 mean_value or as many as channels: &quot; &lt;&lt; input_channels;
    if (mean_values_.size() == 1) {
      caffe_add_scalar(input_blob-&gt;count(), -(mean_values_[0]), input_data);
    } else {
      for (int n = 0; n &lt; input_num; ++n) {
        for (int c = 0; c &lt; input_channels; ++c) {
          int offset = input_blob-&gt;offset(n, c);
          caffe_add_scalar(input_height * input_width, -(mean_values_[c]),
            input_data + offset);
        }
      }
    }
  }

  Dtype* transformed_data = transformed_blob-&gt;mutable_cpu_data();

  for (int n = 0; n &lt; input_num; ++n) {
    int top_index_n = n * channels;
    int data_index_n = n * channels;
    for (int c = 0; c &lt; channels; ++c) {
      int top_index_c = (top_index_n + c) * height;
      int data_index_c = (data_index_n + c) * input_height + h_off;
      for (int h = 0; h &lt; height; ++h) {
        int top_index_h = (top_index_c + h) * width;
        int data_index_h = (data_index_c + h) * input_width + w_off;
        if (do_mirror) {
          int top_index_w = top_index_h + width - 1;
          for (int w = 0; w &lt; width; ++w) {
            transformed_data[top_index_w-w] = input_data[data_index_h + w];
          }
        } else {
          for (int w = 0; w &lt; width; ++w) {
            transformed_data[top_index_h + w] = input_data[data_index_h + w];
          }
        }
      }
    }
  }
  if (scale != Dtype(1)) {
    DLOG(INFO) &lt;&lt; &quot;Scale: &quot; &lt;&lt; scale;
    caffe_scal(size, scale, transformed_data);
  }
}

//获得数据变换输出Blob尺寸
template&lt;typename Dtype&gt;
vector&lt;int&gt; DataTransformer&lt;Dtype&gt;::InferBlobShape(const Datum&amp; datum) {
  if (datum.encoded()) {
#ifdef USE_OPENCV
    CHECK(!(param_.force_color() &amp;&amp; param_.force_gray()))
        &lt;&lt; &quot;cannot set both force_color and force_gray&quot;;
    cv::Mat cv_img;
    if (param_.force_color() || param_.force_gray()) {
    // If force_color then decode in color otherwise decode in gray.
      cv_img = DecodeDatumToCVMat(datum, param_.force_color());
    } else {
      cv_img = DecodeDatumToCVMatNative(datum);
    }
    // InferBlobShape using the cv::image.
    return InferBlobShape(cv_img);
#else
    LOG(FATAL) &lt;&lt; &quot;Encoded datum requires OpenCV; compile with USE_OPENCV.&quot;;
#endif  // USE_OPENCV
  }
  const int crop_size = param_.crop_size();
  const int datum_channels = datum.channels();
  const int datum_height = datum.height();
  const int datum_width = datum.width();
  // Check dimensions.
  CHECK_GT(datum_channels, 0);
  CHECK_GE(datum_height, crop_size);
  CHECK_GE(datum_width, crop_size);
  // Build BlobShape.
  vector&lt;int&gt; shape(4);
  shape[0] = 1;
  shape[1] = datum_channels;
  shape[2] = (crop_size)? crop_size: datum_height;
  shape[3] = (crop_size)? crop_size: datum_width;
  return shape;
}


template&lt;typename Dtype&gt;
vector&lt;int&gt; DataTransformer&lt;Dtype&gt;::InferBlobShape(
    const vector&lt;Datum&gt; &amp; datum_vector) {
  const int num = datum_vector.size();
  CHECK_GT(num, 0) &lt;&lt; &quot;There is no datum to in the vector&quot;;
  // Use first datum in the vector to InferBlobShape.
  vector&lt;int&gt; shape = InferBlobShape(datum_vector[0]);
  // Adjust num to the size of the vector.
  shape[0] = num;
  return shape;
}

#ifdef USE_OPENCV
template&lt;typename Dtype&gt;
vector&lt;int&gt; DataTransformer&lt;Dtype&gt;::InferBlobShape(const cv::Mat&amp; cv_img) {
  const int crop_size = param_.crop_size();
  const int img_channels = cv_img.channels();
  const int img_height = cv_img.rows;
  const int img_width = cv_img.cols;
  // Check dimensions.
  CHECK_GT(img_channels, 0);
  CHECK_GE(img_height, crop_size);
  CHECK_GE(img_width, crop_size);
  // Build BlobShape.
  vector&lt;int&gt; shape(4);
  shape[0] = 1;
  shape[1] = img_channels;
  shape[2] = (crop_size)? crop_size: img_height;
  shape[3] = (crop_size)? crop_size: img_width;
  return shape;
}

template&lt;typename Dtype&gt;
vector&lt;int&gt; DataTransformer&lt;Dtype&gt;::InferBlobShape(
    const vector&lt;cv::Mat&gt; &amp; mat_vector) {
  const int num = mat_vector.size();
  CHECK_GT(num, 0) &lt;&lt; &quot;There is no cv_img to in the vector&quot;;
  // Use first cv_img in the vector to InferBlobShape.
  vector&lt;int&gt; shape = InferBlobShape(mat_vector[0]);
  // Adjust num to the size of the vector.
  shape[0] = num;
  return shape;
}
#endif  // USE_OPENCV

//初始化随机数种子
template &lt;typename Dtype&gt;
void DataTransformer&lt;Dtype&gt;::InitRand() {
//如果在初始化参数中要求对输入进行随机镜像操作，或者在训练阶段需要随机切块,那么需要初始化随机数种子
  const bool needs_rand = param_.mirror() ||
      (phase_ == TRAIN &amp;&amp; param_.crop_size());
  if (needs_rand) {
    const unsigned int rng_seed = caffe_rng_rand();
    rng_.reset(new Caffe::RNG(rng_seed));
  } else {
    rng_.reset();
  }
}

//生成0~n-1之间的随机数
template &lt;typename Dtype&gt;
int DataTransformer&lt;Dtype&gt;::Rand(int n) {
  CHECK(rng_);
  CHECK_GT(n, 0);
  caffe::rng_t* rng =
      static_cast&lt;caffe::rng_t*&gt;(rng_-&gt;generator());
  return ((*rng)() % n);
}

INSTANTIATE_CLASS(DataTransformer);

}  // namespace caffe

</code></pre>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Caffe I/O模块]]></title>
    <link href="https://lockxmonk.github.io/14982657549571.html"/>
    <updated>2017-06-24T08:55:54+08:00</updated>
    <id>https://lockxmonk.github.io/14982657549571.html</id>
    <content type="html"><![CDATA[
<p>这里我们讨论学习Caffe的I/O模块，即与<strong>数据</strong>打交道的模块。</p>

<p>我们在运行Caffe例程前，首先需要将原始数据转换为<strong>LMDB</strong>格式，训练网络时则需要由数据读取层(DataLayer)不断地从LMDB读取数据，送入后续卷积、下采样 等计算层。作为基础,Caffe I/O模块的效率直接影响到处理效果。</p>

<h2 id="toc_0">数据读取层</h2>

<p>Caffe数据读取层(DataLayer)是Layer的派生类。除了读取LMDB、LEVELDB之外，也可以从原始图像直接读取(ImageDataLayer)。</p>

<h3 id="toc_1">数据结构描述</h3>

<p>我们在<code>caffe.proto</code>中可以找到,关于数据结构的描述</p>

<pre><code class="language-protobuf">message DataParameter {
//输入数据使用的DB类型
  enum DB {
    LEVELDB = 0;    //使用 LEVELDB
    LMDB = 1;       //使用 LMDB
  }
  // Specify the data source.(源数据的路径)
  optional string source = 1;
  // Specify the batch size.( 一个批量数据包含的图片数)
  optional uint32 batch_size = 4;
  // The rand_skip variable is for the data layer to skip a few data points
  // to avoid all asynchronous sgd clients to start at the same point. The skip
  // point would be set as rand_skip * rand(0,1). Note that rand_skip should not
  // be larger than the number of keys in the database.
  // DEPRECATED. Each solver accesses a different subset of the database.
  //随机跳过若干图片，跳跃数为rand_skip * rand(0, 1)
  optional uint32 rand_skip = 7 [default = 0];
  //默认输入数据使用DB类型，默认为LEVELDB
  optional DB backend = 8 [default = LEVELDB];
  // DEPRECATED. See TransformationParameter. For data pre-processing, we can do
  // simple scaling and subtracting the data mean, if provided. Note that the
  // mean subtraction is always carried out before scaling.
  //scale、mean_file、crop_size、mirror 均为旧版参数，现已转移到 TransformationParameter
  optional float scale = 2 [default = 1];
  optional string mean_file = 3;
  // DEPRECATED. See TransformationParameter. Specify if we would like to randomly
  // crop an image.
  optional uint32 crop_size = 5 [default = 0];
  // DEPRECATED. See TransformationParameter. Specify if we want to randomly mirror
  // data.
  optional bool mirror = 6 [default = false];
  //强制编码图像为三通道彩色图像
  optional bool force_encoded_color = 9 [default = false];
  // Prefetch queue (Increase if data feeding bandwidth varies, within the
  // limit of device memory for GPU training)
  //预取队列(预先放到主机内存中的批量数.默认为4个Batch)
  optional uint32 prefetch = 10 [default = 4];
}

</code></pre>

<h3 id="toc_2">数据读取层的实现</h3>

<p>数据读取层声明位于<code>include/caffe/layers/base_data_layers.hpp</code>中，如果需要单独使用该层，则应包含这个头文件.</p>

<pre><code class="language-c++">namespace caffe {

/**
 * @brief Provides base for data layers that feed blobs to the Net.
 *
 * TODO(dox): thorough documentation for Forward and proto params.
 */
template &lt;typename Dtype&gt;
class BaseDataLayer : public Layer&lt;Dtype&gt; {
 public:
 //显式构造函数
  explicit BaseDataLayer(const LayerParameter&amp; param);
  // LayerSetUp: implements common data layer setup functionality, and calls
  // DataLayerSetUp to do special data layer setup for individual layer types.
  // This method may not be overridden except by the BasePrefetchingDataLayer.
  //层配置，实现通用层配置功能，之后调用DataLayerSetUp进行数据读取层的特别配置 
  virtual void LayerSetUp(const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,
      const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top);
  virtual void DataLayerSetUp(const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,
      const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top) {}
  // Data layers have no bottoms, so reshaping is trivial.(数据读取没有Bottom Blob,变形操作很简单 )
  virtual void Reshape(const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,
      const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top) {}
//反向传播函数不需要做任何操作
  virtual void Backward_cpu(const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top,
      const vector&lt;bool&gt;&amp; propagate_down, const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom) {}
  virtual void Backward_gpu(const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top,
      const vector&lt;bool&gt;&amp; propagate_down, const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom) {}

 protected:
 //数据预处理变换器参数
  TransformationParameter transform_param_;
  //数据预处理变换器
  shared_ptr&lt;DataTransformer&lt;Dtype&gt; &gt; data_transformer_;
  //是否输出标签数据
  bool output_labels_;
};
//批量数据，用于存放数据读取层输出
template &lt;typename Dtype&gt;
class Batch {
 public:
 //包含两个Blob: data_用于存放图片数据，label_用于存放标签
  Blob&lt;Dtype&gt; data_, label_;
};

//带预取功能的数据读取派生于BaseDataLayer和InternalThread
template &lt;typename Dtype&gt;
class BasePrefetchingDataLayer :
    public BaseDataLayer&lt;Dtype&gt;, public InternalThread {
 public:
 //显式构造函数
  explicit BasePrefetchingDataLayer(const LayerParameter&amp; param);
  // LayerSetUp: implements common data layer setup functionality, and calls
  // DataLayerSetUp to do special data layer setup for individual layer types.
  // This method may not be overridden.
  //层设置函数
  void LayerSetUp(const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,
      const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top);
//前向传播
  virtual void Forward_cpu(const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,
      const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top);
  virtual void Forward_gpu(const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,
      const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top);

 protected:
  virtual void InternalThreadEntry();   //内部线程入口
  virtual void load_batch(Batch&lt;Dtype&gt;* batch) = 0; //载入批量数据,纯虚函数

  vector&lt;shared_ptr&lt;Batch&lt;Dtype&gt; &gt; &gt; prefetch_; //预取Buffer
  BlockingQueue&lt;Batch&lt;Dtype&gt;*&gt; prefetch_free_;  //空闲Batch队列
  BlockingQueue&lt;Batch&lt;Dtype&gt;*&gt; prefetch_full_;  //已加载Batch队列
  Batch&lt;Dtype&gt;* prefetch_current_;  //当前Batch(猜的)

  Blob&lt;Dtype&gt; transformed_data_;    //变换后的数据
};


</code></pre>

<p>数据读取层的实现位于<code>src/caffe/layers/base_data_layer.cpp</code>中，内容如下:</p>

<pre><code class="language-c++">#include &lt;boost/thread.hpp&gt;
#include &lt;vector&gt;

#include &quot;caffe/blob.hpp&quot;
#include &quot;caffe/data_transformer.hpp&quot;
#include &quot;caffe/internal_thread.hpp&quot;
#include &quot;caffe/layer.hpp&quot;
#include &quot;caffe/layers/base_data_layer.hpp&quot;
#include &quot;caffe/proto/caffe.pb.h&quot;
#include &quot;caffe/util/blocking_queue.hpp&quot;

namespace caffe {
//构造函数，初始化Layer参数、数据变换器参数
template &lt;typename Dtype&gt;
BaseDataLayer&lt;Dtype&gt;::BaseDataLayer(const LayerParameter&amp; param)
    : Layer&lt;Dtype&gt;(param),
      transform_param_(param.transform_param()) {
}
//BaseDataLayer层设置 
template &lt;typename Dtype&gt;
void BaseDataLayer&lt;Dtype&gt;::LayerSetUp(const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,
      const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top) {
  if (top.size() == 1) {    //判断输出Blob个数，若为1只输出data，若为2则输出data和label
    output_labels_ = false;
  } else {
    output_labels_ = true;
  }
  //初始化数据变化器对象
  data_transformer_.reset(
      new DataTransformer&lt;Dtype&gt;(transform_param_, this-&gt;phase_));
  data_transformer_-&gt;InitRand();    //生成随机数种子
  // The subclasses should setup the size of bottom and top
  //子类负责设置Top Blob形状
  DataLayerSetUp(bottom, top);
}
//BasePrefetchingDataLayer 构造函数
template &lt;typename Dtype&gt;
BasePrefetchingDataLayer&lt;Dtype&gt;::BasePrefetchingDataLayer(
    const LayerParameter&amp; param)
    : BaseDataLayer&lt;Dtype&gt;(param),
      prefetch_(param.data_param().prefetch()),
      prefetch_free_(), prefetch_full_(), prefetch_current_() {
  for (int i = 0; i &lt; prefetch_.size(); ++i) {
    prefetch_[i].reset(new Batch&lt;Dtype&gt;());
    prefetch_free_.push(prefetch_[i].get());    //将Batch对象都放入空闲队列中
  }
}
//BasePrefetchingDataLayer层配置函数
template &lt;typename Dtype&gt;
void BasePrefetchingDataLayer&lt;Dtype&gt;::LayerSetUp(
    const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom, const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top) {
  BaseDataLayer&lt;Dtype&gt;::LayerSetUp(bottom, top);

  // Before starting the prefetch thread, we make cpu_data and gpu_data
  // calls so that the prefetch thread does not accidentally make simultaneous
  // cudaMalloc calls when the main thread is running. In some GPUs this
  // seems to cause failures if we do not so.
  //在幵启数据预取线程前，通过调用Blob相应函数先进行cudaMalloc,避免在多线程情况下同时进行cudaMalloc.会导致CUDA API调用失败
  for (int i = 0; i &lt; prefetch_.size(); ++i) {
    prefetch_[i]-&gt;data_.mutable_cpu_data();
    if (this-&gt;output_labels_) {
      prefetch_[i]-&gt;label_.mutable_cpu_data();
    }
  }
  //如果编译选项没有CPU_ONLY,则需要编译GPU代码
#ifndef CPU_ONLY    
  if (Caffe::mode() == Caffe::GPU) {
    for (int i = 0; i &lt; prefetch_.size(); ++i) {
      prefetch_[i]-&gt;data_.mutable_gpu_data();
      if (this-&gt;output_labels_) {
        prefetch_[i]-&gt;label_.mutable_gpu_data();    //功能同上
      }
    }
  }
#endif
  DLOG(INFO) &lt;&lt; &quot;Initializing prefetch&quot;;
  this-&gt;data_transformer_-&gt;InitRand();
  StartInternalThread();    //开启内部预取线程
  DLOG(INFO) &lt;&lt; &quot;Prefetch initialized.&quot;;
}
//内部线程入口
template &lt;typename Dtype&gt;
void BasePrefetchingDataLayer&lt;Dtype&gt;::InternalThreadEntry() {
//创建CUDA Stream,非阻塞类型
#ifndef CPU_ONLY
  cudaStream_t stream;
  if (Caffe::mode() == Caffe::GPU) {
    CUDA_CHECK(cudaStreamCreateWithFlags(&amp;stream, cudaStreamNonBlocking));
  }
#endif

  try {
    while (!must_stop()) {  //循环载入批量数据
      Batch&lt;Dtype&gt;* batch = prefetch_free_.pop();   //拿到一个空闲Batch
      load_batch(batch);    //载入批量数据
#ifndef CPU_ONLY
      if (Caffe::mode() == Caffe::GPU) {
        batch-&gt;data_.data().get()-&gt;async_gpu_push(stream);
        if (this-&gt;output_labels_) {
          batch-&gt;label_.data().get()-&gt;async_gpu_push(stream);
        }
        CUDA_CHECK(cudaStreamSynchronize(stream));//同步到GPU
      }
#endif
      prefetch_full_.push(batch);   //加入到带负载的Batch队列中
    }
  } catch (boost::thread_interrupted&amp;) {
    // Interrupted exception is expected on shutdown(捕获到异常,退出while循环)
  }
#ifndef CPU_ONLY
  if (Caffe::mode() == Caffe::GPU) {
    CUDA_CHECK(cudaStreamDestroy(stream));  //销毁CUDA Stream
  }
#endif
}
//前向传波函数
template &lt;typename Dtype&gt;
void BasePrefetchingDataLayer&lt;Dtype&gt;::Forward_cpu(
    const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom, const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top) {
    //从带负载的Batch队列中取出一个Batch对象
  if (prefetch_current_) {
    prefetch_free_.push(prefetch_current_);
  }
  prefetch_current_ = prefetch_full_.pop(&quot;Waiting for data&quot;);
  // Reshape to loaded data.(Top Blob根据Batch形状进行变形)
  top[0]-&gt;ReshapeLike(prefetch_current_-&gt;data_);
  //将数据放到Top Blob中
  top[0]-&gt;set_cpu_data(prefetch_current_-&gt;data_.mutable_cpu_data());
  if (this-&gt;output_labels_) {
    // Reshape to loaded labels.(同上)
    top[1]-&gt;ReshapeLike(prefetch_current_-&gt;label_);
    top[1]-&gt;set_cpu_data(prefetch_current_-&gt;label_.mutable_cpu_data());
  }
}

#ifdef CPU_ONLY
STUB_GPU_FORWARD(BasePrefetchingDataLayer, Forward);
#endif

INSTANTIATE_CLASS(BaseDataLayer);
INSTANTIATE_CLASS(BasePrefetchingDataLayer);

}  // namespace caffe

</code></pre>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[MAC下openBlas的安装]]></title>
    <link href="https://lockxmonk.github.io/14980252836745.html"/>
    <updated>2017-06-21T14:08:03+08:00</updated>
    <id>https://lockxmonk.github.io/14980252836745.html</id>
    <content type="html"><![CDATA[
<p>这里我们安装openblas主要有两种方法:</p>

<ol>
<li>通过git代码到本地并安装</li>
<li>通过brew来安装</li>
</ol>

<h2 id="toc_0">git到本地编译安装.</h2>

<ol>
<li>git代码到本地并安装</li>
</ol>

<pre><code>git clone https://github.com/xianyi/OpenBLAS.git
cd OpenBLAS
make -j4
make install

</code></pre>

<ol>
<li>修改Caffe的<code>Makefile.config</code></li>
</ol>

<pre><code>BLAS := open
BLAS_INCLUDE :=  /opt/OpenBLAS/include
BLAS_LIB := /opt/OpenBLAS/lib
</code></pre>

<ol>
<li>caffe重新make</li>
</ol>

<pre><code>make clean
make pycaffe
make all -j4
make test &amp;&amp; runtest
</code></pre>

<h2 id="toc_1">使用brew进行安装</h2>

<ol>
<li><code>brew uninstall openblas; brew install --fresh -vd openblas.</code>运行上面命令安装openblas</li>
<li>更改<code>Makefile.config</code></li>
</ol>

<pre><code>
# Homebrew puts openblas in a directory that is not on the standard search path
BLAS_INCLUDE := $(shell brew --prefix openblas)/include
BLAS_LIB := $(shell brew --prefix openblas)/lib

</code></pre>

<ol>
<li>重新编译</li>
</ol>

<p><strong>如果有些人遇到了这种错误</strong></p>

<pre><code>In file included from src/caffe/util/blocking_queue.cpp:5:
In file included from ./include/caffe/layers/base_data_layer.hpp:9:
In file included from ./include/caffe/layer.hpp:12:
In file included from ./include/caffe/util/math_functions.hpp:11:
./include/caffe/util/mkl_alternate.hpp:14:10: fatal error: &#39;cblas.h&#39; file not found
#include &lt;cblas.h&gt;
         ^
1 error generated.
make: *** [.build_release/src/caffe/util/blocking_queue.o] Error 1
</code></pre>

<p>可以试试这个命令:</p>

<pre><code>cmake -DCMAKE_CXX_FLAGS=-I/usr/local/opt/openblas/include ..
</code></pre>

]]></content>
  </entry>
  
</feed>
