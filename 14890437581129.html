
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>
    
  感知机 - LZH007
  

  </title>
  <meta name="author" content="">
  <meta name="description" content="LZH的技术杂事小博客~">

  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link href="asset/css/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="atom.xml" rel="alternate" title="LZH007" type="application/atom+xml">
  <script src="asset/js/modernizr-2.0.js"></script>
  <script src="asset/js/jquery.min.js"></script>
  <script src="asset/highlightjs/highlight.pack.js"></script>
  <link href="asset/highlightjs/styles/solarized_light.css" media="screen, projection" rel="stylesheet" type="text/css">
  <script>hljs.initHighlightingOnLoad();</script>

  <style type="text/css">
  .cat-children-p{ padding: 6px 0px;}
  .hljs{background: none;}
  </style>
  <script type="text/javascript">
  var isAddSildbar = true;
  </script>
  <script src="asset/js/octopress.js" type="text/javascript"></script>
</head>
<script type="text/javascript">
//链接新开窗口
function addBlankTargetForLinks () {
  $('a[href^="http"]').each(function(){
      $(this).attr('target', '_blank');
  });
}
$(document).ready(function(event) {
  addBlankTargetForLinks();
});
</script>
<body   >
  <header role="banner"><hgroup>
  <h1><a href="index.html">LZH007</a></h1>
  
    <h2>LZH的技术杂事小博客~</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="http://google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:lockxmonk.github.io" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">

  <li id=""><a target="self" href="index.html">Home</a></li>

  <li id=""><a target="_self" href="archives.html">Archives</a></li>

</ul>

</nav>
  <div id="main">
    <div id="content"> 
<div>
	<article class="hentry" role="article">
	<header>
			  	<h1 class="entry-title">感知机</h1>
				<p class="meta"><time datetime="2017-03-09T15:15:58+08:00" pubdate data-updated="true">2017/3/9</time></p>
			 </header>
		  	<div class="entry-content">
			  	<ul>
<li>
<a href="#toc_0">感知机模型</a>
</li>
<li>
<a href="#toc_1">感知机的学习策略</a>
<ul>
<li>
<a href="#toc_2">数据集的线性可分性</a>
</li>
<li>
<a href="#toc_3">感知机学习策略</a>
</li>
</ul>
</li>
<li>
<a href="#toc_4">感知机学习算法</a>
<ul>
<li>
<a href="#toc_5">感知机学习算法的原始形式</a>
</li>
</ul>
</li>
</ul>


<p>感知机是二类分类的线性分类模型，其输入为实例的特征向量，输出为实例的类别（一般为+1和-1），感知机对应于输入空间（特征空间）中将实例划分为正负两类的分离超平面，属于判别模型。感知机学习旨在求出将训练数据进行线性划分的分离超平面。感知机也是神经网络与支持向量机的基础。</p>

<h2 id="toc_0">感知机模型</h2>

<p>感知机的定义为：<br/>
<img src="media/14890437581129/14890447646559.jpg" alt=""/></p>

<p>感知机有如下的几何解释：<br/>
线性方程：w*x + b = 0<br/>
对应于特征空间R中的一个超平面S，其中w是超平面的法向量，b是超平面的截距，这个超平面将特征空间划分为两个部分，位于两部分的点就被划分为正，负两类，如下图所示：<br/>
<img src="media/14890437581129/14890449623708.jpg" alt=""/></p>

<p>所以求感知机的模型，也就是去求得模型参数w，b。感知机预测，通过学习得到的感知机模型，对于新输入实例给出其对应的输出类别。</p>

<h2 id="toc_1">感知机的学习策略</h2>

<h3 id="toc_2">数据集的线性可分性</h3>

<p><img src="media/14890437581129/14890453486666.jpg" alt=""/></p>

<h3 id="toc_3">感知机学习策略</h3>

<p>如果训练数据集是线性可分的，那么我们需要确定一个学习策略，也就是定义（经验）损失函数并将损失函数极小化。</p>

<p>损失函数的一个自然选择是误分类点的总数。但是，这样的损失函数不是参数w,b的连续可导函数，不易优化。损失函数的另一个选择是误分类点到超平面S的总距离，这是感知机所采用的。为此，首先写出输入控件R中任一点x到平面S的距离：<img src="media/14890437581129/14890456220821.jpg" alt=""/><br/>
这里，||w||是w的2范数。<br/>
其次，对于五分类的数据（x，y）来说，<br/>
<code>-y(w*x+b)&gt;0</code>成立。因为当<code>w*x+b&gt;0</code>时，<code>y=-1</code>，而当<code>w*x+b&lt;0</code>时<code>y=+1</code>，因此，误分类点x到超平面S的距离是：<br/>
<img src="media/14890437581129/14890460147136.jpg" alt=""/><br/>
这样，假设超平面S的误分类点集合为M，那么所有的误分类点到超平面S的总距离为：<br/>
<img src="media/14890437581129/14890462066356.jpg" alt=""/></p>

<p>所以，感知机的损失函数定义为：<img src="media/14890437581129/14890462888502.jpg" alt=""/></p>

<p>显然，损失函数是非负的，如果没有误分类点，那么损失函数为0，而误分类点越少，误分类点离超平面越近，损失函数值越小。一个特定的样本点的损失函数：在误分类时是参数w，b的线性函数，在正确分类时是0，因此给定训练数据集T，损失函数是w，b的连续可导函数。<br/>
总的来说我们的感知机学习策略就是在假设空间中选取使损失函数式最小的模型参数w，b。</p>

<h2 id="toc_4">感知机学习算法</h2>

<p>我们的策略已经明确，就是求解损失函数式的最优化，我们这里最优化的方法是随机梯度下降法。</p>

<h3 id="toc_5">感知机学习算法的原始形式</h3>

<p>感知机学习算法是对以下最优化问题的算法，给定一个训练集：<img src="media/14890437581129/14890473616479.jpg" alt=""/><br/>
感知机学习算法是误分类驱动的，具体采用随机梯度下降法（stochastic gradient descent)。首先，任意选取一个超平面然后用梯度下降法不断地极小化目标函数<code>（2.5）</code>。极小化过程中不是一次使M中所有误分类点的梯度下降， 而是一次随机选取一个误分类点使其梯度下降。<br/>
假设误分类点集合M是固定的，那么损失函数的梯度由<img src="media/14890437581129/14890475151426.jpg" alt=""/><br/>
给出。<br/>
随机选取一个误分类点<code>(x,y)</code>，对w,b进行更新：<img src="media/14890437581129/14890475562013.jpg" alt=""/><br/>
式中η(0&lt;η≤1)是步长，在统计学习中又称为学习率，这样，通过迭代可以期待损失函数不断减小，直到为0，综上所述，得到如下算法：<img src="media/14890437581129/14890483224015.jpg" alt=""/><br/>
这种学习算法直观上有如下解释：当一个实例点被误分类，即位于分离超平面的错误一侧时，则调整w,b的值，使分离超平面向该误分类点的一侧移动，以减少该误分类点与超平面间的距离，直至超平面越过该误分类点使其被正确分类。</p>

<p>上述算法是感知机学习的基本算法，对应于后面的对偶形式，称为原始形式。感知机学习算法简单且易于实现。</p>

<p>该算法使用方法如下：<br/>
<img src="media/14890437581129/14890503525005.jpg" alt=""/><br/>
<img src="media/14890437581129/14890503748369.jpg" alt=""/><br/>
<img src="media/14890437581129/14890503942221.jpg" alt=""/><br/>
这是在计算中误分类点先后取<code>x1,x3,x3,x3,x1,x3,x3</code>得到的分离超平面和感 知机模型，如果在计算中误分类点依次取<code>x1,x3,x3,x3,x2,x3,x3,x3,x1,x3,x3</code>那么得到的分离超平面是2x<sup>1</sup>+x<sup>2</sup>-5=0</p>

<p>可见，感知机学习算法由于采用不同的初值或选取不同的误分类点，解可以不同。</p>

			</div>

		
	  
		<footer>
		 <p class="meta">

			<strong>Categories:</strong>&nbsp; 
			<span class="categories">
			
			    <a class='category' href='%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95.html'>统计学习方法</a>&nbsp;
			 
			</span>
		    </p>
		    <p class="meta">
		      
		 </p>
	    
		<div class="sharing">
		  
          

          

		</div>

	    <p class="meta">
	    
	        <a class="basic-alignment left" href="14891071598954.html" 
	        title="Previous Post: 感知机算法的收敛性">&laquo; 感知机算法的收敛性</a>
	    
	    
	        <a class="basic-alignment right" href="14878150947508.html" 
	        title="Next Post: MNIST机器学习入门">MNIST机器学习入门 &raquo;</a>
	    
	    </p>
	  </footer>
	</article>
</div>
 <aside class="sidebar"> 

	<section>
	  <h1>Categories</h1>
	  <ul id="recent_posts">
	  
	      <li class="post">
	        <a href="Effective%20OC2.0.html"><strong>Effective OC2.0&nbsp;(3)</strong></a>
	        
	        
	        
	      </li>
	  
	      <li class="post">
	        <a href="English%20Study.html"><strong>English Study&nbsp;(2)</strong></a>
	        
	        
	        
	      </li>
	  
	      <li class="post">
	        <a href="%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0.html"><strong>深度学习&nbsp;(1)</strong></a>
	        
	        
	        
	      </li>
	  
	      <li class="post">
	        <a href="%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95.html"><strong>统计学习方法&nbsp;(6)</strong></a>
	        
	        
	        
	      </li>
	   
	  </ul>
	</section>
	<section>
	  <h1>Recent Posts</h1>
	  <ul id="recent_posts">
	  
	      
		      <li class="post">
		        <a href="14908575557810.html">决策树生成--CART算法</a>
		      </li>
	     
	  
	      
		      <li class="post">
		        <a href="14898241272608.html">决策树的生成</a>
		      </li>
	     
	  
	      
		      <li class="post">
		        <a href="14897993109270.html">决策树</a>
		      </li>
	     
	  
	      
		      <li class="post">
		        <a href="14893694433396.html">朴素贝叶斯法</a>
		      </li>
	     
	  
	      
		      <li class="post">
		        <a href="14891936534415.html">k近邻法</a>
		      </li>
	     
	  
	      
	  
	      
	  
	      
	  
	      
	  
	      
	  
	      
	  
	      
	  
	      
	   
	  </ul>
	</section>
	
</aside> </div></div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2014 -  -
  <span class="credit">Powered by <a target="_blank" href="http://www.mweb.im">MWeb</a> &nbsp;&nbsp; Theme by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>

  
    

<script src="asset/chart/all-min.js"></script><script type="text/javascript">$(function(){    var mwebii=0;    var mwebChartEleId = 'mweb-chart-ele-';    $('pre>code').each(function(){        mwebii++;        var eleiid = mwebChartEleId+mwebii;        if($(this).hasClass('language-sequence')){            var ele = $(this).addClass('nohighlight').parent();            $('<div id="'+eleiid+'"></div>').insertAfter(ele);            ele.hide();            var diagram = Diagram.parse($(this).text());            diagram.drawSVG(eleiid,{theme: 'simple'});        }else if($(this).hasClass('language-flow')){            var ele = $(this).addClass('nohighlight').parent();            $('<div id="'+eleiid+'"></div>').insertAfter(ele);            ele.hide();            var diagram = flowchart.parse($(this).text());            diagram.drawSVG(eleiid);        }    });});</script>
<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({TeX: { equationNumbers: { autoNumber: "AMS" } }});</script>

</body>
</html>